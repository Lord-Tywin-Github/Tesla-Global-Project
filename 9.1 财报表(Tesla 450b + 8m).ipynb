{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2e6bb7f-03d7-4a68-ae2d-78a510942510",
   "metadata": {},
   "source": [
    "### **1/6: 生成 Dim_Product 表 （覆盖绝大部分特斯拉产品）(简单静态数据)维度表更可能需要更新Update或追加Append。例如，新产品发布，此时就需要更新Update或追加Append表中的相应记录。这种变化管理被称为“缓慢变化维度”（Slowly Changing Dimension, SCD）** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3938dc8d-31c1-40ac-b3f6-498063caa69d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Dim_Product table...\n",
      "Saving Dim_Product.csv...\n",
      "Dim_Product.csv has been successfully generated with 3151 rows in 0.03 seconds.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"1/6: Generate Dim_Product Table with detailed configurations.\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import product\n",
    "from datetime import date\n",
    "\n",
    "# Use a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def generate_dim_product():\n",
    "    \"\"\"\n",
    "    Generates the Dim_Product table with all product and configuration details.\n",
    "    \"\"\"\n",
    "    # 基础产品信息 (Base products) - Modified\n",
    "    base_products = {\n",
    "        'Model 3': 'Automotive Sales',\n",
    "        'Model Y': 'Automotive Sales',\n",
    "        'Model S': 'Automotive Sales',\n",
    "        'Model X': 'Automotive Sales',\n",
    "        'Cybertruck': 'Automotive Sales'\n",
    "    }\n",
    "\n",
    "    # 汽车版本和价格 (Variants and their prices)\n",
    "    variants = {\n",
    "        'Model 3': {\n",
    "            'Rear-Wheel Drive': np.nan,\n",
    "            'Long Range RWD': np.nan,\n",
    "            'Long Range AWD': np.nan,\n",
    "            'Performance': np.nan\n",
    "        },\n",
    "        'Model Y': {\n",
    "            'Standard Range RWD': np.nan,\n",
    "            'Long Range RWD': np.nan,\n",
    "            'Long Range AWD': np.nan,\n",
    "            'Performance': np.nan,\n",
    "            'Model Y L (3-Row)': np.nan\n",
    "        },\n",
    "        'Model S': {\n",
    "            'Long Range AWD': np.nan,\n",
    "            'Plaid': np.nan\n",
    "        },\n",
    "        'Model X': {\n",
    "            'All-Wheel Drive': np.nan,\n",
    "            'Plaid': np.nan\n",
    "        },\n",
    "        'Cybertruck': {\n",
    "            'Long Range': np.nan,\n",
    "            'AWD': np.nan,\n",
    "            'Cyberbeast': np.nan\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 可配置选项和价格 (Configurable options and their prices)\n",
    "    options = {\n",
    "        'Paint_Color': {\n",
    "            'Solid Black': np.nan, 'Deep Blue Metallic': np.nan, 'Stealth Grey': np.nan,\n",
    "            'Ultra Red': np.nan, 'Quicksilver': np.nan, 'Pearl White Multi-Coat': np.nan, 'None': np.nan\n",
    "        },\n",
    "        'Wheel_Type': {\n",
    "            'Aero Wheels': np.nan, '19\" Nova Wheels': np.nan, 'Crossflow 19\"': np.nan,\n",
    "            'Helix 20\"': np.nan, 'Base Wheels': np.nan, 'Performance Wheels': np.nan, 'None': np.nan\n",
    "        },\n",
    "        'Interior_Type': {\n",
    "            'Black Interior': np.nan, 'Black and White Interior': np.nan, 'Cream Interior': np.nan, 'None': np.nan\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Define product release dates for ID ordering\n",
    "    # Use a dictionary to map product models to their approximate release dates\n",
    "    release_dates = {\n",
    "        'Model S': date(2012, 6, 1),\n",
    "        'Model X': date(2015, 9, 1),\n",
    "        'Model 3': date(2017, 7, 1),\n",
    "        'Model Y': date(2020, 1, 1),\n",
    "        'Cybertruck': date(2023, 11, 1),\n",
    "        'N/A': date(2010, 1, 1) # A generic early date for non-automotive products\n",
    "    }\n",
    "\n",
    "    all_products = []\n",
    "\n",
    "    # Generate all automotive product configurations first\n",
    "    for model, category in base_products.items():\n",
    "        if model in variants:\n",
    "            variant_names = list(variants[model].keys())\n",
    "            paint_colors = list(options['Paint_Color'].keys())\n",
    "            wheel_types = list(options['Wheel_Type'].keys())\n",
    "            interior_types = list(options['Interior_Type'].keys())\n",
    "            \n",
    "            combinations = list(product(variant_names, paint_colors, wheel_types, interior_types))\n",
    "            \n",
    "            for combo in combinations:\n",
    "                variant, paint, wheel, interior = combo\n",
    "                product_name = f\"{model} {variant} - {paint} - {wheel} - {interior}\"\n",
    "                all_products.append({\n",
    "                    'Product_Name': product_name,\n",
    "                    'Product_Category': category,\n",
    "                    'Product_Model': model,\n",
    "                    'Product_Variant': variant,\n",
    "                    'Paint_Color': paint,\n",
    "                    'Wheel_Type': wheel,\n",
    "                    'Interior_Type': interior\n",
    "                })\n",
    "\n",
    "    # Add non-automotive products, including the missing ones\n",
    "    # The categories have been changed to match the user's request\n",
    "    non_automotive_products = [\n",
    "        ('Model 3 LR RWD Lease (24mo)', 'Automotive Leasing', 'Lease', np.nan, np.nan, np.nan),\n",
    "        ('Model 3 LR RWD Lease (36mo)', 'Automotive Leasing', 'Lease', np.nan, np.nan, np.nan),\n",
    "        ('Model Y LR RWD Lease (24mo)', 'Automotive Leasing', 'Lease', np.nan, np.nan, np.nan),\n",
    "        ('Model Y LR RWD Lease (36mo)', 'Automotive Leasing', 'Lease', np.nan, np.nan, np.nan),\n",
    "        ('Solar Panels', 'Energy Generation & Storage', 'Solar Panel', np.nan, np.nan, np.nan),\n",
    "        ('Solar Roof', 'Energy Generation & Storage', 'Solar Roof', np.nan, np.nan, np.nan),\n",
    "        ('Powerwall 3', 'Energy Generation & Storage', 'Powerwall', np.nan, np.nan, np.nan),\n",
    "        ('Megapack', 'Energy Generation & Storage', 'Megapack', np.nan, np.nan, np.nan),\n",
    "        ('FSD (Full Self-Driving)', 'Automotive Sales', 'Feature', np.nan, np.nan, np.nan),\n",
    "        ('CyberCab (2026 Placeholder)', 'Automotive Sales', 'Service', np.nan, np.nan, np.nan),\n",
    "        ('Regulatory Credits', 'Automotive Regulatory Credits', 'Credit', np.nan, np.nan, np.nan),\n",
    "        ('Charging Equipment', 'Services & Other', 'Accessory', np.nan, np.nan, np.nan),\n",
    "        ('Vehicle Accessories', 'Services & Other', 'Accessory', np.nan, np.nan, np.nan),\n",
    "        ('Apparel', 'Services & Other', 'Apparel', np.nan, np.nan, np.nan),\n",
    "        ('Lifestyle', 'Services & Other', 'Lifestyle', np.nan, np.nan, np.nan),\n",
    "    ]\n",
    "\n",
    "    for prod_name, cat, variant, paint, wheel, interior in non_automotive_products:\n",
    "        all_products.append({\n",
    "            'Product_Name': prod_name,\n",
    "            'Product_Category': cat,\n",
    "            'Product_Model': 'N/A', # Use 'N/A' for non-automotive products\n",
    "            'Product_Variant': variant,\n",
    "            'Paint_Color': paint,\n",
    "            'Wheel_Type': wheel,\n",
    "            'Interior_Type': interior\n",
    "        })\n",
    "\n",
    "    # Sort products by their release date to ensure a logical ID sequence\n",
    "    all_products.sort(key=lambda x: release_dates.get(x['Product_Model'], date(2010, 1, 1)))\n",
    "\n",
    "    # Assign sequential Product_ID to the sorted list\n",
    "    for i, prod in enumerate(all_products):\n",
    "        prod['Product_ID'] = f'PRO{i+1:03d}'\n",
    "    \n",
    "    # Define columns with the price column removed\n",
    "    columns = [\n",
    "        'Product_ID', 'Product_Name', 'Product_Category', 'Product_Variant',\n",
    "        'Paint_Color', 'Wheel_Type', 'Interior_Type'\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(all_products, columns=columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Generating Dim_Product table...\")\n",
    "    dim_product_df = generate_dim_product()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(\"Saving Dim_Product.csv...\")\n",
    "    # 修改了这一行，确保 NA 值被正确写入 CSV 文件\n",
    "    dim_product_df.to_csv(os.path.join(output_dir, 'Dim_Product.csv'), index=False, encoding='utf-8', na_rep='NA')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Dim_Product.csv has been successfully generated with {len(dim_product_df)} rows in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c53d0b-cce6-4926-9728-61833d0ef3b5",
   "metadata": {},
   "source": [
    "### **2/6: 生成 Dim_Time 表 (单一向前数据)维度表只追加Append。每一个时间点、每一天、每一个月都是一个既定的、永恒不变的事实。你无法“更新”昨天或去年的日期，此时就需要追加Append表中的相应记录。没有复杂的版本控制机制（Slowly Changing Dimension, SCD）** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f94191e-eb6b-4a29-9662-942dfbb397a9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Dim_Time table...\n",
      "Saving Dim_Time.csv...\n",
      "Dim_Time.csv has been successfully generated with 4,748 rows in 0.02 seconds.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"2/6: Generate Dim_Time Table\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "# Use a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def generate_dim_time():\n",
    "    \"\"\"Generates the Dim_Time table.\"\"\"\n",
    "    # 修改起始年份为 2013\n",
    "    start_date = datetime.date(2013, 1, 1)\n",
    "    end_date = datetime.date(2025, 12, 31)\n",
    "    date_range = [start_date + datetime.timedelta(days=x) for x in range(0, (end_date - start_date).days + 1)]\n",
    "\n",
    "    data = []\n",
    "    time_id_counter = 1\n",
    "    for date in date_range:\n",
    "        # Generate the new Time_ID format (T + 7 digits)\n",
    "        time_id = f'T{time_id_counter:07d}'\n",
    "        \n",
    "        data.append([\n",
    "            time_id,\n",
    "            date,\n",
    "            date.year,\n",
    "            f\"Q{((date.month - 1) // 3) + 1}\",\n",
    "            date.month,\n",
    "            date.day,\n",
    "            date.isocalendar()[1],\n",
    "            date.isoweekday(),\n",
    "            date.strftime('%A')\n",
    "        ])\n",
    "        time_id_counter += 1\n",
    "    \n",
    "    return pd.DataFrame(data, columns=['Time_ID', 'Full_Date', 'Year', 'Quarter', 'Month', 'Day', 'Week_of_Year', 'Day_of_Week', 'Day_Name'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Generating Dim_Time table...\")\n",
    "    dim_time_df = generate_dim_time()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(\"Saving Dim_Time.csv...\")\n",
    "    dim_time_df.to_csv(os.path.join(output_dir, 'Dim_Time.csv'), index=False, encoding='utf-8')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Dim_Time.csv has been successfully generated with {len(dim_time_df):,} rows in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eea8d8-16b1-4f9d-85d7-fabef3cea65b",
   "metadata": {},
   "source": [
    "### **3/6: 生成 Dim_Customer 表 （修改性别和年龄分布）(相对静态数据)维度表更可能需要更新Update或追加Append。例如，一个客户的收入水平或家庭住址可能会发生变化，此时就需要更新Update或追加Append表中的相应记录。这种变化管理被称为“缓慢变化维度”（Slowly Changing Dimension, SCD）** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43821275-ac37-4dff-b170-3a76c42b4ba5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Dim_Customer table...\n",
      "Saving Dim_Customer.csv...\n",
      "Dim_Customer.csv has been successfully generated with 50015 rows in 0.97 seconds.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"3/6: Generate Dim_Customer Table\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Use a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def generate_dim_customer(num_customers=50000):\n",
    "    \"\"\"Generates the Dim_Customer table.\"\"\"\n",
    "    \n",
    "    # 调整性别分布，偏向男性\n",
    "    genders = ['Male', 'Female']\n",
    "    gender_probs = [0.75, 0.25] # Male: 75%, Female: 25%\n",
    "\n",
    "    # 调整年龄组分布，偏向中年群体\n",
    "    age_groups = ['<25', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "    age_probs = [0.05, 0.20, 0.35, 0.25, 0.10, 0.05]\n",
    "    \n",
    "    # 调整收入水平分布，偏向中高收入\n",
    "    income_levels = ['Low', 'Medium', 'High']\n",
    "    income_probs = [0.10, 0.80, 0.10]\n",
    "    \n",
    "    first_names = ['James', 'Mary', 'John', 'Patricia', 'Robert', 'Jennifer', 'Michael', 'Linda', 'William', 'Elizabeth', 'David', 'Susan', 'Richard', 'Jessica', 'Joseph', 'Sarah', 'Thomas', 'Karen', 'Charles', 'Nancy', 'Christopher', 'Lisa', 'Daniel', 'Betty', 'Paul', 'Margaret', 'Mark', 'Sandra', 'Donald', 'Ashley', 'George', 'Kimberly', 'Kenneth', 'Donna', 'Steven', 'Emily', 'Edward', 'Carol', 'Brian', 'Michelle', 'Ronald', 'Amanda', 'Anthony', 'Melissa', 'Kevin', 'Deborah', 'Jason', 'Stephanie', 'Jeff', 'Maria', 'Gary', 'Heather', 'Timothy', 'Nicole', 'Jose', 'Denise', 'Larry', 'Megan', 'Jeffrey', 'Christina', 'Frank', 'Alexis', 'Scott', 'Tiffany', 'Eric', 'Lauren', 'Stephen', 'Rachel', 'Andrew', 'Crystal', 'Raymond', 'Kayla', 'Ryan', 'Danielle', 'Jacob', 'Brittany', 'Nicholas', 'Emma', 'Jonathan', 'Samantha', 'Laura', 'Alexis', 'Joshua', 'Brandon', 'Justin', 'Daniel', 'Daniel', 'Taylor']\n",
    "    last_names = ['Smith', 'Johnson', 'Williams', 'Jones', 'Brown', 'Davis', 'Miller', 'Wilson', 'Moore', 'Taylor', 'Anderson', 'Thomas', 'Jackson', 'White', 'Harris', 'Martin', 'Thompson', 'Garcia', 'Martinez', 'Robinson', 'Clark', 'Rodriguez', 'Lewis', 'Lee', 'Walker', 'Hall', 'Allen', 'Young', 'Hernandez', 'King', 'Wright', 'Lopez', 'Hill', 'Scott', 'Green', 'Adams', 'Baker', 'Gonzalez', 'Nelson', 'Carter', 'Mitchell', 'Perez', 'Roberts', 'Turner', 'Phillips', 'Campbell', 'Parker', 'Evans', 'Edwards', 'Collins', 'Stewart', 'Sanchez', 'Morris', 'Rogers', 'Reed', 'Cook', 'Morgan', 'Bell', 'Murphy', 'Bailey', 'Rivera', 'Cooper', 'Richardson', 'Cox', 'Howard', 'Ward', 'Torres', 'Peterson', 'Gray', 'Ramirez', 'James', 'Watson', 'Brooks', 'Kelly', 'Sanders', 'Price', 'Bennett', 'Wood', 'Barnes', 'Ross', 'Henderson', 'Coleman', 'Jenkins', 'Perry', 'Powell', 'Long', 'Patterson', 'Hughes', 'Flores', 'Washington', 'Butler', 'Simmons', 'Foster', 'Gonzales', 'Bryant', 'Alexander', 'Russell', 'Griffin', 'Diaz', 'Hayes', 'Myers', 'Ford', 'Hamilton', 'Graham', 'Sullivan', 'Wallace', 'Woods', 'Cole', 'West', 'Jordan', 'Owens', 'Reynolds', 'Fisher', 'Ellis', 'Harrison', 'Gibson', 'Mcdonald', 'Cruz', 'Marshall', 'Ortiz', 'Gomez', 'Murray', 'Freeman', 'Wells', 'Webb', 'Simpson', 'Stevens', 'Tucker', 'Porter', 'Hunter', 'Hicks', 'Crawford', 'Henry', 'Boyd', 'Mason', 'Kennedy', 'Warren', 'Dixon', 'Ramos', 'Reid', 'Carr', 'Chavez', 'Gibson']\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # 跟踪每个组合的序号，确保不重复\n",
    "    combination_tracker = {}\n",
    "    \n",
    "    # 随机生成个人客户数据\n",
    "    for _ in range(num_customers):\n",
    "        full_name = f\"{random.choice(first_names)} {random.choice(last_names)}\"\n",
    "        \n",
    "        # 使用 np.random.choice 并指定概率\n",
    "        gender_raw = np.random.choice(genders, p=gender_probs)\n",
    "        age_group = np.random.choice(age_groups, p=age_probs)\n",
    "        income_level = np.random.choice(income_levels, p=income_probs)\n",
    "        \n",
    "        # 随机生成两个字母的国家和省/州代码\n",
    "        country_code = ''.join(random.choices(string.ascii_uppercase, k=2))\n",
    "        state_code = ''.join(random.choices(string.ascii_uppercase, k=2))\n",
    "        \n",
    "        # 编码 Customer_ID\n",
    "        gender_code = 'M' if gender_raw == 'Male' else 'W'\n",
    "        \n",
    "        # 构建组合前缀\n",
    "        prefix = f'C{gender_code}{country_code}{state_code}'\n",
    "        \n",
    "        # 获取并递增序号\n",
    "        if prefix not in combination_tracker:\n",
    "            combination_tracker[prefix] = 0\n",
    "        else:\n",
    "            combination_tracker[prefix] += 1\n",
    "            \n",
    "        # 序号部分为四位数字，从0000开始\n",
    "        sequential_id = f\"{combination_tracker[prefix] % 10000:04d}\"\n",
    "        \n",
    "        customer_id = f'{prefix}{sequential_id}'\n",
    "\n",
    "        data.append([customer_id, full_name, 'Individual', gender_raw, age_group, income_level, 'NA', 'NA', 'NA'])\n",
    "\n",
    "    individual_df = pd.DataFrame(data, columns=['Customer_ID', 'Customer_Name', 'Customer_Segment', 'Gender', 'Age_Group', 'Income_Level', 'Country', 'State_Province', 'City'])\n",
    "\n",
    "    # 新增业务客户数据，用于购买监管积分\n",
    "    business_customers = [\n",
    "        ['B001', 'General Motors', 'Business', 'NA', 'NA', 'NA', 'United States', 'Michigan', 'Detroit'],\n",
    "        ['B002', 'Ford Motor Company', 'Business', 'NA', 'NA', 'NA', 'United States', 'Michigan', 'Dearborn'],\n",
    "        ['B003', 'Toyota', 'Business', 'NA', 'NA', 'NA', 'Japan', 'Aichi', 'Toyota'],\n",
    "        ['B004', 'Volkswagen', 'Business', 'NA', 'NA', 'NA', 'Germany', 'Lower Saxony', 'Wolfsburg'],\n",
    "        ['B005', 'Stellantis', 'Business', 'NA', 'NA', 'NA', 'Netherlands', 'North Holland', 'Amsterdam'],\n",
    "        ['B006', 'Honda', 'Business', 'NA', 'NA', 'NA', 'Japan', 'Tokyo', 'Tokyo'],\n",
    "        ['B007', 'Nissan', 'Business', 'NA', 'NA', 'NA', 'Japan', 'Kanagawa', 'Yokohama'],\n",
    "        ['B008', 'Delta Air Lines', 'Business', 'NA', 'NA', 'NA', 'United States', 'Georgia', 'Atlanta'],\n",
    "        ['B009', 'United Airlines', 'Business', 'NA', 'NA', 'NA', 'United States', 'Illinois', 'Chicago'],\n",
    "        ['B010', 'American Airlines', 'Business', 'NA', 'NA', 'NA', 'United States', 'Texas', 'Fort Worth'],\n",
    "        ['B011', 'Shell', 'Business', 'NA', 'NA', 'NA', 'Netherlands', 'South Holland', 'The Hague'],\n",
    "        ['B012', 'ExxonMobil', 'Business', 'NA', 'NA', 'NA', 'United States', 'Texas', 'Irving'],\n",
    "        ['B013', 'BP', 'Business', 'NA', 'NA', 'NA', 'United Kingdom', 'Greater London', 'London'],\n",
    "        ['B014', 'Chevron', 'Business', 'NA', 'NA', 'NA', 'United States', 'California', 'San Ramon'],\n",
    "        ['B015', 'TotalEnergies', 'Business', 'NA', 'NA', 'NA', 'France', 'Île-de-France', 'Courbevoie'],\n",
    "    ]\n",
    "    \n",
    "    business_df = pd.DataFrame(business_customers, columns=['Customer_ID', 'Customer_Name', 'Customer_Segment', 'Gender', 'Age_Group', 'Income_Level', 'Country', 'State_Province', 'City'])\n",
    "\n",
    "    # 合并个人和业务客户数据\n",
    "    final_df = pd.concat([individual_df, business_df], ignore_index=True)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Generating Dim_Customer table...\")\n",
    "    dim_customer_df = generate_dim_customer()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(\"Saving Dim_Customer.csv...\")\n",
    "    dim_customer_df.to_csv(os.path.join(output_dir, 'Dim_Customer.csv'), index=False, encoding='utf-8')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Dim_Customer.csv has been successfully generated with {len(dim_customer_df)} rows in {end_time - start_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b9de72-6e92-4530-b9db-9157d15e5e35",
   "metadata": {},
   "source": [
    "### **4/6: 生成 Dim_Geography 表 （按大洲、国家编号）(相对静态数据)维度表更可能需要更新Update或追加Append。例如，一个客户的地址可能会发生变化或更新到新的国家和城市，此时就需要更新Update或追加Append表中的相应记录。这种变化管理被称为“缓慢变化维度”（Slowly Changing Dimension, SCD）** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84dffb53-8a63-4efa-a1c8-d66dd28d4d59",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Dim_Geography table...\n",
      "Saving Dim_Geography.csv...\n",
      "Dim_Geography.csv has been successfully generated with 432 rows in 0.01 seconds.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"4/6: Generate Dim_Geography Table\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Use a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def generate_plausible_zip(country):\n",
    "    \"\"\"Generates a plausible zip code based on the country, padded to 8 characters.\"\"\"\n",
    "    letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    digits = '0123456789'\n",
    "    \n",
    "    # 辅助函数，用于填充到8位\n",
    "    def pad_to_eight(s):\n",
    "        return (s + '0' * 8)[:8]\n",
    "\n",
    "    if country == 'United States':\n",
    "        return pad_to_eight(f\"{random.randint(10000, 99999)}\")\n",
    "    elif country == 'Canada':\n",
    "        # A1A 1A1 format (6 characters + 1 space)\n",
    "        code = f\"{random.choice(letters)}{random.choice(digits)}{random.choice(letters)} {random.choice(digits)}{random.choice(letters)}{random.choice(digits)}\"\n",
    "        return pad_to_eight(code.replace(' ', '')) # Remove space for 8-char ID, or keep for Zip_Code column\n",
    "    elif country == 'Mexico':\n",
    "        return pad_to_eight(f\"{random.randint(10000, 99999)}\")\n",
    "    elif country == 'United Kingdom':\n",
    "        # AN NAA or ANN NAA format\n",
    "        part1_letters = ''.join(random.choices(letters, k=random.choice([1, 2])))\n",
    "        part1_digits = ''.join(random.choices(digits, k=random.choice([1, 2])))\n",
    "        part2 = f\"{random.choice(digits)}{random.choice(letters)}{random.choice(letters)}\"\n",
    "        code = f\"{part1_letters}{part1_digits} {part2}\"\n",
    "        return pad_to_eight(code.replace(' ', ''))\n",
    "    elif country == 'France':\n",
    "        # 5 digits, but first is not zero\n",
    "        return pad_to_eight(f\"{random.randint(10000, 99999)}\")\n",
    "    elif country in ['Germany', 'Italy', 'Spain', 'Switzerland', 'Netherlands', 'Denmark', 'Norway', 'Sweden', 'Finland', 'Greece', 'Iceland', 'Ireland', 'Luxembourg', 'Monaco']:\n",
    "        # Most of Europe uses 5-digit numbers\n",
    "        return pad_to_eight(f\"{random.randint(10000, 99999)}\")\n",
    "    elif country == 'China':\n",
    "        # 6-digit numeric\n",
    "        return pad_to_eight(f\"{random.randint(100000, 999999)}\")\n",
    "    elif country == 'Japan':\n",
    "        # 7-digit numeric, often with a hyphen, so we generate and pad\n",
    "        return pad_to_eight(f\"{random.randint(1000000, 9999999)}\")\n",
    "    elif country in ['South Korea', 'Taiwan', 'Hong Kong', 'Macau']:\n",
    "        # 5-7 digit numeric\n",
    "        return pad_to_eight(f\"{random.randint(10000, 9999999)}\")\n",
    "    elif country == 'Australia':\n",
    "        # 4-digit numeric\n",
    "        return pad_to_eight(f\"{random.randint(1000, 9999)}\")\n",
    "    elif country == 'New Zealand':\n",
    "        # 4-digit numeric\n",
    "        return pad_to_eight(f\"{random.randint(1000, 9999)}\")\n",
    "    else:\n",
    "        return \"00000000\"\n",
    "\n",
    "def generate_dim_geography():\n",
    "    \"\"\"\n",
    "    Generates a Dim_Geography table.\n",
    "    \"\"\"\n",
    "    geography_data = []\n",
    "    \n",
    "    # Continent codes for the new Geo_ID\n",
    "    continent_codes = {\n",
    "        'North America': 'NA',\n",
    "        'Europe': 'EU',\n",
    "        'Asia': 'AS',\n",
    "        'Oceania': 'OC'\n",
    "    }\n",
    "    \n",
    "    # North America\n",
    "    north_america_countries = {\n",
    "        'United States': {\n",
    "            'code': 'US',\n",
    "            'provinces': [\n",
    "                'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut',\n",
    "                'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa',\n",
    "                'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan',\n",
    "                'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire',\n",
    "                'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio',\n",
    "                'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota',\n",
    "                'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia',\n",
    "                'Wisconsin', 'Wyoming'\n",
    "            ]\n",
    "        },\n",
    "        'Canada': {\n",
    "            'code': 'CA',\n",
    "            'provinces': [\n",
    "                'Alberta', 'British Columbia', 'Manitoba', 'New Brunswick', 'Newfoundland and Labrador',\n",
    "                'Nova Scotia', 'Ontario', 'Prince Edward Island', 'Québec', 'Saskatchewan',\n",
    "                'Northwest Territories', 'Nunavut', 'Yukon'\n",
    "            ]\n",
    "        },\n",
    "        'Mexico': {\n",
    "            'code': 'MX',\n",
    "            'provinces': [\n",
    "                'Aguascalientes', 'Baja California', 'Baja California Sur', 'Campeche', 'Chiapas',\n",
    "                'Chihuahua', 'Coahuila', 'Colima', 'Durango', 'Guanajuato', 'Guerrero', 'Hidalgo',\n",
    "                'Jalisco', 'México', 'Distrito Federal', 'Michoacán', 'Morelos', 'Nayarit',\n",
    "                'Nuevo León', 'Oaxaca', 'Puebla', 'Querétaro', 'Quintana Roo', 'San Luis Potosí',\n",
    "                'Sinaloa', 'Sonora', 'Tabasco', 'Tamaulipas', 'Tlaxcala', 'Veracruz', 'Yucatán', 'Zacatecas'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Europe\n",
    "    europe_countries = {\n",
    "        'Germany': {\n",
    "            'code': 'DE',\n",
    "            'provinces': [\n",
    "                'Baden-Württemberg', 'Bavaria', 'Berlin', 'Brandenburg', 'Bremen', 'Hamburg',\n",
    "                'Hesse', 'Lower Saxony', 'Mecklenburg-Vorpommern', 'North Rhine-Westphalia',\n",
    "                'Rhineland-Palatinate', 'Saarland', 'Saxony', 'Saxony-Anhalt',\n",
    "                'Schleswig-Holstein', 'Thuringia'\n",
    "            ]\n",
    "        },\n",
    "        'United Kingdom': {\n",
    "            'code': 'GB',\n",
    "            'provinces': [\n",
    "                'England', 'Scotland', 'Wales', 'Northern Ireland'\n",
    "            ]\n",
    "        },\n",
    "        'Norway': {'code': 'NO', 'provinces': ['Oslo', 'Viken', 'Innlandet', 'Vestfold og Telemark', 'Agder', 'Rogaland', 'Vestland', 'Møre og Romsdal', 'Trøndelag', 'Nordland', 'Troms og Finnmark']},\n",
    "        'France': {'code': 'FR', 'provinces': ['Bretagne', 'Normandie', 'Île-de-France', 'Auvergne-Rhône-Alpes', 'Bourgogne-Franche-Comté', 'Centre-Val de Loire', 'Corsica', 'Grand Est', 'Hauts-de-France', 'Nouvelle-Aquitaine', 'Occitanie', 'Pays de la Loire', 'Provence-Alpes-Côte d\\'Azur']},\n",
    "        'Netherlands': {'code': 'NL', 'provinces': ['Drenthe', 'Flevoland', 'Friesland', 'Gelderland', 'Groningen', 'Limburg', 'North Brabant', 'North Holland', 'Overijssel', 'Utrecht', 'Zeeland', 'South Holland']},\n",
    "        'Sweden': {'code': 'SE', 'provinces': ['Blekinge', 'Dalarna', 'Gotland', 'Gävleborg', 'Halland', 'Jämtland', 'Jönköping', 'Kalmar', 'Kronoberg', 'Norrbotten', 'Skåne', 'Stockholm', 'Södermanland', 'Uppsala', 'Värmland', 'Västerbotten', 'Västernorrland', 'Västmanland', 'Västra Götaland', 'Örebro', 'Östergötland']},\n",
    "        'Switzerland': {'code': 'CH', 'provinces': ['Zurich', 'Bern', 'Lucerne', 'Uri', 'Schwyz', 'Obwalden', 'Nidwalden', 'Glarus', 'Zug', 'Fribourg', 'Solothurn', 'Basel-Stadt', 'Basel-Landschaft', 'Schaffhausen', 'Appenzell Ausserrhoden', 'Appenzell Innerrhoden', 'St. Gallen', 'Graubünden', 'Aargau', 'Thurgau', 'Ticino', 'Vaud', 'Valais', 'Neuchâtel', 'Geneva', 'Jura']},\n",
    "        'Italy': {'code': 'IT', 'provinces': ['Abruzzo', 'Aosta Valley', 'Apulia', 'Basilicata', 'Calabria', 'Campania', 'Emilia-Romagna', 'Friuli-Venezia Giulia', 'Lazio', 'Liguria', 'Lombardy', 'Marche', 'Molise', 'Piedmont', 'Sardinia', 'Sicily', 'Tuscany', 'Trentino-Alto Adige', 'Umbria', 'Veneto']},\n",
    "        'Spain': {'code': 'ES', 'provinces': ['Andalusia', 'Aragon', 'Principality of Asturias', 'Balearic Islands', 'Basque Country', 'Canary Islands', 'Cantabria', 'Castile and León', 'Castile-La Mancha', 'Catalonia', 'Community of Madrid', 'Valencian Community', 'Extremadura', 'Galicia', 'La Rioja', 'Region of Murcia', 'Foral Community of Navarre']},\n",
    "        'Denmark': {'code': 'DK', 'provinces': ['Capital Region of Denmark', 'Central Denmark Region', 'North Denmark Region', 'Region Zealand', 'Region of Southern Denmark']},\n",
    "        'Finland': {'code': 'FI', 'provinces': ['Åland Islands', 'Central Finland', 'Central Ostrobothnia', 'Kainuu', 'Kymenlaakso', 'Lapland', 'North Karelia', 'North Ostrobothnia', 'Northern Savonia', 'Päijät-Häme', 'Pirkanmaa', 'Satakunta', 'South Karelia', 'Southern Ostrobothnia', 'Southern Savonia', 'Tavastia Proper', 'Uusimaa', 'Southwest Finland']},\n",
    "        'Greece': {'code': 'GR', 'provinces': ['Attica', 'Central Greece', 'Central Macedonia', 'Crete', 'East Macedonia and Thrace', 'Epirus', 'Ionian Islands', 'North Aegean', 'Peloponnese', 'South Aegean', 'Thessaly', 'West Greece', 'West Macedonia']},\n",
    "        'Iceland': {'code': 'IS', 'provinces': ['Capital Region', 'Southern Peninsula', 'Western Region', 'Westfjords', 'Northwest Region', 'Northeast Region', 'Eastern Region', 'Southern Region']},\n",
    "        'Ireland': {'code': 'IE', 'provinces': ['Connacht', 'Leinster', 'Munster', 'Ulster']},\n",
    "        'Luxembourg': {'code': 'LU', 'provinces': ['Diekirch', 'Grevenmacher', 'Luxembourg']},\n",
    "        'Monaco': {'code': 'MC', 'provinces': ['Monaco']}\n",
    "    }\n",
    "    \n",
    "    # Asia\n",
    "    asia_countries = {\n",
    "        'China': {\n",
    "            'code': 'CN',\n",
    "            'provinces': [\n",
    "                'Anhui', 'Fujian', 'Gansu', 'Guangdong', 'Guizhou', 'Hainan', 'Hebei', 'Heilongjiang',\n",
    "                'Henan', 'Hubei', 'Hunan', 'Jiangsu', 'Jiangxi', 'Jilin', 'Liaoning', 'Qinghai',\n",
    "                'Shaanxi', 'Shandong', 'Shanxi', 'Sichuan', 'Yunnan', 'Zhejiang',\n",
    "                'Guangxi', 'Nei Mongol', 'Ningxia Hui', 'Xinjiang Uygur', 'Xizang',\n",
    "                'Beijing', 'Chongqing', 'Shanghai', 'Tianjin'\n",
    "            ]\n",
    "        },\n",
    "        'Hong Kong': {'code': 'HK', 'provinces': ['Hong Kong Island', 'Kowloon', 'New Territories']},\n",
    "        'Macau': {'code': 'MO', 'provinces': ['Macau']},\n",
    "        'Japan': {\n",
    "            'code': 'JP',\n",
    "            'provinces': [\n",
    "                'Hokkaido', 'Aomori', 'Iwate', 'Miyagi', 'Akita', 'Yamagata', 'Fukushima',\n",
    "                'Ibaraki', 'Tochigi', 'Gunma', 'Saitama', 'Chiba', 'Tokyo', 'Kanagawa',\n",
    "                'Niigata', 'Toyama', 'Ishikawa', 'Fukui', 'Yamanashi', 'Nagano',\n",
    "                'Gifu', 'Shizuoka', 'Aichi', 'Mie', 'Shiga', 'Kyoto', 'Osaka',\n",
    "                'Hyōgo', 'Nara', 'Wakayama', 'Tottori', 'Shimane', 'Okayama',\n",
    "                'Hiroshima', 'Yamaguchi', 'Tokushima', 'Kagawa', 'Ehime', 'Kochi',\n",
    "                'Fukuoka', 'Saga', 'Naoasaki', 'Kumamoto', 'Oita', 'Miyazaki', 'Kagoshima', 'Okinawa'\n",
    "            ]\n",
    "        },\n",
    "        'South Korea': {\n",
    "            'code': 'KR',\n",
    "            'provinces': [\n",
    "                'Busan', 'Chungcheongbuk-do', 'Chungcheongnam-do', 'Daegu', 'Daejeon', 'Gangwon-do',\n",
    "                'Gwangju', 'Gyeonggi-do', 'Gyeongsangbuk-do', 'Gyeongsangnam-do', 'Incheon', 'Jeollabuk-do',\n",
    "                'Jeollanam-do', 'Sejong', 'Seoul', 'Ulsan', 'Jeju'\n",
    "            ]\n",
    "        },\n",
    "        'Taiwan': {\n",
    "            'code': 'TW',\n",
    "            'provinces': [\n",
    "                'Taipei', 'New Taipei', 'Taichung', 'Tainan', 'Kaohsiung', 'Taoyuan',\n",
    "                'Keelung', 'Hsinchu City', 'Chiayi City', 'Hsinchu County', 'Chiayi County',\n",
    "                'Changhua', 'Nantou', 'Yulin', 'Miaoli', 'Pingtung', 'Yilan', 'Hualien',\n",
    "                'Taitung', 'Penghu', 'Kinmen', 'Lienkiang'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Oceania\n",
    "    oceania_countries = {\n",
    "        'Australia': {\n",
    "            'code': 'AU',\n",
    "            'provinces': [\n",
    "                'New South Wales', 'Victoria', 'Queensland', 'South Australia', 'Western Australia',\n",
    "                'Tasmania', 'Australian Capital Territory', 'Northern Territory'\n",
    "            ]\n",
    "        },\n",
    "        'New Zealand': {\n",
    "            'code': 'NZ',\n",
    "            'provinces': [\n",
    "                'Auckland', 'Bay of Plenty', 'Canterbury', 'Gisborne', 'Hawke\\'s Bay',\n",
    "                'Manawatu-Wanganui', 'Marlborough', 'Nelson', 'Northland', 'Otago',\n",
    "                'Southland', 'Taranaki', 'Tasman', 'Waikato', 'Wellington', 'West Coast'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    continents = {\n",
    "        'North America': north_america_countries,\n",
    "        'Europe': europe_countries,\n",
    "        'Asia': asia_countries,\n",
    "        'Oceania': oceania_countries\n",
    "    }\n",
    "\n",
    "    for continent, countries in continents.items():\n",
    "        for country, details in countries.items():\n",
    "            state_id = 1\n",
    "            for province in details['provinces']:\n",
    "                # The state abbreviation logic needs to be robust for all cases.\n",
    "                state_abbr_words = province.split(' ')\n",
    "                state_abbr_raw = ''.join([word[0].upper() for word in state_abbr_words if word[0].isalpha()]).ljust(2, 'X')\n",
    "                \n",
    "                # Create a reliable 2-letter abbreviation\n",
    "                state_abbr = state_abbr_raw[:2]\n",
    "\n",
    "                # Create the new 8-character Geo_ID\n",
    "                geo_id = f\"{continent_codes[continent]}{details['code']}{state_abbr}{state_id:02d}\"\n",
    "\n",
    "                geography_data.append([\n",
    "                    geo_id,\n",
    "                    continent,\n",
    "                    country,\n",
    "                    details['code'],\n",
    "                    province,\n",
    "                    generate_plausible_zip(country)\n",
    "                ])\n",
    "                state_id += 1\n",
    "\n",
    "    dim_geography_df = pd.DataFrame(geography_data, columns=[\n",
    "        'Geo_ID', 'Continent', 'Country', 'Country_Code', 'State_Province', 'Zip_Code'\n",
    "    ])\n",
    "    \n",
    "    return dim_geography_df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Generating Dim_Geography table...\")\n",
    "    dim_geography_df = generate_dim_geography()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(\"Saving Dim_Geography.csv...\")\n",
    "    # Using 'utf-8-sig' encoding to ensure proper display of non-English characters in Excel.\n",
    "    # This adds a BOM (Byte Order Mark) to the file, which helps applications\n",
    "    # correctly identify the encoding.\n",
    "    dim_geography_df.to_csv(os.path.join(output_dir, 'Dim_Geography.csv'), index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Dim_Geography.csv has been successfully generated with {len(dim_geography_df)} rows in {end_time - start_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5e4897-3e37-49ec-916d-e38386464c31",
   "metadata": {},
   "source": [
    "### **5/6: 生成 Dim_Prices 表 (相对静态数据)维度表更可能需要更新Update或追加Append。例如，新产品或不同时段价格可能会发生变化，此时就需要更新或追加Append表中的相应记录。这种变化管理被称为“缓慢变化维度”（Slowly Changing Dimension, SCD）** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e3387e8-e364-4367-a5f7-45052df60898",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在生成 Dim_Prices 表...\n",
      "保存 Dim_Prices.csv...\n",
      "Dim_Prices.csv 已成功生成！\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Generate Dim_Prices Table\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Use a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def generate_dim_prices():\n",
    "    \"\"\"\n",
    "    Generates the Dim_Prices table with prices for different vehicle models and time periods.\n",
    "    \"\"\"\n",
    "    start_date = datetime(2013, 1, 1)\n",
    "    end_date = datetime(2025, 6, 30)\n",
    "\n",
    "    price_data = []\n",
    "\n",
    "    # 定义不同车型的基础价格\n",
    "    # 价格基于公开数据和市场趋势估算\n",
    "    base_prices = {\n",
    "        1: 75000,  # Model S\n",
    "        2: 80000,  # Model X\n",
    "        3: 40000,  # Model 3\n",
    "        4: 50000,  # Model Y\n",
    "        5: 120000, # Cybertruck\n",
    "    }\n",
    "    \n",
    "    # 定义产品ID的映射，使其与产品维度表格式一致\n",
    "    product_id_mapping = {\n",
    "        1: 'PRO001',\n",
    "        2: 'PRO002',\n",
    "        3: 'PRO003',\n",
    "        4: 'PRO004',\n",
    "        5: 'PRO005',\n",
    "    }\n",
    "\n",
    "    # 手动添加 2013-2018 年的价格数据以确保销售数据生成准确\n",
    "    # Model S (Product_ID = 1)\n",
    "    price_data.append({'Quarter_Start_Date': datetime(2013, 1, 1), 'Product_ID': product_id_mapping[1], 'Standard_Price_USD': 75000, 'Discounted_Price_USD': 75000})\n",
    "    price_data.append({'Quarter_Start_Date': datetime(2013, 4, 1), 'Product_ID': product_id_mapping[1], 'Standard_Price_USD': 75000, 'Discounted_Price_USD': 75000})\n",
    "    price_data.append({'Quarter_Start_Date': datetime(2013, 7, 1), 'Product_ID': product_id_mapping[1], 'Standard_Price_USD': 75000, 'Discounted_Price_USD': 75000})\n",
    "    price_data.append({'Quarter_Start_Date': datetime(2013, 10, 1), 'Product_ID': product_id_mapping[1], 'Standard_Price_USD': 75000, 'Discounted_Price_USD': 75000})\n",
    "\n",
    "    # Model X (Product_ID = 2) 在2015年末发布\n",
    "    # Model 3 (Product_ID = 3) 在2017年中发布\n",
    "    # Model Y (Product_ID = 4) 在2020年初发布\n",
    "    # Cybertruck (Product_ID = 5) 在2023年末发布\n",
    "    \n",
    "    # 填充 2014-2018 年的价格\n",
    "    for year in range(2014, 2019):\n",
    "        for month in [1, 4, 7, 10]:\n",
    "            quarter_start = datetime(year, month, 1)\n",
    "            # Model S 价格小幅波动\n",
    "            price_s = base_prices[1] + np.random.randint(-2000, 2000)\n",
    "            price_data.append({'Quarter_Start_Date': quarter_start, 'Product_ID': product_id_mapping[1], 'Standard_Price_USD': price_s, 'Discounted_Price_USD': price_s})\n",
    "\n",
    "            # Model X\n",
    "            if year >= 2015 and quarter_start >= datetime(2015, 9, 1):\n",
    "                price_x = base_prices[2] + np.random.randint(-2000, 2000)\n",
    "                price_data.append({'Quarter_Start_Date': quarter_start, 'Product_ID': product_id_mapping[2], 'Standard_Price_USD': price_x, 'Discounted_Price_USD': price_x})\n",
    "\n",
    "            # Model 3\n",
    "            if year >= 2017 and quarter_start >= datetime(2017, 7, 1):\n",
    "                price_3 = base_prices[3] + np.random.randint(-1000, 1000)\n",
    "                price_data.append({'Quarter_Start_Date': quarter_start, 'Product_ID': product_id_mapping[3], 'Standard_Price_USD': price_3, 'Discounted_Price_USD': price_3})\n",
    "\n",
    "    # 填充 2019 年至今的价格，并引入价格波动和折扣\n",
    "    current_date = datetime(2019, 1, 1)\n",
    "    while current_date <= end_date:\n",
    "        for product_id, base_price in base_prices.items():\n",
    "            if (product_id == 4 and current_date < datetime(2020, 1, 1)) or \\\n",
    "               (product_id == 5 and current_date < datetime(2023, 11, 1)):\n",
    "                continue\n",
    "\n",
    "            # 模拟价格波动（5%以内的随机波动）\n",
    "            price_std = base_price * (1 + random.uniform(-0.05, 0.05))\n",
    "            price_dis = price_std\n",
    "\n",
    "            # 模拟折扣（约20%的记录有折扣）\n",
    "            if random.random() < 0.20:\n",
    "                discount_rate = random.uniform(0.01, 0.15)\n",
    "                price_dis = price_std * (1 - discount_rate)\n",
    "            \n",
    "            price_data.append({\n",
    "                'Quarter_Start_Date': current_date,\n",
    "                'Product_ID': product_id_mapping[product_id],\n",
    "                'Standard_Price_USD': round(price_std, 2),\n",
    "                'Discounted_Price_USD': round(price_dis, 2)\n",
    "            })\n",
    "\n",
    "        # 移动到下一个季度\n",
    "        if current_date.month == 10:\n",
    "            current_date = current_date.replace(year=current_date.year + 1, month=1)\n",
    "        else:\n",
    "            current_date = current_date.replace(month=current_date.month + 3)\n",
    "\n",
    "    dim_prices_df = pd.DataFrame(price_data)\n",
    "\n",
    "    # 格式化日期列\n",
    "    dim_prices_df['Quarter_Start_Date'] = pd.to_datetime(dim_prices_df['Quarter_Start_Date']).dt.date\n",
    "\n",
    "    # 生成 Price_ID，格式为 PRI###\n",
    "    price_ids = [f'PRI{i:03d}' for i in range(1, len(dim_prices_df) + 1)]\n",
    "    dim_prices_df['Price_ID'] = price_ids\n",
    "    \n",
    "    # 重新排序列以匹配您的要求\n",
    "    dim_prices_df = dim_prices_df[['Price_ID', 'Product_ID', 'Quarter_Start_Date', 'Standard_Price_USD', 'Discounted_Price_USD']]\n",
    "    \n",
    "    return dim_prices_df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"正在生成 Dim_Prices 表...\")\n",
    "    dim_prices_df = generate_dim_prices()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    print(\"保存 Dim_Prices.csv...\")\n",
    "    dim_prices_df.to_csv(os.path.join(output_dir, 'Dim_Prices.csv'), index=False, encoding='utf-8')\n",
    "    print(\"Dim_Prices.csv 已成功生成！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b18d6ee-49f0-4cf2-8fef-d2b9bb9f345f",
   "metadata": {},
   "source": [
    "### **6/6: 生成 Fact_Sales 表 （没有空白营收行 追加到2013）(高度动态数据，最常被追加（append）的表) 只进不出”的设计哲学。每当一笔新的销售发生，就在 Fact_Sales 表中追加一行新的数据，而不会去修改之前已经存在的历史销售记录** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "465a0f68-6f1f-4435-93e7-17243ecf80e4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载所有维度表...\n",
      "已移除旧的 Fact_Sales.csv 文件。\n",
      "正在生成 Fact_Sales 表...\n",
      "正在为年份 2013 第 1 季度生成 4,750 条销售记录...\n",
      "正在为年份 2013 第 2 季度生成 5,150 条销售记录...\n",
      "正在为年份 2013 第 3 季度生成 5,800 条销售记录...\n",
      "正在为年份 2013 第 4 季度生成 6,742 条销售记录...\n",
      "正在为年份 2014 第 1 季度生成 6,450 条销售记录...\n",
      "正在为年份 2014 第 2 季度生成 7,570 条销售记录...\n",
      "正在为年份 2014 第 3 季度生成 8,800 条销售记录...\n",
      "正在为年份 2014 第 4 季度生成 8,835 条销售记录...\n",
      "正在为年份 2015 第 1 季度生成 10,045 条销售记录...\n",
      "正在为年份 2015 第 2 季度生成 11,532 条销售记录...\n",
      "正在为年份 2015 第 3 季度生成 11,584 条销售记录...\n",
      "正在为年份 2015 第 4 季度生成 17,356 条销售记录...\n",
      "正在为年份 2016 第 1 季度生成 14,810 条销售记录...\n",
      "正在为年份 2016 第 2 季度生成 18,345 条销售记录...\n",
      "正在为年份 2016 第 3 季度生成 24,500 条销售记录...\n",
      "正在为年份 2016 第 4 季度生成 18,588 条销售记录...\n",
      "正在为年份 2017 第 1 季度生成 25,418 条销售记录...\n",
      "正在为年份 2017 第 2 季度生成 22,000 条销售记录...\n",
      "正在为年份 2017 第 3 季度生成 26,135 条销售记录...\n",
      "正在为年份 2017 第 4 季度生成 29,538 条销售记录...\n",
      "正在为年份 2018 第 1 季度生成 29,980 条销售记录...\n",
      "正在为年份 2018 第 2 季度生成 40,740 条销售记录...\n",
      "正在为年份 2018 第 3 季度生成 83,780 条销售记录...\n",
      "正在为年份 2018 第 4 季度生成 90,991 条销售记录...\n",
      "正在为年份 2019 第 1 季度生成 67,927 条销售记录...\n",
      "正在为年份 2019 第 2 季度生成 94,988 条销售记录...\n",
      "正在为年份 2019 第 3 季度生成 94,284 条销售记录...\n",
      "正在为年份 2019 第 4 季度生成 110,455 条销售记录...\n",
      "正在为年份 2020 第 1 季度生成 109,609 条销售记录...\n",
      "正在为年份 2020 第 2 季度生成 89,940 条销售记录...\n",
      "正在为年份 2020 第 3 季度生成 134,535 条销售记录...\n",
      "正在为年份 2020 第 4 季度生成 165,449 条销售记录...\n",
      "正在为年份 2021 第 1 季度生成 173,707 条销售记录...\n",
      "正在为年份 2021 第 2 季度生成 201,990 条销售记录...\n",
      "正在为年份 2021 第 3 季度生成 241,730 条销售记录...\n",
      "正在为年份 2021 第 4 季度生成 318,792 条销售记录...\n",
      "正在为年份 2022 第 1 季度生成 303,274 条销售记录...\n",
      "正在为年份 2022 第 2 季度生成 267,227 条销售记录...\n",
      "正在为年份 2022 第 3 季度生成 347,669 条销售记录...\n",
      "正在为年份 2022 第 4 季度生成 395,680 条销售记录...\n",
      "正在为年份 2023 第 1 季度生成 434,885 条销售记录...\n",
      "正在为年份 2023 第 2 季度生成 470,384 条销售记录...\n",
      "正在为年份 2023 第 3 季度生成 428,066 条销售记录...\n",
      "正在为年份 2023 第 4 季度生成 475,245 条销售记录...\n",
      "正在为年份 2024 第 1 季度生成 406,328 条销售记录...\n",
      "正在为年份 2024 第 2 季度生成 457,427 条销售记录...\n",
      "正在为年份 2024 第 3 季度生成 464,858 条销售记录...\n",
      "正在为年份 2024 第 4 季度生成 460,612 条销售记录...\n",
      "正在为年份 2025 第 1 季度生成 324,476 条销售记录...\n",
      "正在为年份 2025 第 2 季度生成 396,326 条销售记录...\n",
      "Fact_Sales.csv 已成功生成 7,965,302 行数据，耗时 171.40 秒。\n",
      "数据生成完成！\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Generate Fact_Sales Table (CPU Version)\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "\n",
    "def generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath):\n",
    "    \"\"\"\n",
    "    Generates the Fact_Sales table by combining all dimension tables.\n",
    "    Uses real-world Tesla sales distribution and volume data for realistic output.\n",
    "    \"\"\"\n",
    "    end_date = datetime(2025, 6, 30)\n",
    "\n",
    "    # 季度总营收数据 (单位: 10亿 USD)\n",
    "    quarterly_total_revenue = {\n",
    "        # 2013-2018年的数据根据提供的图片分配\n",
    "        (2013, 1): 0.4e9, (2013, 2): 0.45e9, (2013, 3): 0.53e9, (2013, 4): 0.63e9,\n",
    "        (2014, 1): 0.65e9, (2014, 2): 0.75e9, (2014, 3): 0.85e9, (2014, 4): 0.95e9,\n",
    "        (2015, 1): 0.8e9, (2015, 2): 0.9e9, (2015, 3): 1.0e9, (2015, 4): 1.35e9,\n",
    "        (2016, 1): 1.4e9, (2016, 2): 1.6e9, (2016, 3): 1.9e9, (2016, 4): 2.1e9,\n",
    "        (2017, 1): 2.3e9, (2017, 2): 2.6e9, (2017, 3): 3.0e9, (2017, 4): 3.86e9,\n",
    "        (2018, 1): 4.1e9, (2018, 2): 4.9e9, (2018, 3): 5.8e9, (2018, 4): 6.66e9,\n",
    "        # 2019-2025年季度总营收，严格按照用户提供的财报数据\n",
    "        (2019, 1): 4.541e9, (2019, 2): 6.350e9, (2019, 3): 6.303e9, (2019, 4): 7.384e9,\n",
    "        (2020, 1): 5.985e9, (2020, 2): 6.036e9, (2020, 3): 8.771e9, (2020, 4): 10.744e9,\n",
    "        (2021, 1): 10.389e9, (2021, 2): 11.958e9, (2021, 3): 13.757e9, (2021, 4): 17.719e9,\n",
    "        (2022, 1): 18.756e9, (2022, 2): 16.934e9, (2022, 3): 21.454e9, (2022, 4): 24.318e9,\n",
    "        (2023, 1): 23.329e9, (2023, 2): 24.927e9, (2023, 3): 23.350e9, (2023, 4): 25.167e9,\n",
    "        (2024, 1): 21.301e9, (2024, 2): 25.500e9, (2024, 3): 25.182e9, (2024, 4): 25.707e9,\n",
    "        (2025, 1): 19.335e9, (2025, 2): 22.496e9\n",
    "    }\n",
    "    \n",
    "    # 季度汽车销售营收数据 (单位: 10亿 USD)，严格按照用户提供的财报数据\n",
    "    quarterly_automotive_revenue = {\n",
    "        (2019, 1): 4.541e9, (2019, 2): 6.350e9, (2019, 3): 6.303e9, (2019, 4): 7.384e9,\n",
    "        (2020, 1): 5.985e9, (2020, 2): 4.911e9, (2020, 3): 7.346e9, (2020, 4): 9.034e9,\n",
    "        (2021, 1): 8.187e9, (2021, 2): 9.520e9, (2021, 3): 11.393e9, (2021, 4): 15.025e9,\n",
    "        (2022, 1): 15.514e9, (2022, 2): 13.670e9, (2022, 3): 17.785e9, (2022, 4): 20.241e9,\n",
    "        (2023, 1): 18.878e9, (2023, 2): 20.419e9, (2023, 3): 18.582e9, (2023, 4): 20.630e9,\n",
    "        (2024, 1): 16.460e9, (2024, 2): 18.530e9, (2024, 3): 18.831e9, (2024, 4): 18.659e9,\n",
    "        (2025, 1): 12.925e9, (2025, 2): 15.787e9\n",
    "    }\n",
    "\n",
    "    # 年度交付量数据，已根据你提供的实际历史数据更新\n",
    "    unit_targets_by_year = {\n",
    "        2013: 22442, 2014: 31655, 2015: 50517, 2016: 76243, 2017: 103091,\n",
    "        2018: 245491, 2019: 367656, 2020: 499535, 2021: 936222, 2022: 1313851,\n",
    "        2023: 1808581, 2024: 1789226\n",
    "    }\n",
    "    unit_targets_by_year[2025] = 336681 + 384122\n",
    "    \n",
    "    # 2013-2018年季度交付量手动分配\n",
    "    quarterly_unit_splits = {\n",
    "        2013: {1: 4750, 2: 5150, 3: 5800, 4: 6742},\n",
    "        2014: {1: 6450, 2: 7570, 3: 8800, 4: 8835},\n",
    "        2015: {1: 10045, 2: 11532, 3: 11584, 4: 17356},\n",
    "        2016: {1: 14810, 2: 18345, 3: 24500, 4: 18588},\n",
    "        2017: {1: 25418, 2: 22000, 3: 26135, 4: 29538},\n",
    "        2018: {1: 29980, 2: 40740, 3: 83780, 4: 90991}\n",
    "    }\n",
    "\n",
    "    # --------------------------\n",
    "    # 步骤 1: 数据清洗和预处理\n",
    "    # --------------------------\n",
    "    if 'Product_Name' not in dim_product_df.columns:\n",
    "        print(\"警告：Dim_Product.csv中缺少'Product_Name'列，正在根据Product_ID创建。\")\n",
    "        product_id_to_name = {\n",
    "            'PRO001': 'Model S', 'PRO002': 'Model X', 'PRO003': 'Model 3', 'PRO004': 'Model Y', 'PRO005': 'Cybertruck'\n",
    "        }\n",
    "        dim_product_df['Product_Name'] = dim_product_df['Product_ID'].map(product_id_to_name).fillna('Other')\n",
    "    \n",
    "    # 补全国家列表，确保数据更真实\n",
    "    asia_countries = ['China', 'Japan', 'South Korea', 'Singapore', 'India', 'Indonesia', 'Thailand', 'Malaysia', 'Taiwan']\n",
    "    oceania_countries = ['Australia', 'New Zealand']\n",
    "    europe_countries = ['Germany', 'United Kingdom', 'France', 'Norway', 'Netherlands', 'Sweden', 'Italy', 'Switzerland', 'Spain', 'Belgium', 'Austria', 'Denmark', 'Finland', 'Portugal', 'Ireland', 'Luxembourg', 'Iceland']\n",
    "    \n",
    "    def get_continent(country):\n",
    "        if country in asia_countries: return 'Asia'\n",
    "        if country in oceania_countries: return 'Oceania'\n",
    "        if country in europe_countries: return 'Europe'\n",
    "        return 'North America'\n",
    "        \n",
    "    dim_geography_df['Continent'] = dim_geography_df['Country'].apply(get_continent).astype(str)\n",
    "\n",
    "    # --------------------------\n",
    "    # 步骤 2: 定义权重\n",
    "    # --------------------------\n",
    "    # 调整产品权重，使其更符合实际销售情况\n",
    "    product_weights_by_name = {\n",
    "        'Model S': 0.05, 'Model X': 0.05, 'Model 3': 0.45, 'Model Y': 0.40, 'Cybertruck': 0.05\n",
    "    }\n",
    "    \n",
    "    # 定义大陆、国家、省份的权重，并提供默认值\n",
    "    continent_weights = {'North America': 0.45, 'Europe': 0.30, 'Asia': 0.23, 'Oceania': 0.02}\n",
    "    country_weights = {'United States': 0.80, 'Canada': 0.20, 'China': 0.70, 'Japan': 0.18, 'South Korea': 0.13, 'Germany': 0.30, 'United Kingdom': 0.20, 'France': 0.15, 'Norway': 0.10, 'Australia': 0.75, 'New Zealand': 0.25, 'Taiwan': 0.1}\n",
    "    state_province_weights = {\n",
    "        'California': 0.40, 'Texas': 0.25, 'Florida': 0.15, 'Washington': 0.10, 'New York': 0.10,\n",
    "        'Ontario': 0.4, 'Quebec': 0.25, 'British Columbia': 0.2, 'Alberta': 0.15,\n",
    "        'Shanghai': 0.50, 'Beijing': 0.20, 'Guangdong': 0.20, 'Zhejiang': 0.10,\n",
    "        'Taipei': 0.5, 'New Taipei City': 0.2, 'Taichung': 0.1, 'Kaohsiung': 0.1, 'Tainan': 0.05, 'Taoyuan': 0.05,\n",
    "        'Bavaria': 0.40, 'North Rhine-Westphalia': 0.25, 'Baden-Württemberg': 0.15, 'Berlin': 0.10,\n",
    "        'Greater London': 0.50, 'South East England': 0.25, 'North West England': 0.15, 'West Midlands': 0.10,\n",
    "        'Île-de-France': 0.60, 'Auvergne-Rhône-Alpes': 0.20, 'Nouvelle-Aquitaine': 0.10, 'Provence-Alpes-Côte d\\'Azur': 0.10,\n",
    "        'Oslo': 0.70, 'Vestland': 0.15, 'Viken': 0.10, 'Trøndelag': 0.05,\n",
    "        'New South Wales': 0.5, 'Victoria': 0.3, 'Queensland': 0.1, 'Western Australia': 0.05, 'South Australia': 0.05,\n",
    "        'Auckland': 0.6, 'Wellington': 0.2, 'Canterbury': 0.1, 'Otago': 0.05, 'Waikato': 0.05,\n",
    "    }\n",
    "\n",
    "    # 预计算所有 Geo_ID 的权重\n",
    "    dim_geography_df['Geo_Weight'] = 0.0\n",
    "    for continent, c_weight in continent_weights.items():\n",
    "        countries_in_continent = dim_geography_df[dim_geography_df['Continent'] == continent]['Country'].unique()\n",
    "        for country in countries_in_continent:\n",
    "            country_w = country_weights.get(country, 0.01)\n",
    "            states = dim_geography_df[dim_geography_df['Country'] == country]['State_Province'].unique()\n",
    "            for state in states:\n",
    "                state_w = state_province_weights.get(state, 0.01)\n",
    "                mask = (dim_geography_df['Country'] == country) & (dim_geography_df['State_Province'] == state)\n",
    "                dim_geography_df.loc[mask, 'Geo_Weight'] = c_weight * country_w * state_w\n",
    "    dim_geography_df['Geo_Weight'] = dim_geography_df['Geo_Weight'].replace(0.0, 0.0001)\n",
    "\n",
    "    customer_ids = dim_customer_df['Customer_ID'].values\n",
    "    \n",
    "    # --------------------------\n",
    "    # 步骤 3: 确保时间数据类型一致\n",
    "    # --------------------------\n",
    "    dim_time_df['Full_Date'] = pd.to_datetime(dim_time_df['Full_Date'])\n",
    "    dim_time_df['Year_Int'] = dim_time_df['Full_Date'].dt.year\n",
    "    dim_time_df['Quarter_Int'] = dim_time_df['Full_Date'].dt.quarter\n",
    "    dim_time_df['Quarter_Start_Date'] = dim_time_df['Full_Date'].dt.to_period('Q').dt.start_time\n",
    "\n",
    "    # --------------------------\n",
    "    # 步骤 4: 创建价格查找字典\n",
    "    # --------------------------\n",
    "    price_lookup = {}\n",
    "    if 'Standard_Price_USD' not in dim_prices_df.columns or 'Discounted_Price_USD' not in dim_prices_df.columns:\n",
    "        raise KeyError(\"Dim_Prices.csv 文件中缺少必要的列。请检查文件是否包含 'Standard_Price_USD' 和 'Discounted_Price_USD'。\")\n",
    "\n",
    "    dim_prices_df['Quarter_Start_Date'] = pd.to_datetime(dim_prices_df['Quarter_Start_Date'])\n",
    "    for _, row in dim_prices_df.iterrows():\n",
    "        quarter_start_date = row['Quarter_Start_Date']\n",
    "        product_id = row['Product_ID']\n",
    "        price_lookup[(quarter_start_date, product_id)] = {\n",
    "            'Standard_Price_USD': row['Standard_Price_USD'],\n",
    "            'Discounted_Price_USD': row['Discounted_Price_USD']\n",
    "        }\n",
    "\n",
    "    model_avg_prices = dim_prices_df.groupby('Product_ID')['Standard_Price_USD'].mean().to_dict()\n",
    "\n",
    "    product_weights_dict = {\n",
    "        pid: product_weights_by_name.get(pname, 0.0001) for pid, pname in dim_product_df.set_index('Product_ID')['Product_Name'].to_dict().items()\n",
    "    }\n",
    "    geo_weights_dict = dim_geography_df.set_index('Geo_ID')['Geo_Weight'].to_dict()\n",
    "\n",
    "    start_year = min(unit_targets_by_year.keys())\n",
    "    \n",
    "    total_generated_rows = 0\n",
    "    header_written = False\n",
    "\n",
    "    all_product_ids = list(product_weights_dict.keys())\n",
    "    all_geo_ids = list(geo_weights_dict.keys())\n",
    "    \n",
    "    combo_list = []\n",
    "    combo_weights_list = []\n",
    "    \n",
    "    for prod_id, geo_id in product(all_product_ids, all_geo_ids):\n",
    "        prod_weight = product_weights_dict.get(prod_id, 0.0001)\n",
    "        geo_weight = geo_weights_dict.get(geo_id, 0.0001)\n",
    "        combo_list.append((prod_id, geo_id))\n",
    "        combo_weights_list.append(prod_weight * geo_weight)\n",
    "\n",
    "    total_combo_weight = sum(combo_weights_list)\n",
    "    if total_combo_weight == 0:\n",
    "        print(\"警告：总组合权重为零，无法进行数据生成。\")\n",
    "        return 0\n",
    "\n",
    "    combo_probabilities = np.array(combo_weights_list) / total_combo_weight\n",
    "    \n",
    "    for year in range(start_year, end_date.year + 1):\n",
    "        for quarter in range(1, 5):\n",
    "            target_units = 0\n",
    "            target_sales_revenue = 0\n",
    "\n",
    "            # 严格根据提供的财报数据分配汽车销售额\n",
    "            if (year, quarter) in quarterly_automotive_revenue:\n",
    "                target_sales_revenue = quarterly_automotive_revenue[(year, quarter)]\n",
    "            else:\n",
    "                # 对于2013-2018年，根据总营收比例估算汽车销售额\n",
    "                if (year, quarter) in quarterly_total_revenue and year < 2019:\n",
    "                    # 假设汽车销售占总营收的90% (一个合理的假设)\n",
    "                    target_sales_revenue = quarterly_total_revenue[(year, quarter)] * 0.9 \n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            # 根据季度交付量来计算目标单位数\n",
    "            if year < 2019:\n",
    "                if year not in quarterly_unit_splits or quarter not in quarterly_unit_splits[year]:\n",
    "                    continue\n",
    "                target_units = quarterly_unit_splits[year][quarter]\n",
    "            else:\n",
    "                total_year_units = unit_targets_by_year.get(year, 0)\n",
    "                if total_year_units == 0:\n",
    "                    continue\n",
    "                # 使用季度汽车销售额占年度总销售额的比例来分配单位数\n",
    "                total_year_sales_revenue = sum(v for k, v in quarterly_automotive_revenue.items() if k[0] == year)\n",
    "                if total_year_sales_revenue == 0:\n",
    "                    # 2013-2018年的特殊处理\n",
    "                    total_year_sales_revenue = sum(v for k, v in quarterly_total_revenue.items() if k[0] == year) * 0.9\n",
    "                    \n",
    "                if total_year_sales_revenue == 0:\n",
    "                     continue\n",
    "\n",
    "                quarter_revenue_ratio = target_sales_revenue / total_year_sales_revenue\n",
    "                target_units = int(total_year_units * quarter_revenue_ratio)\n",
    "            \n",
    "            if target_units <= 0:\n",
    "                continue\n",
    "            \n",
    "            print(f\"正在为年份 {year} 第 {quarter} 季度生成 {target_units:,} 条销售记录...\")\n",
    "            \n",
    "            sampled_combo_indices = np.random.choice(len(combo_list), size=target_units, p=combo_probabilities)\n",
    "            \n",
    "            records = []\n",
    "            quarter_time_ids = dim_time_df[\n",
    "                (dim_time_df['Year_Int'] == year) & (dim_time_df['Quarter_Int'] == quarter)\n",
    "            ]['Time_ID'].tolist()\n",
    "            if not quarter_time_ids:\n",
    "                print(f\"警告：年份 {year} 第 {quarter} 季度没有可用的时间组合，跳过生成。\")\n",
    "                continue\n",
    "            \n",
    "            quarter_start_date = dim_time_df[\n",
    "                (dim_time_df['Year_Int'] == year) & (dim_time_df['Quarter_Int'] == quarter)\n",
    "            ]['Quarter_Start_Date'].iloc[0]\n",
    "\n",
    "            generated_revenues = []\n",
    "            transaction_details = []\n",
    "\n",
    "            for i in range(target_units):\n",
    "                combo_index = sampled_combo_indices[i]\n",
    "                product_id, geo_id = combo_list[combo_index]\n",
    "                \n",
    "                prices = price_lookup.get((quarter_start_date, product_id))\n",
    "                if prices:\n",
    "                    standard_price = prices['Standard_Price_USD']\n",
    "                    discounted_price = prices['Discounted_Price_USD']\n",
    "                else:\n",
    "                    standard_price = model_avg_prices.get(product_id, 0)\n",
    "                    discounted_price = standard_price\n",
    "                \n",
    "                is_discounted = np.random.choice([True, False], p=[0.2, 0.8])\n",
    "                price_used = discounted_price if is_discounted else standard_price\n",
    "                generated_revenues.append(price_used)\n",
    "\n",
    "                time_id = np.random.choice(quarter_time_ids)\n",
    "                customer_id = np.random.choice(customer_ids)\n",
    "                \n",
    "                transaction_details.append({\n",
    "                    'Time_ID': time_id,\n",
    "                    'Geo_ID': geo_id,\n",
    "                    'Product_ID': product_id,\n",
    "                    'Customer_ID': customer_id,\n",
    "                    'Sales_Units': 1,\n",
    "                    'Is_Discounted_Sale': is_discounted,\n",
    "                    'Revenue_USD': 0 # 临时占位，稍后校准\n",
    "                })\n",
    "\n",
    "            if not generated_revenues:\n",
    "                continue\n",
    "\n",
    "            # 校准收入以匹配季度汽车销售额\n",
    "            total_generated_revenue = sum(generated_revenues)\n",
    "            if total_generated_revenue > 0:\n",
    "                scaling_factor = target_sales_revenue / total_generated_revenue\n",
    "            else:\n",
    "                scaling_factor = 0\n",
    "            \n",
    "            for detail, revenue in zip(transaction_details, generated_revenues):\n",
    "                detail['Revenue_USD'] = revenue * scaling_factor\n",
    "\n",
    "            fact_sales_df_temp = pd.DataFrame(transaction_details)\n",
    "\n",
    "            fact_sales_df_temp.to_csv(output_filepath, mode='a', header=not header_written, index=False, encoding='utf-8')\n",
    "            header_written = True\n",
    "            total_generated_rows += len(fact_sales_df_temp)\n",
    "    \n",
    "    return total_generated_rows\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"正在加载所有维度表...\")\n",
    "    try:\n",
    "        dim_product_df = pd.read_csv(os.path.join('./output_data', 'Dim_Product.csv'))\n",
    "        dim_time_df = pd.read_csv(os.path.join('./output_data', 'Dim_Time.csv'))\n",
    "        dim_customer_df = pd.read_csv(os.path.join('./output_data', 'Dim_Customer.csv'))\n",
    "        dim_geography_df = pd.read_csv(os.path.join('./output_data', 'Dim_Geography.csv'))\n",
    "        dim_prices_df = pd.read_csv(os.path.join('./output_data', 'Dim_Prices.csv'))\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"错误：缺少一个或多个必需的 CSV 文件。请先运行所有维度生成脚本（1-5）。\\n{e}\")\n",
    "        exit()\n",
    "\n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    output_filepath = os.path.join(output_dir, 'Fact_Sales.csv')\n",
    "\n",
    "    if os.path.exists(output_filepath):\n",
    "        os.remove(output_filepath)\n",
    "        print(\"已移除旧的 Fact_Sales.csv 文件。\")\n",
    "\n",
    "    print(\"正在生成 Fact_Sales 表...\")\n",
    "    total_rows = generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath)\n",
    "\n",
    "    if total_rows > 0:\n",
    "        end_time = time.time()\n",
    "        print(f\"Fact_Sales.csv 已成功生成 {total_rows:,} 行数据，耗时 {end_time - start_time:.2f} 秒。\")\n",
    "        print(\"数据生成完成！\")\n",
    "    else:\n",
    "        print(\"数据生成失败。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da87be58-cc76-4bd8-bb3b-137b8faaede6",
   "metadata": {},
   "source": [
    "## **所有经营项目都有数据了** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "782f53d9-6153-4d38-91f2-2df16aaf870b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all dimension tables and data sources from './output_data'...\n",
      "Generating Fact_Sales table...\n",
      "正在为2013Q1生成 5,071 条汽车销售记录...\n",
      "正在为2013Q2生成 5,325 条汽车销售记录...\n",
      "正在为2013Q3生成 5,705 条汽车销售记录...\n",
      "正在为2013Q4生成 6,339 条汽车销售记录...\n",
      "正在为2014Q1生成 7,147 条汽车销售记录...\n",
      "正在为2014Q2生成 7,658 条汽车销售记录...\n",
      "正在为2014Q3生成 8,169 条汽车销售记录...\n",
      "正在为2014Q4生成 8,679 条汽车销售记录...\n",
      "正在为2015Q1生成 11,510 条汽车销售记录...\n",
      "正在为2015Q2生成 12,149 条汽车销售记录...\n",
      "正在为2015Q3生成 12,789 条汽车销售记录...\n",
      "正在为2015Q4生成 14,068 条汽车销售记录...\n",
      "正在为2016Q1生成 16,574 条汽车销售记录...\n",
      "正在为2016Q2生成 17,679 条汽车销售记录...\n",
      "正在为2016Q3生成 19,889 条汽车销售记录...\n",
      "正在为2016Q4生成 22,099 条汽车销售记录...\n",
      "正在为2017Q1生成 22,411 条汽车销售记录...\n",
      "正在为2017Q2生成 25,100 条汽车销售记录...\n",
      "正在为2017Q3生成 26,893 条汽车销售记录...\n",
      "正在为2017Q4生成 28,686 条汽车销售记录...\n",
      "正在为2018Q1生成 38,948 条汽车销售记录...\n",
      "正在为2018Q2生成 46,029 条汽车销售记录...\n",
      "正在为2018Q3生成 77,896 条汽车销售记录...\n",
      "正在为2018Q4生成 82,617 条汽车销售记录...\n",
      "正在为2019Q1生成 64,660 条汽车销售记录...\n",
      "正在为2019Q2生成 95,230 条汽车销售记录...\n",
      "正在为2019Q3生成 94,567 条汽车销售记录...\n",
      "正在为2019Q4生成 113,197 条汽车销售记录...\n",
      "正在为2020Q1生成 93,348 条汽车销售记录...\n",
      "正在为2020Q2生成 93,691 条汽车销售记录...\n",
      "正在为2020Q3生成 140,146 条汽车销售记录...\n",
      "正在为2020Q4生成 172,349 条汽车销售记录...\n",
      "正在为2021Q1生成 173,707 条汽车销售记录...\n",
      "正在为2021Q2生成 201,990 条汽车销售记录...\n",
      "正在为2021Q3生成 241,730 条汽车销售记录...\n",
      "正在为2021Q4生成 318,792 条汽车销售记录...\n",
      "正在为2022Q1生成 303,274 条汽车销售记录...\n",
      "正在为2022Q2生成 267,227 条汽车销售记录...\n",
      "正在为2022Q3生成 347,669 条汽车销售记录...\n",
      "正在为2022Q4生成 395,680 条汽车销售记录...\n",
      "正在为2023Q1生成 434,885 条汽车销售记录...\n",
      "正在为2023Q2生成 470,384 条汽车销售记录...\n",
      "正在为2023Q3生成 428,066 条汽车销售记录...\n",
      "正在为2023Q4生成 475,245 条汽车销售记录...\n",
      "正在为2024Q1生成 406,328 条汽车销售记录...\n",
      "正在为2024Q2生成 457,427 条汽车销售记录...\n",
      "正在为2024Q3生成 464,858 条汽车销售记录...\n",
      "正在为2024Q4生成 460,612 条汽车销售记录...\n",
      "正在为2025Q1生成 324,476 条汽车销售记录...\n",
      "正在为2025Q2生成 396,325 条汽车销售记录...\n",
      "Fact_Sales.csv successfully generated 7,965,461 rows of data in 118.85 seconds.\n",
      "其中包含 7,965,293 条汽车销售记录。\n",
      "Data generation complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "\n",
    "# --------------------------\n",
    "# 修正后的生成 Dim_Time 表的函数\n",
    "# --------------------------\n",
    "def generate_dim_time_table(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generate a time dimension table (dim_time_df) with all necessary columns.\n",
    "    \"\"\"\n",
    "    time_series = pd.date_range(start=start_date, end=end_date)\n",
    "    dim_time_df = pd.DataFrame(time_series, columns=['Full_Date'])\n",
    "    \n",
    "    dim_time_df['Time_ID'] = dim_time_df['Full_Date'].apply(lambda x: int(x.strftime('%Y%m%d')))\n",
    "    \n",
    "    dim_time_df['Year'] = dim_time_df['Full_Date'].dt.year\n",
    "    dim_time_df['Quarter_of_Year'] = dim_time_df['Full_Date'].dt.quarter\n",
    "    dim_time_df['Month_of_Year'] = dim_time_df['Full_Date'].dt.month\n",
    "    dim_time_df['Day_of_Month'] = dim_time_df['Full_Date'].dt.day\n",
    "    dim_time_df['Day_of_Week'] = dim_time_df['Full_Date'].dt.dayofweek\n",
    "    dim_time_df['Week_of_Year'] = dim_time_df['Full_Date'].dt.isocalendar().week.astype(int)\n",
    "    \n",
    "    dim_time_df['Day_Name'] = dim_time_df['Full_Date'].dt.day_name()\n",
    "    dim_time_df['Month_Name'] = dim_time_df['Full_Date'].dt.month_name()\n",
    "    \n",
    "    dim_time_df['Is_Weekend'] = dim_time_df['Day_of_Week'] >= 5\n",
    "    \n",
    "    return dim_time_df\n",
    "\n",
    "\n",
    "def generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath):\n",
    "    \"\"\"\n",
    "    Generates the Fact_Sales table by combining all dimension tables.\n",
    "    Uses real-world Tesla sales distribution and volume data for realistic output\n",
    "    \"\"\"\n",
    "    end_date = datetime(2025, 6, 30)\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 1: Parse and Load Data\n",
    "    # --------------------------\n",
    "    revenue_data = {\n",
    "        'Automotive sales': {\n",
    "            (2013, 1): 400.0e6, (2013, 2): 420.0e6, (2013, 3): 450.0e6, (2013, 4): 500.0e6,\n",
    "            (2014, 1): 700.0e6, (2014, 2): 750.0e6, (2014, 3): 800.0e6, (2014, 4): 850.0e6,\n",
    "            (2015, 1): 900.0e6, (2015, 2): 950.0e6, (2015, 3): 1000.0e6, (2015, 4): 1100.0e6,\n",
    "            (2016, 1): 1500.0e6, (2016, 2): 1600.0e6, (2016, 3): 1800.0e6, (2016, 4): 2000.0e6,\n",
    "            (2017, 1): 2500.0e6, (2017, 2): 2800.0e6, (2017, 3): 3000.0e6, (2017, 4): 3200.0e6,\n",
    "            (2018, 1): 3300.0e6, (2018, 2): 3900.0e6, (2018, 3): 6600.0e6, (2018, 4): 7000.0e6,\n",
    "            (2019, 1): 3509.0e6, (2019, 2): 5168.0e6, (2019, 3): 5132.0e6, (2019, 4): 6143.0e6,\n",
    "            (2020, 1): 4893.0e6, (2020, 2): 4911.0e6, (2020, 3): 7346.0e6, (2020, 4): 9034.0e6,\n",
    "            (2021, 1): 8187.0e6, (2021, 2): 9520.0e6, (2021, 3): 11393.0e6, (2021, 4): 15025.0e6,\n",
    "            (2022, 1): 15514.0e6, (2022, 2): 13670.0e6, (2022, 3): 17785.0e6, (2022, 4): 20241.0e6,\n",
    "            (2023, 1): 18878.0e6, (2023, 2): 20419.0e6, (2023, 3): 18582.0e6, (2023, 4): 20630.0e6,\n",
    "            (2024, 1): 16460.0e6, (2024, 2): 18530.0e6, (2024, 3): 18831.0e6, (2024, 4): 18659.0e6,\n",
    "            (2025, 1): 12925.0e6, (2025, 2): 15787.0e6\n",
    "        },\n",
    "        'Automotive regulatory credits': {\n",
    "            (2013, 1): 0.0e6, (2013, 2): 0.0e6, (2013, 3): 0.0e6, (2013, 4): 0.0e6,\n",
    "            (2014, 1): 0.0e6, (2014, 2): 0.0e6, (2014, 3): 0.0e6, (2014, 4): 0.0e6,\n",
    "            (2015, 1): 0.0e6, (2015, 2): 0.0e6, (2015, 3): 0.0e6, (2015, 4): 0.0e6,\n",
    "            (2016, 1): 0.0e6, (2016, 2): 0.0e6, (2016, 3): 0.0e6, (2016, 4): 0.0e6,\n",
    "            (2017, 1): 0.0e6, (2017, 2): 0.0e6, (2017, 3): 0.0e6, (2017, 4): 0.0e6,\n",
    "            (2018, 1): 0.0e6, (2018, 2): 0.0e6, (2018, 3): 0.0e6, (2018, 4): 0.0e6,\n",
    "            (2019, 1): 0.0e6, (2019, 2): 0.0e6, (2019, 3): 0.0e6, (2019, 4): 0.0e6,\n",
    "            (2020, 1): 0.0e6, (2020, 2): 0.0e6, (2020, 3): 0.0e6, (2020, 4): 0.0e6,\n",
    "            (2021, 1): 518.0e6, (2021, 2): 354.0e6, (2021, 3): 279.0e6, (2021, 4): 314.0e6,\n",
    "            (2022, 1): 679.0e6, (2022, 2): 344.0e6, (2022, 3): 286.0e6, (2022, 4): 467.0e6,\n",
    "            (2023, 1): 521.0e6, (2023, 2): 282.0e6, (2023, 3): 554.0e6, (2023, 4): 433.0e6,\n",
    "            (2024, 1): 442.0e6, (2024, 2): 890.0e6, (2024, 3): 739.0e6, (2024, 4): 692.0e6,\n",
    "            (2025, 1): 595.0e6, (2025, 2): 439.0e6\n",
    "        },\n",
    "        'Automotive leasing': {\n",
    "            (2013, 1): 25.0e6, (2013, 2): 28.0e6, (2013, 3): 30.0e6, (2013, 4): 32.0e6,\n",
    "            (2014, 1): 35.0e6, (2014, 2): 38.0e6, (2014, 3): 40.0e6, (2014, 4): 42.0e6,\n",
    "            (2015, 1): 45.0e6, (2015, 2): 48.0e6, (2015, 3): 50.0e6, (2015, 4): 55.0e6,\n",
    "            (2016, 1): 60.0e6, (2016, 2): 65.0e6, (2016, 3): 70.0e6, (2016, 4): 75.0e6,\n",
    "            (2017, 1): 80.0e6, (2017, 2): 85.0e6, (2017, 3): 90.0e6, (2017, 4): 95.0e6,\n",
    "            (2018, 1): 100.0e6, (2018, 2): 110.0e6, (2018, 3): 120.0e6, (2018, 4): 130.0e6,\n",
    "            (2019, 1): 215.0e6, (2019, 2): 208.0e6, (2019, 3): 221.0e6, (2019, 4): 225.0e6,\n",
    "            (2020, 1): 239.0e6, (2020, 2): 268.0e6, (2020, 3): 265.0e6, (2020, 4): 280.0e6,\n",
    "            (2021, 1): 297.0e6, (2021, 2): 332.0e6, (2021, 3): 385.0e6, (2021, 4): 628.0e6,\n",
    "            (2022, 1): 668.0e6, (2022, 2): 588.0e6, (2022, 3): 621.0e6, (2022, 4): 599.0e6,\n",
    "            (2023, 1): 564.0e6, (2023, 2): 567.0e6, (2023, 3): 489.0e6, (2023, 4): 500.0e6,\n",
    "            (2024, 1): 476.0e6, (2024, 2): 458.0e6, (2024, 3): 446.0e6, (2024, 4): 447.0e6,\n",
    "            (2025, 1): 447.0e6, (2025, 2): 435.0e6\n",
    "        },\n",
    "        'Energy generation and storage': {\n",
    "            (2013, 1): 10.0e6, (2013, 2): 12.0e6, (2013, 3): 14.0e6, (2013, 4): 16.0e6,\n",
    "            (2014, 1): 18.0e6, (2014, 2): 20.0e6, (2014, 3): 22.0e6, (2014, 4): 24.0e6,\n",
    "            (2015, 1): 26.0e6, (2015, 2): 28.0e6, (2015, 3): 30.0e6, (2015, 4): 32.0e6,\n",
    "            (2016, 1): 35.0e6, (2016, 2): 38.0e6, (2016, 3): 40.0e6, (2016, 4): 42.0e6,\n",
    "            (2017, 1): 45.0e6, (2017, 2): 48.0e6, (2017, 3): 50.0e6, (2017, 4): 55.0e6,\n",
    "            (2018, 1): 60.0e6, (2018, 2): 65.0e6, (2018, 3): 70.0e6, (2018, 4): 75.0e6,\n",
    "            (2019, 1): 324.0e6, (2019, 2): 369.0e6, (2019, 3): 402.0e6, (2019, 4): 436.0e6,\n",
    "            (2020, 1): 293.0e6, (2020, 2): 370.0e6, (2020, 3): 579.0e6, (2020, 4): 752.0e6,\n",
    "            (2021, 1): 494.0e6, (2021, 2): 801.0e6, (2021, 3): 806.0e6, (2021, 4): 688.0e6,\n",
    "            (2022, 1): 616.0e6, (2022, 2): 866.0e6, (2022, 3): 1117.0e6, (2022, 4): 1310.0e6,\n",
    "            (2023, 1): 1529.0e6, (2023, 2): 1509.0e6, (2023, 3): 1559.0e6, (2023, 4): 1438.0e6,\n",
    "            (2024, 1): 1635.0e6, (2024, 2): 3014.0e6, (2024, 3): 2376.0e6, (2024, 4): 3061.0e6,\n",
    "            (2025, 1): 2730.0e6, (2025, 2): 2789.0e6\n",
    "        },\n",
    "        'Services and other': {\n",
    "            (2013, 1): 15.0e6, (2013, 2): 17.0e6, (2013, 3): 19.0e6, (2013, 4): 20.0e6,\n",
    "            (2014, 1): 22.0e6, (2014, 2): 24.0e6, (2014, 3): 26.0e6, (2014, 4): 28.0e6,\n",
    "            (2015, 1): 30.0e6, (2015, 2): 32.0e6, (2015, 3): 35.0e6, (2015, 4): 38.0e6,\n",
    "            (2016, 1): 40.0e6, (2016, 2): 45.0e6, (2016, 3): 48.0e6, (2016, 4): 50.0e6,\n",
    "            (2017, 1): 55.0e6, (2017, 2): 58.0e6, (2017, 3): 55.0e6, (2017, 4): 58.0e6,\n",
    "            (2018, 1): 65.0e6, (2018, 2): 70.0e6, (2018, 3): 75.0e6, (2018, 4): 80.0e6,\n",
    "            (2019, 1): 493.0e6, (2019, 2): 605.0e6, (2019, 3): 548.0e6, (2019, 4): 580.0e6,\n",
    "            (2020, 1): 560.0e6, (2020, 2): 487.0e6, (2020, 3): 581.0e6, (2020, 4): 678.0e6,\n",
    "            (2021, 1): 893.0e6, (2021, 2): 951.0e6, (2021, 3): 894.0e6, (2021, 4): 1064.0e6,\n",
    "            (2022, 1): 1279.0e6, (2022, 2): 1466.0e6, (2022, 3): 1645.0e6, (2022, 4): 1701.0e6,\n",
    "            (2023, 1): 1837.0e6, (2023, 2): 2150.0e6, (2023, 3): 2166.0e6, (2023, 4): 2166.0e6,\n",
    "            (2024, 1): 2288.0e6, (2024, 2): 2608.0e6, (2024, 3): 2790.0e6, (2024, 4): 2848.0e6,\n",
    "            (2025, 1): 2638.0e6, (2025, 2): 3046.0e6\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    unit_targets_by_year = defaultdict(int)\n",
    "    unit_targets_by_year.update({\n",
    "        2013: 22442, 2014: 31655, 2015: 50517, 2016: 76243, 2017: 103091,\n",
    "        2018: 245491, 2019: 367656, 2020: 499535, 2021: 936222, 2022: 1313851,\n",
    "        2023: 1808581, 2024: 1789226, 2025: 720802\n",
    "    })\n",
    "    \n",
    "    # --------------------------\n",
    "    # Step 2: Data Cleaning and Preprocessing\n",
    "    # --------------------------\n",
    "    if 'Product_Name' not in dim_product_df.columns:\n",
    "        print(\"Warning: Missing 'Product_Name' column in Dim_Product.csv. Creating from Product_ID.\")\n",
    "        product_id_to_name = {\n",
    "            'PRO001': 'Model S', 'PRO002': 'Model X', 'PRO003': 'Model 3', 'PRO004': 'Model Y', 'PRO005': 'Cybertruck', 'PRO006': 'Other Revenue'\n",
    "        }\n",
    "        dim_product_df['Product_Name'] = dim_product_df['Product_ID'].map(product_id_to_name).fillna('Other')\n",
    "    \n",
    "    asia_countries = ['China', 'Japan', 'South Korea', 'Singapore', 'India', 'Indonesia', 'Thailand', 'Malaysia', 'Taiwan']\n",
    "    oceania_countries = ['Australia', 'New Zealand']\n",
    "    europe_countries = ['Germany', 'United Kingdom', 'France', 'Norway', 'Netherlands', 'Sweden', 'Italy', 'Switzerland', 'Spain', 'Belgium', 'Austria', 'Denmark', 'Finland', 'Portugal', 'Ireland', 'Luxembourg', 'Iceland']\n",
    "    \n",
    "    def get_continent(country):\n",
    "        if country in asia_countries: return 'Asia'\n",
    "        if country in oceania_countries: return 'Oceania'\n",
    "        if country in europe_countries: return 'Europe'\n",
    "        return 'North America'\n",
    "        \n",
    "    dim_geography_df['Continent'] = dim_geography_df['Country'].apply(get_continent).astype(str)\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 3: Define Weights\n",
    "    # --------------------------\n",
    "    product_weights_by_name = {\n",
    "        'Model S': 0.05, 'Model X': 0.05, 'Model 3': 0.45, 'Model Y': 0.40, 'Cybertruck': 0.05\n",
    "    }\n",
    "    \n",
    "    continent_weights = {'North America': 0.45, 'Europe': 0.30, 'Asia': 0.23, 'Oceania': 0.02}\n",
    "    country_weights = {'United States': 0.80, 'Canada': 0.20, 'China': 0.70, 'Japan': 0.18, 'South Korea': 0.13, 'Germany': 0.30, 'United Kingdom': 0.20, 'France': 0.15, 'Norway': 0.10, 'Australia': 0.75, 'New Zealand': 0.25, 'Taiwan': 0.1}\n",
    "    state_province_weights = {\n",
    "        'California': 0.40, 'Texas': 0.25, 'Florida': 0.15, 'Washington': 0.10, 'New York': 0.10,\n",
    "        'Ontario': 0.4, 'Quebec': 0.25, 'British Columbia': 0.2, 'Alberta': 0.15,\n",
    "        'Shanghai': 0.50, 'Beijing': 0.20, 'Guangdong': 0.20, 'Zhejiang': 0.10,\n",
    "        'Taipei': 0.5, 'New Taipei City': 0.2, 'Taichung': 0.1, 'Kaohsiung': 0.1, 'Tainan': 0.05, 'Taoyuan': 0.05,\n",
    "        'Bavaria': 0.40, 'North Rhine-Westphalia': 0.25, 'Baden-Württemberg': 0.15, 'Berlin': 0.10,\n",
    "        'Greater London': 0.50, 'South East England': 0.25, 'North West England': 0.15, 'West Midlands': 0.10,\n",
    "        'Île-de-France': 0.60, 'Auvergne-Rhône-Alpes': 0.20, 'Nouvelle-Aquitaine': 0.10, 'Provence-Alpes-Côte d\\'Azur': 0.10,\n",
    "        'Oslo': 0.70, 'Vestland': 0.15, 'Viken': 0.10, 'Trøndelag': 0.05,\n",
    "        'New South Wales': 0.5, 'Victoria': 0.3, 'Queensland': 0.1, 'Western Australia': 0.05, 'South Australia': 0.05,\n",
    "        'Auckland': 0.6, 'Wellington': 0.2, 'Canterbury': 0.1, 'Otago': 0.05, 'Waikato': 0.05,\n",
    "    }\n",
    "\n",
    "    dim_geography_df['Geo_Weight'] = 0.0\n",
    "    for continent, c_weight in continent_weights.items():\n",
    "        countries_in_continent = dim_geography_df[dim_geography_df['Continent'] == continent]['Country'].unique()\n",
    "        for country in countries_in_continent:\n",
    "            country_w = country_weights.get(country, 0.01)\n",
    "            states = dim_geography_df[dim_geography_df['Country'] == country]['State_Province'].unique()\n",
    "            for state in states:\n",
    "                state_w = state_province_weights.get(state, 0.01)\n",
    "                mask = (dim_geography_df['Country'] == country) & (dim_geography_df['State_Province'] == state)\n",
    "                dim_geography_df.loc[mask, 'Geo_Weight'] = c_weight * country_w * state_w\n",
    "    dim_geography_df['Geo_Weight'] = dim_geography_df['Geo_Weight'].replace(0.0, 0.0001)\n",
    "\n",
    "    customer_ids = dim_customer_df['Customer_ID'].values\n",
    "    \n",
    "    # --------------------------\n",
    "    # Step 4: Ensure Data Types are Consistent (Modified)\n",
    "    # --------------------------\n",
    "    dim_time_df['Full_Date'] = pd.to_datetime(dim_time_df['Full_Date'])\n",
    "    \n",
    "    # Check for and create necessary columns if they don't exist\n",
    "    if 'Year' not in dim_time_df.columns:\n",
    "        dim_time_df['Year'] = dim_time_df['Full_Date'].dt.year\n",
    "    if 'Quarter_of_Year' not in dim_time_df.columns:\n",
    "        dim_time_df['Quarter_of_Year'] = dim_time_df['Full_Date'].dt.quarter\n",
    "    \n",
    "    # Using 'Year' and 'Quarter_of_Year' for consistency\n",
    "    dim_time_df['Year_Int'] = dim_time_df['Year']\n",
    "    dim_time_df['Quarter_Int'] = dim_time_df['Quarter_of_Year']\n",
    "    dim_time_df['Quarter_Start_Date'] = dim_time_df['Full_Date'].dt.to_period('Q').dt.start_time\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 5: Create Price Lookup Dictionary\n",
    "    # --------------------------\n",
    "    price_lookup = {}\n",
    "    if 'Standard_Price_USD' not in dim_prices_df.columns or 'Discounted_Price_USD' not in dim_prices_df.columns:\n",
    "        raise KeyError(\"Dim_Prices.csv is missing required columns. Please check if it contains 'Standard_Price_USD' and 'Discounted_Price_USD'.\")\n",
    "\n",
    "    dim_prices_df['Quarter_Start_Date'] = pd.to_datetime(dim_prices_df['Quarter_Start_Date'])\n",
    "    for _, row in dim_prices_df.iterrows():\n",
    "        quarter_start_date = row['Quarter_Start_Date']\n",
    "        product_id = row['Product_ID']\n",
    "        price_lookup[(quarter_start_date, product_id)] = {\n",
    "            'Standard_Price_USD': row['Standard_Price_USD'],\n",
    "            'Discounted_Price_USD': row['Discounted_Price_USD']\n",
    "        }\n",
    "\n",
    "    model_avg_prices = dim_prices_df.groupby('Product_ID')['Standard_Price_USD'].mean().to_dict()\n",
    "\n",
    "    product_weights_dict = {\n",
    "        pid: product_weights_by_name.get(pname, 0.0001) for pid, pname in dim_product_df.set_index('Product_ID')['Product_Name'].to_dict().items()\n",
    "    }\n",
    "    geo_weights_dict = dim_geography_df.set_index('Geo_ID')['Geo_Weight'].to_dict()\n",
    "\n",
    "    start_year = min(y for y, q in revenue_data['Automotive sales'].keys())\n",
    "    \n",
    "    total_generated_rows = 0\n",
    "    header_written = False\n",
    "    total_automotive_units = 0\n",
    "\n",
    "    all_product_ids = list(product_weights_dict.keys())\n",
    "    all_geo_ids = list(geo_weights_dict.keys())\n",
    "    \n",
    "    combo_list = []\n",
    "    combo_weights_list = []\n",
    "    \n",
    "    for prod_id, geo_id in product(all_product_ids, all_geo_ids):\n",
    "        prod_weight = product_weights_dict.get(prod_id, 0.0001)\n",
    "        geo_weight = geo_weights_dict.get(geo_id, 0.0001)\n",
    "        combo_list.append((prod_id, geo_id))\n",
    "        combo_weights_list.append(prod_weight * geo_weight)\n",
    "\n",
    "    total_combo_weight = sum(combo_weights_list)\n",
    "    if total_combo_weight == 0:\n",
    "        print(\"Warning: Total combination weight is zero. Cannot generate data.\")\n",
    "        return 0, 0\n",
    "\n",
    "    combo_probabilities = np.array(combo_weights_list) / total_combo_weight\n",
    "    \n",
    "    # --------------------------\n",
    "    # Step 6: Generate Fact Table Records (Optimized Logic)\n",
    "    # --------------------------\n",
    "    non_automotive_products = {\n",
    "        'Automotive regulatory credits': 'PRO007',\n",
    "        'Services and other': 'PRO008',\n",
    "        'Automotive leasing': 'PRO009',\n",
    "        'Energy generation and storage': 'PRO010'\n",
    "    }\n",
    "    \n",
    "    for year in range(start_year, end_date.year + 1):\n",
    "        for quarter in range(1, 5):\n",
    "            if year == 2025 and quarter > 2:\n",
    "                continue\n",
    "            \n",
    "            quarterly_revenue = {category: revenue_data.get(category, {}).get((year, quarter), 0) for category in revenue_data}\n",
    "            \n",
    "            # Find the number of days in the quarter\n",
    "            quarter_dates_df = dim_time_df[\n",
    "                (dim_time_df['Year_Int'] == year) & (dim_time_df['Quarter_Int'] == quarter)\n",
    "            ]\n",
    "            \n",
    "            if quarter_dates_df.empty:\n",
    "                print(f\"Warning: No time IDs available for Year {year} Quarter {quarter}, skipping generation.\")\n",
    "                continue\n",
    "\n",
    "            records = []\n",
    "            \n",
    "            for category, revenue in quarterly_revenue.items():\n",
    "                if revenue > 0:\n",
    "                    if category == 'Automotive sales':\n",
    "                        total_year_units = unit_targets_by_year.get(year, 0)\n",
    "                        \n",
    "                        total_year_sales_revenue = sum(v for k, v in revenue_data['Automotive sales'].items() if k[0] == year)\n",
    "                        \n",
    "                        if total_year_sales_revenue > 0:\n",
    "                            quarter_revenue_ratio = revenue / total_year_sales_revenue\n",
    "                            target_units = int(total_year_units * quarter_revenue_ratio)\n",
    "                            \n",
    "                            if target_units > 0:\n",
    "                                print(f\"正在为{year}Q{quarter}生成 {target_units:,} 条汽车销售记录...\")\n",
    "                                \n",
    "                                sampled_combo_indices = np.random.choice(len(combo_list), size=target_units, p=combo_probabilities)\n",
    "                                average_price_per_unit = revenue / target_units\n",
    "                                \n",
    "                                for i in range(target_units):\n",
    "                                    combo_index = sampled_combo_indices[i]\n",
    "                                    product_id, geo_id = combo_list[combo_index]\n",
    "                                    \n",
    "                                    time_id = np.random.choice(quarter_dates_df['Time_ID'])\n",
    "                                    customer_id = np.random.choice(customer_ids)\n",
    "                                    \n",
    "                                    records.append({\n",
    "                                        'Time_ID': time_id,\n",
    "                                        'Geo_ID': geo_id,\n",
    "                                        'Product_ID': product_id,\n",
    "                                        'Customer_ID': customer_id,\n",
    "                                        'Sales_Units': 1,\n",
    "                                        'Is_Discounted_Sale': False,\n",
    "                                        'Revenue_USD': average_price_per_unit,\n",
    "                                        'Revenue_Category': category\n",
    "                                    })\n",
    "                                total_automotive_units += target_units\n",
    "                        \n",
    "                    else:\n",
    "                        product_id = non_automotive_products.get(category, 'PRO006')\n",
    "                        quarter_time_id = quarter_dates_df.iloc[0]['Time_ID']\n",
    "                        \n",
    "                        records.append({\n",
    "                            'Time_ID': quarter_time_id,\n",
    "                            'Geo_ID': 'GEO001',\n",
    "                            'Product_ID': product_id,\n",
    "                            'Customer_ID': 'CUS001',\n",
    "                            'Sales_Units': 1,\n",
    "                            'Is_Discounted_Sale': False,\n",
    "                            'Revenue_USD': revenue,\n",
    "                            'Revenue_Category': category\n",
    "                        })\n",
    "            \n",
    "            fact_sales_df_temp = pd.DataFrame(records)\n",
    "            \n",
    "            if not fact_sales_df_temp.empty:\n",
    "                fact_sales_df_temp.to_csv(output_filepath, mode='a', header=not header_written, index=False, encoding='utf-8')\n",
    "                header_written = True\n",
    "                total_generated_rows += len(fact_sales_df_temp)\n",
    "    \n",
    "    return total_generated_rows, total_automotive_units\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    \n",
    "    print(f\"Loading all dimension tables and data sources from '{output_dir}'...\")\n",
    "    \n",
    "    dim_product_df = None\n",
    "    dim_time_df = None\n",
    "    dim_customer_df = None\n",
    "    dim_geography_df = None\n",
    "    dim_prices_df = None\n",
    "    \n",
    "    try:\n",
    "        # Check if Dim_Time.csv exists, if not, generate it\n",
    "        dim_time_path = os.path.join(output_dir, 'Dim_Time.csv')\n",
    "        if not os.path.exists(dim_time_path):\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            print(\"Dim_Time.csv not found. Generating...\")\n",
    "            dim_time_df = generate_dim_time_table(datetime(2013, 1, 1), datetime(2025, 6, 30))\n",
    "            dim_time_df.to_csv(dim_time_path, index=False)\n",
    "            print(\"Dim_Time.csv generated.\")\n",
    "\n",
    "        dim_product_df = pd.read_csv(os.path.join(output_dir, 'Dim_Product.csv'))\n",
    "        dim_time_df = pd.read_csv(dim_time_path)\n",
    "        dim_customer_df = pd.read_csv(os.path.join(output_dir, 'Dim_Customer.csv'))\n",
    "        dim_geography_df = pd.read_csv(os.path.join(output_dir, 'Dim_Geography.csv'))\n",
    "        dim_prices_df = pd.read_csv(os.path.join(output_dir, 'Dim_Prices.csv'))\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: One or more required CSV files are missing. Please ensure all dimension tables are in the '{output_dir}' directory. The file '{e.filename}' was not found.\")\n",
    "    \n",
    "    if dim_product_df is None or dim_time_df is None or dim_customer_df is None or dim_geography_df is None or dim_prices_df is None:\n",
    "        print(\"Data generation failed due to missing files.\")\n",
    "    else:\n",
    "        # Extend the Product dimension\n",
    "        new_product_records = pd.DataFrame([\n",
    "            {'Product_ID': 'PRO006', 'Product_Name': 'Other Revenue'},\n",
    "            {'Product_ID': 'PRO007', 'Product_Name': 'Regulatory Credits'},\n",
    "            {'Product_ID': 'PRO008', 'Product_Name': 'Services'},\n",
    "            {'Product_ID': 'PRO009', 'Product_Name': 'Leasing'},\n",
    "            {'Product_ID': 'PRO010', 'Product_Name': 'Energy'}\n",
    "        ])\n",
    "        dim_product_df = pd.concat([dim_product_df, new_product_records], ignore_index=True)\n",
    "\n",
    "        # Extend the Geography dimension\n",
    "        new_geo_record = pd.DataFrame([{'Geo_ID': 'GEO001', 'Country': 'Global', 'State_Province': 'NA'}])\n",
    "        dim_geography_df = pd.concat([dim_geography_df, new_geo_record], ignore_index=True)\n",
    "        \n",
    "        # Extend the Customer dimension\n",
    "        new_customer_record = pd.DataFrame([{'Customer_ID': 'CUS001', 'First_Name': 'Global', 'Last_Name': 'Customer', 'Gender': 'NA'}])\n",
    "        dim_customer_df = pd.concat([dim_customer_df, new_customer_record], ignore_index=True)\n",
    "        \n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        output_filepath = os.path.join(output_dir, 'Fact_Sales.csv')\n",
    "        \n",
    "        if os.path.exists(output_filepath):\n",
    "            os.remove(output_filepath)\n",
    "    \n",
    "        print(\"Generating Fact_Sales table...\")\n",
    "        total_rows, total_automotive_units = generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath)\n",
    "    \n",
    "        if total_rows > 0:\n",
    "            end_time = time.time()\n",
    "            print(f\"Fact_Sales.csv successfully generated {total_rows:,} rows of data in {end_time - start_time:.2f} seconds.\")\n",
    "            print(f\"其中包含 {total_automotive_units:,} 条汽车销售记录。\")\n",
    "            print(\"Data generation complete!\")\n",
    "        else:\n",
    "            print(\"Data generation failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb49aba-3ee3-4833-b44e-551824faa178",
   "metadata": {},
   "source": [
    "## **移除空白大洲** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dac8c1da-076f-4235-840d-b4942bc05bf0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all dimension tables and data sources from './output_data'...\n",
      "Generating Fact_Sales table...\n",
      "正在为2013Q1生成 5,071 条汽车销售记录...\n",
      "正在为2013Q2生成 5,325 条汽车销售记录...\n",
      "正在为2013Q3生成 5,705 条汽车销售记录...\n",
      "正在为2013Q4生成 6,339 条汽车销售记录...\n",
      "正在为2014Q1生成 7,147 条汽车销售记录...\n",
      "正在为2014Q2生成 7,658 条汽车销售记录...\n",
      "正在为2014Q3生成 8,169 条汽车销售记录...\n",
      "正在为2014Q4生成 8,679 条汽车销售记录...\n",
      "正在为2015Q1生成 11,510 条汽车销售记录...\n",
      "正在为2015Q2生成 12,149 条汽车销售记录...\n",
      "正在为2015Q3生成 12,789 条汽车销售记录...\n",
      "正在为2015Q4生成 14,068 条汽车销售记录...\n",
      "正在为2016Q1生成 16,574 条汽车销售记录...\n",
      "正在为2016Q2生成 17,679 条汽车销售记录...\n",
      "正在为2016Q3生成 19,889 条汽车销售记录...\n",
      "正在为2016Q4生成 22,099 条汽车销售记录...\n",
      "正在为2017Q1生成 22,411 条汽车销售记录...\n",
      "正在为2017Q2生成 25,100 条汽车销售记录...\n",
      "正在为2017Q3生成 26,893 条汽车销售记录...\n",
      "正在为2017Q4生成 28,686 条汽车销售记录...\n",
      "正在为2018Q1生成 38,948 条汽车销售记录...\n",
      "正在为2018Q2生成 46,029 条汽车销售记录...\n",
      "正在为2018Q3生成 77,896 条汽车销售记录...\n",
      "正在为2018Q4生成 82,617 条汽车销售记录...\n",
      "正在为2019Q1生成 64,660 条汽车销售记录...\n",
      "正在为2019Q2生成 95,230 条汽车销售记录...\n",
      "正在为2019Q3生成 94,567 条汽车销售记录...\n",
      "正在为2019Q4生成 113,197 条汽车销售记录...\n",
      "正在为2020Q1生成 93,348 条汽车销售记录...\n",
      "正在为2020Q2生成 93,691 条汽车销售记录...\n",
      "正在为2020Q3生成 140,146 条汽车销售记录...\n",
      "正在为2020Q4生成 172,349 条汽车销售记录...\n",
      "正在为2021Q1生成 173,707 条汽车销售记录...\n",
      "正在为2021Q2生成 201,990 条汽车销售记录...\n",
      "正在为2021Q3生成 241,730 条汽车销售记录...\n",
      "正在为2021Q4生成 318,792 条汽车销售记录...\n",
      "正在为2022Q1生成 303,274 条汽车销售记录...\n",
      "正在为2022Q2生成 267,227 条汽车销售记录...\n",
      "正在为2022Q3生成 347,669 条汽车销售记录...\n",
      "正在为2022Q4生成 395,680 条汽车销售记录...\n",
      "正在为2023Q1生成 434,885 条汽车销售记录...\n",
      "正在为2023Q2生成 470,384 条汽车销售记录...\n",
      "正在为2023Q3生成 428,066 条汽车销售记录...\n",
      "正在为2023Q4生成 475,245 条汽车销售记录...\n",
      "正在为2024Q1生成 406,328 条汽车销售记录...\n",
      "正在为2024Q2生成 457,427 条汽车销售记录...\n",
      "正在为2024Q3生成 464,858 条汽车销售记录...\n",
      "正在为2024Q4生成 460,612 条汽车销售记录...\n",
      "正在为2025Q1生成 324,476 条汽车销售记录...\n",
      "正在为2025Q2生成 396,325 条汽车销售记录...\n",
      "Fact_Sales.csv successfully generated 7,965,461 rows of data in 115.32 seconds.\n",
      "其中包含 7,965,293 条汽车销售记录。\n",
      "Data generation complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "\n",
    "# --------------------------\n",
    "# 修正后的生成 Dim_Time 表的函数\n",
    "# --------------------------\n",
    "def generate_dim_time_table(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generate a time dimension table (dim_time_df) with all necessary columns.\n",
    "    \"\"\"\n",
    "    time_series = pd.date_range(start=start_date, end=end_date)\n",
    "    dim_time_df = pd.DataFrame(time_series, columns=['Full_Date'])\n",
    "    \n",
    "    dim_time_df['Time_ID'] = dim_time_df['Full_Date'].apply(lambda x: int(x.strftime('%Y%m%d')))\n",
    "    \n",
    "    dim_time_df['Year'] = dim_time_df['Full_Date'].dt.year\n",
    "    dim_time_df['Quarter_of_Year'] = dim_time_df['Full_Date'].dt.quarter\n",
    "    dim_time_df['Month_of_Year'] = dim_time_df['Full_Date'].dt.month\n",
    "    dim_time_df['Day_of_Month'] = dim_time_df['Full_Date'].dt.day\n",
    "    dim_time_df['Day_of_Week'] = dim_time_df['Full_Date'].dt.dayofweek\n",
    "    dim_time_df['Week_of_Year'] = dim_time_df['Full_Date'].dt.isocalendar().week.astype(int)\n",
    "    \n",
    "    dim_time_df['Day_Name'] = dim_time_df['Full_Date'].dt.day_name()\n",
    "    dim_time_df['Month_Name'] = dim_time_df['Full_Date'].dt.month_name()\n",
    "    \n",
    "    dim_time_df['Is_Weekend'] = dim_time_df['Day_of_Week'] >= 5\n",
    "    \n",
    "    return dim_time_df\n",
    "\n",
    "\n",
    "def generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath):\n",
    "    \"\"\"\n",
    "    Generates the Fact_Sales table by combining all dimension tables.\n",
    "    Uses real-world Tesla sales distribution and volume data for realistic output\n",
    "    \"\"\"\n",
    "    end_date = datetime(2025, 6, 30)\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 1: Parse and Load Data (修正后的碳积分数据)\n",
    "    # --------------------------\n",
    "    revenue_data = {\n",
    "        'Automotive sales': {\n",
    "            (2013, 1): 400.0e6, (2013, 2): 420.0e6, (2013, 3): 450.0e6, (2013, 4): 500.0e6,\n",
    "            (2014, 1): 700.0e6, (2014, 2): 750.0e6, (2014, 3): 800.0e6, (2014, 4): 850.0e6,\n",
    "            (2015, 1): 900.0e6, (2015, 2): 950.0e6, (2015, 3): 1000.0e6, (2015, 4): 1100.0e6,\n",
    "            (2016, 1): 1500.0e6, (2016, 2): 1600.0e6, (2016, 3): 1800.0e6, (2016, 4): 2000.0e6,\n",
    "            (2017, 1): 2500.0e6, (2017, 2): 2800.0e6, (2017, 3): 3000.0e6, (2017, 4): 3200.0e6,\n",
    "            (2018, 1): 3300.0e6, (2018, 2): 3900.0e6, (2018, 3): 6600.0e6, (2018, 4): 7000.0e6,\n",
    "            (2019, 1): 3509.0e6, (2019, 2): 5168.0e6, (2019, 3): 5132.0e6, (2019, 4): 6143.0e6,\n",
    "            (2020, 1): 4893.0e6, (2020, 2): 4911.0e6, (2020, 3): 7346.0e6, (2020, 4): 9034.0e6,\n",
    "            (2021, 1): 8187.0e6, (2021, 2): 9520.0e6, (2021, 3): 11393.0e6, (2021, 4): 15025.0e6,\n",
    "            (2022, 1): 15514.0e6, (2022, 2): 13670.0e6, (2022, 3): 17785.0e6, (2022, 4): 20241.0e6,\n",
    "            (2023, 1): 18878.0e6, (2023, 2): 20419.0e6, (2023, 3): 18582.0e6, (2023, 4): 20630.0e6,\n",
    "            (2024, 1): 16460.0e6, (2024, 2): 18530.0e6, (2024, 3): 18831.0e6, (2024, 4): 18659.0e6,\n",
    "            (2025, 1): 12925.0e6, (2025, 2): 15787.0e6\n",
    "        },\n",
    "        'Automotive regulatory credits': {\n",
    "            (2013, 1): 0.0e6, (2013, 2): 0.0e6, (2013, 3): 0.0e6, (2013, 4): 0.0e6,\n",
    "            (2014, 1): 0.0e6, (2014, 2): 0.0e6, (2014, 3): 0.0e6, (2014, 4): 0.0e6,\n",
    "            (2015, 1): 0.0e6, (2015, 2): 0.0e6, (2015, 3): 0.0e6, (2015, 4): 0.0e6,\n",
    "            (2016, 1): 0.0e6, (2016, 2): 0.0e6, (2016, 3): 0.0e6, (2016, 4): 0.0e6,\n",
    "            (2017, 1): 0.0e6, (2017, 2): 0.0e6, (2017, 3): 0.0e6, (2017, 4): 0.0e6,\n",
    "            (2018, 1): 0.0e6, (2018, 2): 0.0e6, (2018, 3): 0.0e6, (2018, 4): 0.0e6,\n",
    "            (2019, 1): 0.0e6, (2019, 2): 0.0e6, (2019, 3): 0.0e6, (2019, 4): 0.0e6,\n",
    "            (2020, 1): 0.0e6, (2020, 2): 0.0e6, (2020, 3): 0.0e6, (2020, 4): 0.0e6,\n",
    "            (2021, 1): 518.0e6, (2021, 2): 354.0e6, (2021, 3): 279.0e6, (2021, 4): 314.0e6,\n",
    "            (2022, 1): 679.0e6, (2022, 2): 344.0e6, (2022, 3): 286.0e6, (2022, 4): 467.0e6,\n",
    "            (2023, 1): 521.0e6, (2023, 2): 282.0e6, (2023, 3): 554.0e6, (2023, 4): 433.0e6,\n",
    "            (2024, 1): 442.0e6, (2024, 2): 890.0e6, (2024, 3): 739.0e6, (2024, 4): 692.0e6,\n",
    "            (2025, 1): 595.0e6, (2025, 2): 439.0e6\n",
    "        },\n",
    "        'Automotive leasing': {\n",
    "            (2013, 1): 25.0e6, (2013, 2): 28.0e6, (2013, 3): 30.0e6, (2013, 4): 32.0e6,\n",
    "            (2014, 1): 35.0e6, (2014, 2): 38.0e6, (2014, 3): 40.0e6, (2014, 4): 42.0e6,\n",
    "            (2015, 1): 45.0e6, (2015, 2): 48.0e6, (2015, 3): 50.0e6, (2015, 4): 55.0e6,\n",
    "            (2016, 1): 60.0e6, (2016, 2): 65.0e6, (2016, 3): 70.0e6, (2016, 4): 75.0e6,\n",
    "            (2017, 1): 80.0e6, (2017, 2): 85.0e6, (2017, 3): 90.0e6, (2017, 4): 95.0e6,\n",
    "            (2018, 1): 100.0e6, (2018, 2): 110.0e6, (2018, 3): 120.0e6, (2018, 4): 130.0e6,\n",
    "            (2019, 1): 215.0e6, (2019, 2): 208.0e6, (2019, 3): 221.0e6, (2019, 4): 225.0e6,\n",
    "            (2020, 1): 239.0e6, (2020, 2): 268.0e6, (2020, 3): 265.0e6, (2020, 4): 280.0e6,\n",
    "            (2021, 1): 297.0e6, (2021, 2): 332.0e6, (2021, 3): 385.0e6, (2021, 4): 628.0e6,\n",
    "            (2022, 1): 668.0e6, (2022, 2): 588.0e6, (2022, 3): 621.0e6, (2022, 4): 599.0e6,\n",
    "            (2023, 1): 564.0e6, (2023, 2): 567.0e6, (2023, 3): 489.0e6, (2023, 4): 500.0e6,\n",
    "            (2024, 1): 476.0e6, (2024, 2): 458.0e6, (2024, 3): 446.0e6, (2024, 4): 447.0e6,\n",
    "            (2025, 1): 447.0e6, (2025, 2): 435.0e6\n",
    "        },\n",
    "        'Energy generation and storage': {\n",
    "            (2013, 1): 10.0e6, (2013, 2): 12.0e6, (2013, 3): 14.0e6, (2013, 4): 16.0e6,\n",
    "            (2014, 1): 18.0e6, (2014, 2): 20.0e6, (2014, 3): 22.0e6, (2014, 4): 24.0e6,\n",
    "            (2015, 1): 26.0e6, (2015, 2): 28.0e6, (2015, 3): 30.0e6, (2015, 4): 32.0e6,\n",
    "            (2016, 1): 35.0e6, (2016, 2): 38.0e6, (2016, 3): 40.0e6, (2016, 4): 42.0e6,\n",
    "            (2017, 1): 45.0e6, (2017, 2): 48.0e6, (2017, 3): 50.0e6, (2017, 4): 55.0e6,\n",
    "            (2018, 1): 60.0e6, (2018, 2): 65.0e6, (2018, 3): 70.0e6, (2018, 4): 75.0e6,\n",
    "            (2019, 1): 324.0e6, (2019, 2): 369.0e6, (2019, 3): 402.0e6, (2019, 4): 436.0e6,\n",
    "            (2020, 1): 293.0e6, (2020, 2): 370.0e6, (2020, 3): 579.0e6, (2020, 4): 752.0e6,\n",
    "            (2021, 1): 494.0e6, (2021, 2): 801.0e6, (2021, 3): 806.0e6, (2021, 4): 688.0e6,\n",
    "            (2022, 1): 616.0e6, (2022, 2): 866.0e6, (2022, 3): 1117.0e6, (2022, 4): 1310.0e6,\n",
    "            (2023, 1): 1529.0e6, (2023, 2): 1509.0e6, (2023, 3): 1559.0e6, (2023, 4): 1438.0e6,\n",
    "            (2024, 1): 1635.0e6, (2024, 2): 3014.0e6, (2024, 3): 2376.0e6, (2024, 4): 3061.0e6,\n",
    "            (2025, 1): 2730.0e6, (2025, 2): 2789.0e6\n",
    "        },\n",
    "        'Services and other': {\n",
    "            (2013, 1): 15.0e6, (2013, 2): 17.0e6, (2013, 3): 19.0e6, (2013, 4): 20.0e6,\n",
    "            (2014, 1): 22.0e6, (2014, 2): 24.0e6, (2014, 3): 26.0e6, (2014, 4): 28.0e6,\n",
    "            (2015, 1): 30.0e6, (2015, 2): 32.0e6, (2015, 3): 35.0e6, (2015, 4): 38.0e6,\n",
    "            (2016, 1): 40.0e6, (2016, 2): 45.0e6, (2016, 3): 48.0e6, (2016, 4): 50.0e6,\n",
    "            (2017, 1): 55.0e6, (2017, 2): 58.0e6, (2017, 3): 55.0e6, (2017, 4): 58.0e6,\n",
    "            (2018, 1): 65.0e6, (2018, 2): 70.0e6, (2018, 3): 75.0e6, (2018, 4): 80.0e6,\n",
    "            (2019, 1): 493.0e6, (2019, 2): 605.0e6, (2019, 3): 548.0e6, (2019, 4): 580.0e6,\n",
    "            (2020, 1): 560.0e6, (2020, 2): 487.0e6, (2020, 3): 581.0e6, (2020, 4): 678.0e6,\n",
    "            (2021, 1): 893.0e6, (2021, 2): 951.0e6, (2021, 3): 894.0e6, (2021, 4): 1064.0e6,\n",
    "            (2022, 1): 1279.0e6, (2022, 2): 1466.0e6, (2022, 3): 1645.0e6, (2022, 4): 1701.0e6,\n",
    "            (2023, 1): 1837.0e6, (2023, 2): 2150.0e6, (2023, 3): 2166.0e6, (2023, 4): 2166.0e6,\n",
    "            (2024, 1): 2288.0e6, (2024, 2): 2608.0e6, (2024, 3): 2790.0e6, (2024, 4): 2848.0e6,\n",
    "            (2025, 1): 2638.0e6, (2025, 2): 3046.0e6\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    unit_targets_by_year = defaultdict(int)\n",
    "    unit_targets_by_year.update({\n",
    "        2013: 22442, 2014: 31655, 2015: 50517, 2016: 76243, 2017: 103091,\n",
    "        2018: 245491, 2019: 367656, 2020: 499535, 2021: 936222, 2022: 1313851,\n",
    "        2023: 1808581, 2024: 1789226, 2025: 720802\n",
    "    })\n",
    "    \n",
    "    # --------------------------\n",
    "    # Step 2: Data Cleaning and Preprocessing\n",
    "    # --------------------------\n",
    "    if 'Product_Name' not in dim_product_df.columns:\n",
    "        print(\"Warning: Missing 'Product_Name' column in Dim_Product.csv. Creating from Product_ID.\")\n",
    "        product_id_to_name = {\n",
    "            'PRO001': 'Model S', 'PRO002': 'Model X', 'PRO003': 'Model 3', 'PRO004': 'Model Y', 'PRO005': 'Cybertruck', 'PRO006': 'Other Revenue'\n",
    "        }\n",
    "        dim_product_df['Product_Name'] = dim_product_df['Product_ID'].map(product_id_to_name).fillna('Other')\n",
    "    \n",
    "    asia_countries = ['China', 'Japan', 'South Korea', 'Singapore', 'India', 'Indonesia', 'Thailand', 'Malaysia', 'Taiwan']\n",
    "    oceania_countries = ['Australia', 'New Zealand']\n",
    "    europe_countries = ['Germany', 'United Kingdom', 'France', 'Norway', 'Netherlands', 'Sweden', 'Italy', 'Switzerland', 'Spain', 'Belgium', 'Austria', 'Denmark', 'Finland', 'Portugal', 'Ireland', 'Luxembourg', 'Iceland']\n",
    "    \n",
    "    def get_continent(country):\n",
    "        if country in asia_countries: return 'Asia'\n",
    "        if country in oceania_countries: return 'Oceania'\n",
    "        if country in europe_countries: return 'Europe'\n",
    "        if country in ['United States', 'Canada', 'Mexico']: return 'North America' # Add Mexico to North America\n",
    "        return 'Other' # Handle any countries not in the lists\n",
    "        \n",
    "    dim_geography_df['Continent'] = dim_geography_df['Country'].apply(get_continent).astype(str)\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 3: Define Weights\n",
    "    # --------------------------\n",
    "    product_weights_by_name = {\n",
    "        'Model S': 0.05, 'Model X': 0.05, 'Model 3': 0.45, 'Model Y': 0.40, 'Cybertruck': 0.05\n",
    "    }\n",
    "    \n",
    "    continent_weights = {'North America': 0.45, 'Europe': 0.30, 'Asia': 0.23, 'Oceania': 0.02}\n",
    "    country_weights = {'United States': 0.80, 'Canada': 0.20, 'China': 0.70, 'Japan': 0.18, 'South Korea': 0.13, 'Germany': 0.30, 'United Kingdom': 0.20, 'France': 0.15, 'Norway': 0.10, 'Australia': 0.75, 'New Zealand': 0.25, 'Taiwan': 0.1}\n",
    "    state_province_weights = {\n",
    "        'California': 0.40, 'Texas': 0.25, 'Florida': 0.15, 'Washington': 0.10, 'New York': 0.10,\n",
    "        'Ontario': 0.4, 'Quebec': 0.25, 'British Columbia': 0.2, 'Alberta': 0.15,\n",
    "        'Shanghai': 0.50, 'Beijing': 0.20, 'Guangdong': 0.20, 'Zhejiang': 0.10,\n",
    "        'Taipei': 0.5, 'New Taipei City': 0.2, 'Taichung': 0.1, 'Kaohsiung': 0.1, 'Tainan': 0.05, 'Taoyuan': 0.05,\n",
    "        'Bavaria': 0.40, 'North Rhine-Westphalia': 0.25, 'Baden-Württemberg': 0.15, 'Berlin': 0.10,\n",
    "        'Greater London': 0.50, 'South East England': 0.25, 'North West England': 0.15, 'West Midlands': 0.10,\n",
    "        'Île-de-France': 0.60, 'Auvergne-Rhône-Alpes': 0.20, 'Nouvelle-Aquitaine': 0.10, 'Provence-Alpes-Côte d\\'Azur': 0.10,\n",
    "        'Oslo': 0.70, 'Vestland': 0.15, 'Viken': 0.10, 'Trøndelag': 0.05,\n",
    "        'New South Wales': 0.5, 'Victoria': 0.3, 'Queensland': 0.1, 'Western Australia': 0.05, 'South Australia': 0.05,\n",
    "        'Auckland': 0.6, 'Wellington': 0.2, 'Canterbury': 0.1, 'Otago': 0.05, 'Waikato': 0.05,\n",
    "    }\n",
    "\n",
    "    dim_geography_df['Geo_Weight'] = 0.0\n",
    "    for continent, c_weight in continent_weights.items():\n",
    "        countries_in_continent = dim_geography_df[dim_geography_df['Continent'] == continent]['Country'].unique()\n",
    "        for country in countries_in_continent:\n",
    "            country_w = country_weights.get(country, 0.01)\n",
    "            states = dim_geography_df[dim_geography_df['Country'] == country]['State_Province'].unique()\n",
    "            for state in states:\n",
    "                state_w = state_province_weights.get(state, 0.01)\n",
    "                mask = (dim_geography_df['Country'] == country) & (dim_geography_df['State_Province'] == state)\n",
    "                dim_geography_df.loc[mask, 'Geo_Weight'] = c_weight * country_w * state_w\n",
    "    dim_geography_df['Geo_Weight'] = dim_geography_df['Geo_Weight'].replace(0.0, 0.0001)\n",
    "\n",
    "    customer_ids = dim_customer_df['Customer_ID'].values\n",
    "    \n",
    "    # --------------------------\n",
    "    # Step 4: Ensure Data Types are Consistent (Modified)\n",
    "    # --------------------------\n",
    "    dim_time_df['Full_Date'] = pd.to_datetime(dim_time_df['Full_Date'])\n",
    "    \n",
    "    # Check for and create necessary columns if they don't exist\n",
    "    if 'Year' not in dim_time_df.columns:\n",
    "        dim_time_df['Year'] = dim_time_df['Full_Date'].dt.year\n",
    "    if 'Quarter_of_Year' not in dim_time_df.columns:\n",
    "        dim_time_df['Quarter_of_Year'] = dim_time_df['Full_Date'].dt.quarter\n",
    "    \n",
    "    # Using 'Year' and 'Quarter_of_Year' for consistency\n",
    "    dim_time_df['Year_Int'] = dim_time_df['Year']\n",
    "    dim_time_df['Quarter_Int'] = dim_time_df['Quarter_of_Year']\n",
    "    dim_time_df['Quarter_Start_Date'] = dim_time_df['Full_Date'].dt.to_period('Q').dt.start_time\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 5: Create Price Lookup Dictionary\n",
    "    # --------------------------\n",
    "    price_lookup = {}\n",
    "    if 'Standard_Price_USD' not in dim_prices_df.columns or 'Discounted_Price_USD' not in dim_prices_df.columns:\n",
    "        raise KeyError(\"Dim_Prices.csv is missing required columns. Please check if it contains 'Standard_Price_USD' and 'Discounted_Price_USD'.\")\n",
    "\n",
    "    dim_prices_df['Quarter_Start_Date'] = pd.to_datetime(dim_prices_df['Quarter_Start_Date'])\n",
    "    for _, row in dim_prices_df.iterrows():\n",
    "        quarter_start_date = row['Quarter_Start_Date']\n",
    "        product_id = row['Product_ID']\n",
    "        price_lookup[(quarter_start_date, product_id)] = {\n",
    "            'Standard_Price_USD': row['Standard_Price_USD'],\n",
    "            'Discounted_Price_USD': row['Discounted_Price_USD']\n",
    "        }\n",
    "\n",
    "    model_avg_prices = dim_prices_df.groupby('Product_ID')['Standard_Price_USD'].mean().to_dict()\n",
    "\n",
    "    product_weights_dict = {\n",
    "        pid: product_weights_by_name.get(pname, 0.0001) for pid, pname in dim_product_df.set_index('Product_ID')['Product_Name'].to_dict().items()\n",
    "    }\n",
    "    geo_weights_dict = dim_geography_df.set_index('Geo_ID')['Geo_Weight'].to_dict()\n",
    "    \n",
    "    # 获取汽车销售的地理ID列表，排除非汽车销售的GEO001\n",
    "    automotive_geo_ids = dim_geography_df[dim_geography_df['Geo_ID'] != 'GEO001']['Geo_ID'].tolist()\n",
    "\n",
    "    start_year = min(y for y, q in revenue_data['Automotive sales'].keys())\n",
    "    \n",
    "    total_generated_rows = 0\n",
    "    header_written = False\n",
    "    total_automotive_units = 0\n",
    "\n",
    "    all_product_ids = list(product_weights_dict.keys())\n",
    "    # 修正: 使用所有地理ID，包括GEO001\n",
    "    all_geo_ids = list(geo_weights_dict.keys())\n",
    "    \n",
    "    combo_list = []\n",
    "    combo_weights_list = []\n",
    "    \n",
    "    for prod_id, geo_id in product(all_product_ids, all_geo_ids):\n",
    "        # 修正：非汽车产品（PRO007-PRO010）只与GEO001组合，汽车产品（PRO001-PRO005）只与非GEO001的地理ID组合\n",
    "        is_automotive_product = prod_id in ['PRO001', 'PRO002', 'PRO003', 'PRO004', 'PRO005']\n",
    "        \n",
    "        if is_automotive_product and geo_id != 'GEO001':\n",
    "            prod_weight = product_weights_dict.get(prod_id, 0.0001)\n",
    "            geo_weight = geo_weights_dict.get(geo_id, 0.0001)\n",
    "            combo_list.append((prod_id, geo_id))\n",
    "            combo_weights_list.append(prod_weight * geo_weight)\n",
    "        elif not is_automotive_product and geo_id == 'GEO001':\n",
    "            # 非汽车产品和GEO001的权重设为1，以确保被选中\n",
    "            combo_list.append((prod_id, geo_id))\n",
    "            combo_weights_list.append(1.0) # 修正: 给予高权重\n",
    "    \n",
    "    total_combo_weight = sum(combo_weights_list)\n",
    "    if total_combo_weight == 0:\n",
    "        print(\"Warning: Total combination weight is zero. Cannot generate data.\")\n",
    "        return 0, 0\n",
    "\n",
    "    combo_probabilities = np.array(combo_weights_list) / total_combo_weight\n",
    "    \n",
    "    # --------------------------\n",
    "    # Step 6: Generate Fact Table Records (Optimized Logic)\n",
    "    # --------------------------\n",
    "    non_automotive_products = {\n",
    "        'Automotive regulatory credits': 'PRO007',\n",
    "        'Services and other': 'PRO008',\n",
    "        'Automotive leasing': 'PRO009',\n",
    "        'Energy generation and storage': 'PRO010'\n",
    "    }\n",
    "    \n",
    "    # 获取现有地理维度表中，不包括GEO001的所有地理ID\n",
    "    real_geo_ids = dim_geography_df[dim_geography_df['Geo_ID'] != 'GEO001']['Geo_ID'].tolist()\n",
    "    \n",
    "    for year in range(start_year, end_date.year + 1):\n",
    "        for quarter in range(1, 5):\n",
    "            if year == 2025 and quarter > 2:\n",
    "                continue\n",
    "            \n",
    "            quarterly_revenue = {category: revenue_data.get(category, {}).get((year, quarter), 0) for category in revenue_data}\n",
    "            \n",
    "            quarter_dates_df = dim_time_df[\n",
    "                (dim_time_df['Year_Int'] == year) & (dim_time_df['Quarter_Int'] == quarter)\n",
    "            ]\n",
    "            \n",
    "            if quarter_dates_df.empty:\n",
    "                print(f\"Warning: No time IDs available for Year {year} Quarter {quarter}, skipping generation.\")\n",
    "                continue\n",
    "\n",
    "            records = []\n",
    "            \n",
    "            for category, revenue in quarterly_revenue.items():\n",
    "                if revenue > 0:\n",
    "                    if category == 'Automotive sales':\n",
    "                        total_year_units = unit_targets_by_year.get(year, 0)\n",
    "                        \n",
    "                        total_year_sales_revenue = sum(v for k, v in revenue_data['Automotive sales'].items() if k[0] == year)\n",
    "                        \n",
    "                        if total_year_sales_revenue > 0:\n",
    "                            quarter_revenue_ratio = revenue / total_year_sales_revenue\n",
    "                            target_units = int(total_year_units * quarter_revenue_ratio)\n",
    "                            \n",
    "                            if target_units > 0:\n",
    "                                print(f\"正在为{year}Q{quarter}生成 {target_units:,} 条汽车销售记录...\")\n",
    "                                \n",
    "                                sampled_combo_indices = np.random.choice(len(combo_list), size=target_units, p=combo_probabilities)\n",
    "                                average_price_per_unit = revenue / target_units\n",
    "                                \n",
    "                                for i in range(target_units):\n",
    "                                    combo_index = sampled_combo_indices[i]\n",
    "                                    product_id, geo_id = combo_list[combo_index]\n",
    "                                    \n",
    "                                    # 修正：确保汽车销售记录的geo_id不是GEO001\n",
    "                                    if geo_id == 'GEO001':\n",
    "                                        continue\n",
    "                                    \n",
    "                                    time_id = np.random.choice(quarter_dates_df['Time_ID'])\n",
    "                                    customer_id = np.random.choice(customer_ids)\n",
    "                                    \n",
    "                                    records.append({\n",
    "                                        'Time_ID': time_id,\n",
    "                                        'Geo_ID': geo_id,\n",
    "                                        'Product_ID': product_id,\n",
    "                                        'Customer_ID': customer_id,\n",
    "                                        'Sales_Units': 1,\n",
    "                                        'Is_Discounted_Sale': False,\n",
    "                                        'Revenue_USD': average_price_per_unit,\n",
    "                                        'Revenue_Category': category\n",
    "                                    })\n",
    "                                total_automotive_units += target_units\n",
    "                    else:\n",
    "                        # 修正: 非汽车销售收入不再只使用GEO001，而是随机分配给所有真实地理ID\n",
    "                        product_id = non_automotive_products.get(category, 'PRO006')\n",
    "                        quarter_time_id = quarter_dates_df.iloc[0]['Time_ID']\n",
    "                        \n",
    "                        # 新增逻辑：将非汽车销售收入拆分成多条记录，并分配给不同的真实地理位置\n",
    "                        # 这里我们简化处理，将总收入根据地理权重拆分并分配\n",
    "                        \n",
    "                        # 随机选择一个地理ID进行分配\n",
    "                        # 修正: 使用真实地理ID列表进行随机选择\n",
    "                        random_geo_id = np.random.choice(real_geo_ids)\n",
    "                        \n",
    "                        records.append({\n",
    "                            'Time_ID': quarter_time_id,\n",
    "                            'Geo_ID': random_geo_id, # 修正: 分配给一个随机的真实地理ID\n",
    "                            'Product_ID': product_id,\n",
    "                            'Customer_ID': 'CUS001',\n",
    "                            'Sales_Units': 1,\n",
    "                            'Is_Discounted_Sale': False,\n",
    "                            'Revenue_USD': revenue,\n",
    "                            'Revenue_Category': category\n",
    "                        })\n",
    "            \n",
    "            fact_sales_df_temp = pd.DataFrame(records)\n",
    "            \n",
    "            if not fact_sales_df_temp.empty:\n",
    "                fact_sales_df_temp.to_csv(output_filepath, mode='a', header=not header_written, index=False, encoding='utf-8')\n",
    "                header_written = True\n",
    "                total_generated_rows += len(fact_sales_df_temp)\n",
    "    \n",
    "    return total_generated_rows, total_automotive_units\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    \n",
    "    print(f\"Loading all dimension tables and data sources from '{output_dir}'...\")\n",
    "    \n",
    "    dim_product_df = None\n",
    "    dim_time_df = None\n",
    "    dim_customer_df = None\n",
    "    dim_geography_df = None\n",
    "    dim_prices_df = None\n",
    "    \n",
    "    try:\n",
    "        # Check if Dim_Time.csv exists, if not, generate it\n",
    "        dim_time_path = os.path.join(output_dir, 'Dim_Time.csv')\n",
    "        if not os.path.exists(dim_time_path):\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            print(\"Dim_Time.csv not found. Generating...\")\n",
    "            dim_time_df = generate_dim_time_table(datetime(2013, 1, 1), datetime(2025, 6, 30))\n",
    "            dim_time_df.to_csv(dim_time_path, index=False)\n",
    "            print(\"Dim_Time.csv generated.\")\n",
    "\n",
    "        dim_product_df = pd.read_csv(os.path.join(output_dir, 'Dim_Product.csv'))\n",
    "        dim_time_df = pd.read_csv(dim_time_path)\n",
    "        dim_customer_df = pd.read_csv(os.path.join(output_dir, 'Dim_Customer.csv'))\n",
    "        dim_geography_df = pd.read_csv(os.path.join(output_dir, 'Dim_Geography.csv'))\n",
    "        dim_prices_df = pd.read_csv(os.path.join(output_dir, 'Dim_Prices.csv'))\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: One or more required CSV files are missing. Please ensure all dimension tables are in the '{output_dir}' directory. The file '{e.filename}' was not found.\")\n",
    "    \n",
    "    if dim_product_df is None or dim_time_df is None or dim_customer_df is None or dim_geography_df is None or dim_prices_df is None:\n",
    "        print(\"Data generation failed due to missing files.\")\n",
    "    else:\n",
    "        # Extend the Product dimension\n",
    "        new_product_records = pd.DataFrame([\n",
    "            {'Product_ID': 'PRO006', 'Product_Name': 'Other Revenue'},\n",
    "            {'Product_ID': 'PRO007', 'Product_Name': 'Regulatory Credits'},\n",
    "            {'Product_ID': 'PRO008', 'Product_Name': 'Services'},\n",
    "            {'Product_ID': 'PRO009', 'Product_Name': 'Leasing'},\n",
    "            {'Product_ID': 'PRO010', 'Product_Name': 'Energy'}\n",
    "        ])\n",
    "        dim_product_df = pd.concat([dim_product_df, new_product_records], ignore_index=True)\n",
    "\n",
    "        # Extend the Customer dimension\n",
    "        new_customer_record = pd.DataFrame([{'Customer_ID': 'CUS001', 'First_Name': 'Global', 'Last_Name': 'Customer', 'Gender': 'NA'}])\n",
    "        dim_customer_df = pd.concat([dim_customer_df, new_customer_record], ignore_index=True)\n",
    "        \n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        output_filepath = os.path.join(output_dir, 'Fact_Sales.csv')\n",
    "        \n",
    "        if os.path.exists(output_filepath):\n",
    "            os.remove(output_filepath)\n",
    "    \n",
    "        print(\"Generating Fact_Sales table...\")\n",
    "        total_rows, total_automotive_units = generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath)\n",
    "    \n",
    "        if total_rows > 0:\n",
    "            end_time = time.time()\n",
    "            print(f\"Fact_Sales.csv successfully generated {total_rows:,} rows of data in {end_time - start_time:.2f} seconds.\")\n",
    "            print(f\"其中包含 {total_automotive_units:,} 条汽车销售记录。\")\n",
    "            print(\"Data generation complete!\")\n",
    "        else:\n",
    "            print(\"Data generation failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0632fd9f-44bf-4ebf-b549-57687b3280f6",
   "metadata": {},
   "source": [
    "## **带有验证机制的数据生成代码** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15db44cf-c1c7-4b43-b6e5-990a4d26a13c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all dimension tables and data sources from './output_data'...\n",
      "\n",
      "Generating Fact_Sales table...\n",
      "Generating data for Year 2013 Quarter 1...\n",
      "Generating data for Year 2013 Quarter 2...\n",
      "Generating data for Year 2013 Quarter 3...\n",
      "Generating data for Year 2013 Quarter 4...\n",
      "Generating data for Year 2014 Quarter 1...\n",
      "Generating data for Year 2014 Quarter 2...\n",
      "Generating data for Year 2014 Quarter 3...\n",
      "Generating data for Year 2014 Quarter 4...\n",
      "Generating data for Year 2015 Quarter 1...\n",
      "Generating data for Year 2015 Quarter 2...\n",
      "Generating data for Year 2015 Quarter 3...\n",
      "Generating data for Year 2015 Quarter 4...\n",
      "Generating data for Year 2016 Quarter 1...\n",
      "Generating data for Year 2016 Quarter 2...\n",
      "Generating data for Year 2016 Quarter 3...\n",
      "Generating data for Year 2016 Quarter 4...\n",
      "Generating data for Year 2017 Quarter 1...\n",
      "Generating data for Year 2017 Quarter 2...\n",
      "Generating data for Year 2017 Quarter 3...\n",
      "Generating data for Year 2017 Quarter 4...\n",
      "Generating data for Year 2018 Quarter 1...\n",
      "Generating data for Year 2018 Quarter 2...\n",
      "Generating data for Year 2018 Quarter 3...\n",
      "Generating data for Year 2018 Quarter 4...\n",
      "Generating data for Year 2019 Quarter 1...\n",
      "Generating data for Year 2019 Quarter 2...\n",
      "Generating data for Year 2019 Quarter 3...\n",
      "Generating data for Year 2019 Quarter 4...\n",
      "Generating data for Year 2020 Quarter 1...\n",
      "Generating data for Year 2020 Quarter 2...\n",
      "Generating data for Year 2020 Quarter 3...\n",
      "Generating data for Year 2020 Quarter 4...\n",
      "Generating data for Year 2021 Quarter 1...\n",
      "Generating data for Year 2021 Quarter 2...\n",
      "Generating data for Year 2021 Quarter 3...\n",
      "Generating data for Year 2021 Quarter 4...\n",
      "Generating data for Year 2022 Quarter 1...\n",
      "Generating data for Year 2022 Quarter 2...\n",
      "Generating data for Year 2022 Quarter 3...\n",
      "Generating data for Year 2022 Quarter 4...\n",
      "Generating data for Year 2023 Quarter 1...\n",
      "Generating data for Year 2023 Quarter 2...\n",
      "Generating data for Year 2023 Quarter 3...\n",
      "Generating data for Year 2023 Quarter 4...\n",
      "Generating data for Year 2024 Quarter 1...\n",
      "Generating data for Year 2024 Quarter 2...\n",
      "Generating data for Year 2024 Quarter 3...\n",
      "Generating data for Year 2024 Quarter 4...\n",
      "Generating data for Year 2025 Quarter 1...\n",
      "Generating data for Year 2025 Quarter 2...\n",
      "\n",
      "--- Generating Summary Report ---\n",
      "\n",
      "Comparing 'Automotive sales' revenue:\n",
      "  2013Q1 | Target: $400,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2013Q2 | Target: $420,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2013Q3 | Target: $450,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2013Q4 | Target: $500,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2014Q1 | Target: $700,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2014Q2 | Target: $750,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2014Q3 | Target: $800,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2014Q4 | Target: $850,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2015Q1 | Target: $900,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2015Q2 | Target: $950,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2015Q3 | Target: $1,000,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2015Q4 | Target: $1,100,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2016Q1 | Target: $1,500,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2016Q2 | Target: $1,600,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2016Q3 | Target: $1,800,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2016Q4 | Target: $2,000,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2017Q1 | Target: $2,500,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2017Q2 | Target: $2,800,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2017Q3 | Target: $3,000,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2017Q4 | Target: $3,200,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2018Q1 | Target: $3,300,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2018Q2 | Target: $3,900,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2018Q3 | Target: $6,600,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2018Q4 | Target: $7,000,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2019Q1 | Target: $3,509,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2019Q2 | Target: $5,168,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2019Q3 | Target: $5,132,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2019Q4 | Target: $6,143,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2020Q1 | Target: $4,893,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2020Q2 | Target: $4,911,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2020Q3 | Target: $7,346,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2020Q4 | Target: $9,034,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2021Q1 | Target: $8,187,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2021Q2 | Target: $9,520,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2021Q3 | Target: $11,393,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2021Q4 | Target: $15,025,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2022Q1 | Target: $15,514,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2022Q2 | Target: $13,670,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2022Q3 | Target: $17,785,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2022Q4 | Target: $20,241,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2023Q1 | Target: $18,878,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2023Q2 | Target: $20,419,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2023Q3 | Target: $18,582,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2023Q4 | Target: $20,630,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2024Q1 | Target: $16,460,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2024Q2 | Target: $18,530,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2024Q3 | Target: $18,831,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2024Q4 | Target: $18,659,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2025Q1 | Target: $12,925,000,000.00 | Generated: $0.00 | Match: False\n",
      "  2025Q2 | Target: $15,787,000,000.00 | Generated: $0.00 | Match: False\n",
      "\n",
      "Comparing 'Automotive regulatory credits' revenue:\n",
      "  2013Q1 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2013Q2 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2013Q3 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2013Q4 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2014Q1 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2014Q2 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2014Q3 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2014Q4 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2015Q1 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2015Q2 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2015Q3 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2015Q4 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2016Q1 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2016Q2 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2016Q3 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2016Q4 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2017Q1 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2017Q2 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2017Q3 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2017Q4 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2018Q1 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2018Q2 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2018Q3 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2018Q4 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2019Q1 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2019Q2 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2019Q3 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2019Q4 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2020Q1 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2020Q2 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2020Q3 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2020Q4 | Target: $0.00 | Generated: $0.00 | Match: True\n",
      "  2021Q1 | Target: $518,000,000.00 | Generated: $518,000,000.00 | Match: True\n",
      "  2021Q2 | Target: $354,000,000.00 | Generated: $354,000,000.00 | Match: True\n",
      "  2021Q3 | Target: $279,000,000.00 | Generated: $279,000,000.00 | Match: True\n",
      "  2021Q4 | Target: $314,000,000.00 | Generated: $314,000,000.00 | Match: True\n",
      "  2022Q1 | Target: $679,000,000.00 | Generated: $679,000,000.00 | Match: True\n",
      "  2022Q2 | Target: $344,000,000.00 | Generated: $344,000,000.00 | Match: True\n",
      "  2022Q3 | Target: $286,000,000.00 | Generated: $286,000,000.00 | Match: True\n",
      "  2022Q4 | Target: $467,000,000.00 | Generated: $467,000,000.00 | Match: True\n",
      "  2023Q1 | Target: $521,000,000.00 | Generated: $521,000,000.00 | Match: True\n",
      "  2023Q2 | Target: $282,000,000.00 | Generated: $282,000,000.00 | Match: True\n",
      "  2023Q3 | Target: $554,000,000.00 | Generated: $554,000,000.00 | Match: True\n",
      "  2023Q4 | Target: $433,000,000.00 | Generated: $433,000,000.00 | Match: True\n",
      "  2024Q1 | Target: $442,000,000.00 | Generated: $442,000,000.00 | Match: True\n",
      "  2024Q2 | Target: $890,000,000.00 | Generated: $890,000,000.00 | Match: True\n",
      "  2024Q3 | Target: $739,000,000.00 | Generated: $739,000,000.00 | Match: True\n",
      "  2024Q4 | Target: $692,000,000.00 | Generated: $692,000,000.00 | Match: True\n",
      "  2025Q1 | Target: $595,000,000.00 | Generated: $595,000,000.00 | Match: True\n",
      "  2025Q2 | Target: $439,000,000.00 | Generated: $439,000,000.00 | Match: True\n",
      "\n",
      "Comparing 'Automotive leasing' revenue:\n",
      "  2013Q1 | Target: $25,000,000.00 | Generated: $25,000,000.00 | Match: True\n",
      "  2013Q2 | Target: $28,000,000.00 | Generated: $28,000,000.00 | Match: True\n",
      "  2013Q3 | Target: $30,000,000.00 | Generated: $30,000,000.00 | Match: True\n",
      "  2013Q4 | Target: $32,000,000.00 | Generated: $32,000,000.00 | Match: True\n",
      "  2014Q1 | Target: $35,000,000.00 | Generated: $35,000,000.00 | Match: True\n",
      "  2014Q2 | Target: $38,000,000.00 | Generated: $38,000,000.00 | Match: True\n",
      "  2014Q3 | Target: $40,000,000.00 | Generated: $40,000,000.00 | Match: True\n",
      "  2014Q4 | Target: $42,000,000.00 | Generated: $42,000,000.00 | Match: True\n",
      "  2015Q1 | Target: $45,000,000.00 | Generated: $45,000,000.00 | Match: True\n",
      "  2015Q2 | Target: $48,000,000.00 | Generated: $48,000,000.00 | Match: True\n",
      "  2015Q3 | Target: $50,000,000.00 | Generated: $50,000,000.00 | Match: True\n",
      "  2015Q4 | Target: $55,000,000.00 | Generated: $55,000,000.00 | Match: True\n",
      "  2016Q1 | Target: $60,000,000.00 | Generated: $60,000,000.00 | Match: True\n",
      "  2016Q2 | Target: $65,000,000.00 | Generated: $65,000,000.00 | Match: True\n",
      "  2016Q3 | Target: $70,000,000.00 | Generated: $70,000,000.00 | Match: True\n",
      "  2016Q4 | Target: $75,000,000.00 | Generated: $75,000,000.00 | Match: True\n",
      "  2017Q1 | Target: $80,000,000.00 | Generated: $80,000,000.00 | Match: True\n",
      "  2017Q2 | Target: $85,000,000.00 | Generated: $85,000,000.00 | Match: True\n",
      "  2017Q3 | Target: $90,000,000.00 | Generated: $90,000,000.00 | Match: True\n",
      "  2017Q4 | Target: $95,000,000.00 | Generated: $95,000,000.00 | Match: True\n",
      "  2018Q1 | Target: $100,000,000.00 | Generated: $100,000,000.00 | Match: True\n",
      "  2018Q2 | Target: $110,000,000.00 | Generated: $110,000,000.00 | Match: True\n",
      "  2018Q3 | Target: $120,000,000.00 | Generated: $120,000,000.00 | Match: True\n",
      "  2018Q4 | Target: $130,000,000.00 | Generated: $130,000,000.00 | Match: True\n",
      "  2019Q1 | Target: $215,000,000.00 | Generated: $215,000,000.00 | Match: True\n",
      "  2019Q2 | Target: $208,000,000.00 | Generated: $208,000,000.00 | Match: True\n",
      "  2019Q3 | Target: $221,000,000.00 | Generated: $221,000,000.00 | Match: True\n",
      "  2019Q4 | Target: $225,000,000.00 | Generated: $225,000,000.00 | Match: True\n",
      "  2020Q1 | Target: $239,000,000.00 | Generated: $239,000,000.00 | Match: True\n",
      "  2020Q2 | Target: $268,000,000.00 | Generated: $268,000,000.00 | Match: True\n",
      "  2020Q3 | Target: $265,000,000.00 | Generated: $265,000,000.00 | Match: True\n",
      "  2020Q4 | Target: $280,000,000.00 | Generated: $280,000,000.00 | Match: True\n",
      "  2021Q1 | Target: $297,000,000.00 | Generated: $297,000,000.00 | Match: True\n",
      "  2021Q2 | Target: $332,000,000.00 | Generated: $332,000,000.00 | Match: True\n",
      "  2021Q3 | Target: $385,000,000.00 | Generated: $385,000,000.00 | Match: True\n",
      "  2021Q4 | Target: $628,000,000.00 | Generated: $628,000,000.00 | Match: True\n",
      "  2022Q1 | Target: $668,000,000.00 | Generated: $668,000,000.00 | Match: True\n",
      "  2022Q2 | Target: $588,000,000.00 | Generated: $588,000,000.00 | Match: True\n",
      "  2022Q3 | Target: $621,000,000.00 | Generated: $621,000,000.00 | Match: True\n",
      "  2022Q4 | Target: $599,000,000.00 | Generated: $599,000,000.00 | Match: True\n",
      "  2023Q1 | Target: $564,000,000.00 | Generated: $564,000,000.00 | Match: True\n",
      "  2023Q2 | Target: $567,000,000.00 | Generated: $567,000,000.00 | Match: True\n",
      "  2023Q3 | Target: $489,000,000.00 | Generated: $489,000,000.00 | Match: True\n",
      "  2023Q4 | Target: $500,000,000.00 | Generated: $500,000,000.00 | Match: True\n",
      "  2024Q1 | Target: $476,000,000.00 | Generated: $476,000,000.00 | Match: True\n",
      "  2024Q2 | Target: $458,000,000.00 | Generated: $458,000,000.00 | Match: True\n",
      "  2024Q3 | Target: $446,000,000.00 | Generated: $446,000,000.00 | Match: True\n",
      "  2024Q4 | Target: $447,000,000.00 | Generated: $447,000,000.00 | Match: True\n",
      "  2025Q1 | Target: $447,000,000.00 | Generated: $447,000,000.00 | Match: True\n",
      "  2025Q2 | Target: $435,000,000.00 | Generated: $435,000,000.00 | Match: True\n",
      "\n",
      "Comparing 'Energy generation and storage' revenue:\n",
      "  2013Q1 | Target: $10,000,000.00 | Generated: $10,000,000.00 | Match: True\n",
      "  2013Q2 | Target: $12,000,000.00 | Generated: $12,000,000.00 | Match: True\n",
      "  2013Q3 | Target: $14,000,000.00 | Generated: $14,000,000.00 | Match: True\n",
      "  2013Q4 | Target: $16,000,000.00 | Generated: $16,000,000.00 | Match: True\n",
      "  2014Q1 | Target: $18,000,000.00 | Generated: $18,000,000.00 | Match: True\n",
      "  2014Q2 | Target: $20,000,000.00 | Generated: $20,000,000.00 | Match: True\n",
      "  2014Q3 | Target: $22,000,000.00 | Generated: $22,000,000.00 | Match: True\n",
      "  2014Q4 | Target: $24,000,000.00 | Generated: $24,000,000.00 | Match: True\n",
      "  2015Q1 | Target: $26,000,000.00 | Generated: $26,000,000.00 | Match: True\n",
      "  2015Q2 | Target: $28,000,000.00 | Generated: $28,000,000.00 | Match: True\n",
      "  2015Q3 | Target: $30,000,000.00 | Generated: $30,000,000.00 | Match: True\n",
      "  2015Q4 | Target: $32,000,000.00 | Generated: $32,000,000.00 | Match: True\n",
      "  2016Q1 | Target: $35,000,000.00 | Generated: $35,000,000.00 | Match: True\n",
      "  2016Q2 | Target: $38,000,000.00 | Generated: $38,000,000.00 | Match: True\n",
      "  2016Q3 | Target: $40,000,000.00 | Generated: $40,000,000.00 | Match: True\n",
      "  2016Q4 | Target: $42,000,000.00 | Generated: $42,000,000.00 | Match: True\n",
      "  2017Q1 | Target: $45,000,000.00 | Generated: $45,000,000.00 | Match: True\n",
      "  2017Q2 | Target: $48,000,000.00 | Generated: $48,000,000.00 | Match: True\n",
      "  2017Q3 | Target: $50,000,000.00 | Generated: $50,000,000.00 | Match: True\n",
      "  2017Q4 | Target: $55,000,000.00 | Generated: $55,000,000.00 | Match: True\n",
      "  2018Q1 | Target: $60,000,000.00 | Generated: $60,000,000.00 | Match: True\n",
      "  2018Q2 | Target: $65,000,000.00 | Generated: $65,000,000.00 | Match: True\n",
      "  2018Q3 | Target: $70,000,000.00 | Generated: $70,000,000.00 | Match: True\n",
      "  2018Q4 | Target: $75,000,000.00 | Generated: $75,000,000.00 | Match: True\n",
      "  2019Q1 | Target: $324,000,000.00 | Generated: $324,000,000.00 | Match: True\n",
      "  2019Q2 | Target: $369,000,000.00 | Generated: $369,000,000.00 | Match: True\n",
      "  2019Q3 | Target: $402,000,000.00 | Generated: $402,000,000.00 | Match: True\n",
      "  2019Q4 | Target: $436,000,000.00 | Generated: $436,000,000.00 | Match: True\n",
      "  2020Q1 | Target: $293,000,000.00 | Generated: $293,000,000.00 | Match: True\n",
      "  2020Q2 | Target: $370,000,000.00 | Generated: $370,000,000.00 | Match: True\n",
      "  2020Q3 | Target: $579,000,000.00 | Generated: $579,000,000.00 | Match: True\n",
      "  2020Q4 | Target: $752,000,000.00 | Generated: $752,000,000.00 | Match: True\n",
      "  2021Q1 | Target: $494,000,000.00 | Generated: $494,000,000.00 | Match: True\n",
      "  2021Q2 | Target: $801,000,000.00 | Generated: $801,000,000.00 | Match: True\n",
      "  2021Q3 | Target: $806,000,000.00 | Generated: $806,000,000.00 | Match: True\n",
      "  2021Q4 | Target: $688,000,000.00 | Generated: $688,000,000.00 | Match: True\n",
      "  2022Q1 | Target: $616,000,000.00 | Generated: $616,000,000.00 | Match: True\n",
      "  2022Q2 | Target: $866,000,000.00 | Generated: $866,000,000.00 | Match: True\n",
      "  2022Q3 | Target: $1,117,000,000.00 | Generated: $1,117,000,000.00 | Match: True\n",
      "  2022Q4 | Target: $1,310,000,000.00 | Generated: $1,310,000,000.00 | Match: True\n",
      "  2023Q1 | Target: $1,529,000,000.00 | Generated: $1,529,000,000.00 | Match: True\n",
      "  2023Q2 | Target: $1,509,000,000.00 | Generated: $1,509,000,000.00 | Match: True\n",
      "  2023Q3 | Target: $1,559,000,000.00 | Generated: $1,559,000,000.00 | Match: True\n",
      "  2023Q4 | Target: $1,438,000,000.00 | Generated: $1,438,000,000.00 | Match: True\n",
      "  2024Q1 | Target: $1,635,000,000.00 | Generated: $1,635,000,000.00 | Match: True\n",
      "  2024Q2 | Target: $3,014,000,000.00 | Generated: $3,014,000,000.00 | Match: True\n",
      "  2024Q3 | Target: $2,376,000,000.00 | Generated: $2,376,000,000.00 | Match: True\n",
      "  2024Q4 | Target: $3,061,000,000.00 | Generated: $3,061,000,000.00 | Match: True\n",
      "  2025Q1 | Target: $2,730,000,000.00 | Generated: $2,730,000,000.00 | Match: True\n",
      "  2025Q2 | Target: $2,789,000,000.00 | Generated: $2,789,000,000.00 | Match: True\n",
      "\n",
      "Comparing 'Services and other' revenue:\n",
      "  2013Q1 | Target: $15,000,000.00 | Generated: $15,000,000.00 | Match: True\n",
      "  2013Q2 | Target: $17,000,000.00 | Generated: $17,000,000.00 | Match: True\n",
      "  2013Q3 | Target: $19,000,000.00 | Generated: $19,000,000.00 | Match: True\n",
      "  2013Q4 | Target: $20,000,000.00 | Generated: $20,000,000.00 | Match: True\n",
      "  2014Q1 | Target: $22,000,000.00 | Generated: $22,000,000.00 | Match: True\n",
      "  2014Q2 | Target: $24,000,000.00 | Generated: $24,000,000.00 | Match: True\n",
      "  2014Q3 | Target: $26,000,000.00 | Generated: $26,000,000.00 | Match: True\n",
      "  2014Q4 | Target: $28,000,000.00 | Generated: $28,000,000.00 | Match: True\n",
      "  2015Q1 | Target: $30,000,000.00 | Generated: $30,000,000.00 | Match: True\n",
      "  2015Q2 | Target: $32,000,000.00 | Generated: $32,000,000.00 | Match: True\n",
      "  2015Q3 | Target: $35,000,000.00 | Generated: $35,000,000.00 | Match: True\n",
      "  2015Q4 | Target: $38,000,000.00 | Generated: $38,000,000.00 | Match: True\n",
      "  2016Q1 | Target: $40,000,000.00 | Generated: $40,000,000.00 | Match: True\n",
      "  2016Q2 | Target: $45,000,000.00 | Generated: $45,000,000.00 | Match: True\n",
      "  2016Q3 | Target: $48,000,000.00 | Generated: $48,000,000.00 | Match: True\n",
      "  2016Q4 | Target: $50,000,000.00 | Generated: $50,000,000.00 | Match: True\n",
      "  2017Q1 | Target: $55,000,000.00 | Generated: $55,000,000.00 | Match: True\n",
      "  2017Q2 | Target: $58,000,000.00 | Generated: $58,000,000.00 | Match: True\n",
      "  2017Q3 | Target: $55,000,000.00 | Generated: $55,000,000.00 | Match: True\n",
      "  2017Q4 | Target: $58,000,000.00 | Generated: $58,000,000.00 | Match: True\n",
      "  2018Q1 | Target: $65,000,000.00 | Generated: $65,000,000.00 | Match: True\n",
      "  2018Q2 | Target: $70,000,000.00 | Generated: $70,000,000.00 | Match: True\n",
      "  2018Q3 | Target: $75,000,000.00 | Generated: $75,000,000.00 | Match: True\n",
      "  2018Q4 | Target: $80,000,000.00 | Generated: $80,000,000.00 | Match: True\n",
      "  2019Q1 | Target: $493,000,000.00 | Generated: $493,000,000.00 | Match: True\n",
      "  2019Q2 | Target: $605,000,000.00 | Generated: $605,000,000.00 | Match: True\n",
      "  2019Q3 | Target: $548,000,000.00 | Generated: $548,000,000.00 | Match: True\n",
      "  2019Q4 | Target: $580,000,000.00 | Generated: $580,000,000.00 | Match: True\n",
      "  2020Q1 | Target: $560,000,000.00 | Generated: $560,000,000.00 | Match: True\n",
      "  2020Q2 | Target: $487,000,000.00 | Generated: $487,000,000.00 | Match: True\n",
      "  2020Q3 | Target: $581,000,000.00 | Generated: $581,000,000.00 | Match: True\n",
      "  2020Q4 | Target: $678,000,000.00 | Generated: $678,000,000.00 | Match: True\n",
      "  2021Q1 | Target: $893,000,000.00 | Generated: $893,000,000.00 | Match: True\n",
      "  2021Q2 | Target: $951,000,000.00 | Generated: $951,000,000.00 | Match: True\n",
      "  2021Q3 | Target: $894,000,000.00 | Generated: $894,000,000.00 | Match: True\n",
      "  2021Q4 | Target: $1,064,000,000.00 | Generated: $1,064,000,000.00 | Match: True\n",
      "  2022Q1 | Target: $1,279,000,000.00 | Generated: $1,279,000,000.00 | Match: True\n",
      "  2022Q2 | Target: $1,466,000,000.00 | Generated: $1,466,000,000.00 | Match: True\n",
      "  2022Q3 | Target: $1,645,000,000.00 | Generated: $1,645,000,000.00 | Match: True\n",
      "  2022Q4 | Target: $1,701,000,000.00 | Generated: $1,701,000,000.00 | Match: True\n",
      "  2023Q1 | Target: $1,837,000,000.00 | Generated: $1,837,000,000.00 | Match: True\n",
      "  2023Q2 | Target: $2,150,000,000.00 | Generated: $2,150,000,000.00 | Match: True\n",
      "  2023Q3 | Target: $2,166,000,000.00 | Generated: $2,166,000,000.00 | Match: True\n",
      "  2023Q4 | Target: $2,166,000,000.00 | Generated: $2,166,000,000.00 | Match: True\n",
      "  2024Q1 | Target: $2,288,000,000.00 | Generated: $2,288,000,000.00 | Match: True\n",
      "  2024Q2 | Target: $2,608,000,000.00 | Generated: $2,608,000,000.00 | Match: True\n",
      "  2024Q3 | Target: $2,790,000,000.00 | Generated: $2,790,000,000.00 | Match: True\n",
      "  2024Q4 | Target: $2,848,000,000.00 | Generated: $2,848,000,000.00 | Match: True\n",
      "  2025Q1 | Target: $2,638,000,000.00 | Generated: $2,638,000,000.00 | Match: True\n",
      "  2025Q2 | Target: $3,046,000,000.00 | Generated: $3,046,000,000.00 | Match: True\n",
      "\n",
      "Fact_Sales.csv successfully generated 43,268 rows of data in 8.43 seconds.\n",
      "其中包含 0 条汽车销售记录。\n",
      "Data generation complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# --------------------------\n",
    "# 生成 Dim_Time 表的函数\n",
    "# --------------------------\n",
    "def generate_dim_time_table(start_date, end_date):\n",
    "    \"\"\"\n",
    "    生成一个包含所有必要列的时间维度表 (dim_time_df)。\n",
    "    \"\"\"\n",
    "    time_series = pd.date_range(start=start_date, end=end_date)\n",
    "    dim_time_df = pd.DataFrame(time_series, columns=['Full_Date'])\n",
    "    \n",
    "    dim_time_df['Time_ID'] = dim_time_df['Full_Date'].apply(lambda x: int(x.strftime('%Y%m%d')))\n",
    "    \n",
    "    dim_time_df['Year'] = dim_time_df['Full_Date'].dt.year\n",
    "    dim_time_df['Quarter_of_Year'] = dim_time_df['Full_Date'].dt.quarter\n",
    "    dim_time_df['Month_of_Year'] = dim_time_df['Full_Date'].dt.month\n",
    "    dim_time_df['Day_of_Month'] = dim_time_df['Full_Date'].dt.day\n",
    "    dim_time_df['Day_of_Week'] = dim_time_df['Full_Date'].dt.dayofweek\n",
    "    dim_time_df['Week_of_Year'] = dim_time_df['Full_Date'].dt.isocalendar().week.astype(int)\n",
    "    \n",
    "    dim_time_df['Day_Name'] = dim_time_df['Full_Date'].dt.day_name()\n",
    "    dim_time_df['Month_Name'] = dim_time_df['Full_Date'].dt.month_name()\n",
    "    \n",
    "    dim_time_df['Is_Weekend'] = dim_time_df['Day_of_Week'] >= 5\n",
    "    \n",
    "    return dim_time_df\n",
    "\n",
    "# --------------------------\n",
    "# 生成 Fact_Sales 表的函数\n",
    "# --------------------------\n",
    "def generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath):\n",
    "    \"\"\"\n",
    "    生成 Fact_Sales 表，其逻辑经过优化以匹配财务数据。\n",
    "    \"\"\"\n",
    "    start_date_of_data = datetime(2013, 1, 1)\n",
    "    end_date_of_data = datetime(2025, 6, 30)\n",
    "\n",
    "    # --------------------------\n",
    "    # 步骤 1: 解析和加载数据 (保持不变)\n",
    "    # --------------------------\n",
    "    revenue_data = {\n",
    "        'Automotive sales': {\n",
    "            (2013, 1): 400.0e6, (2013, 2): 420.0e6, (2013, 3): 450.0e6, (2013, 4): 500.0e6,\n",
    "            (2014, 1): 700.0e6, (2014, 2): 750.0e6, (2014, 3): 800.0e6, (2014, 4): 850.0e6,\n",
    "            (2015, 1): 900.0e6, (2015, 2): 950.0e6, (2015, 3): 1000.0e6, (2015, 4): 1100.0e6,\n",
    "            (2016, 1): 1500.0e6, (2016, 2): 1600.0e6, (2016, 3): 1800.0e6, (2016, 4): 2000.0e6,\n",
    "            (2017, 1): 2500.0e6, (2017, 2): 2800.0e6, (2017, 3): 3000.0e6, (2017, 4): 3200.0e6,\n",
    "            (2018, 1): 3300.0e6, (2018, 2): 3900.0e6, (2018, 3): 6600.0e6, (2018, 4): 7000.0e6,\n",
    "            (2019, 1): 3509.0e6, (2019, 2): 5168.0e6, (2019, 3): 5132.0e6, (2019, 4): 6143.0e6,\n",
    "            (2020, 1): 4893.0e6, (2020, 2): 4911.0e6, (2020, 3): 7346.0e6, (2020, 4): 9034.0e6,\n",
    "            (2021, 1): 8187.0e6, (2021, 2): 9520.0e6, (2021, 3): 11393.0e6, (2021, 4): 15025.0e6,\n",
    "            (2022, 1): 15514.0e6, (2022, 2): 13670.0e6, (2022, 3): 17785.0e6, (2022, 4): 20241.0e6,\n",
    "            (2023, 1): 18878.0e6, (2023, 2): 20419.0e6, (2023, 3): 18582.0e6, (2023, 4): 20630.0e6,\n",
    "            (2024, 1): 16460.0e6, (2024, 2): 18530.0e6, (2024, 3): 18831.0e6, (2024, 4): 18659.0e6,\n",
    "            (2025, 1): 12925.0e6, (2025, 2): 15787.0e6\n",
    "        },\n",
    "        'Automotive regulatory credits': {\n",
    "            (2013, 1): 0.0e6, (2013, 2): 0.0e6, (2013, 3): 0.0e6, (2013, 4): 0.0e6,\n",
    "            (2014, 1): 0.0e6, (2014, 2): 0.0e6, (2014, 3): 0.0e6, (2014, 4): 0.0e6,\n",
    "            (2015, 1): 0.0e6, (2015, 2): 0.0e6, (2015, 3): 0.0e6, (2015, 4): 0.0e6,\n",
    "            (2016, 1): 0.0e6, (2016, 2): 0.0e6, (2016, 3): 0.0e6, (2016, 4): 0.0e6,\n",
    "            (2017, 1): 0.0e6, (2017, 2): 0.0e6, (2017, 3): 0.0e6, (2017, 4): 0.0e6,\n",
    "            (2018, 1): 0.0e6, (2018, 2): 0.0e6, (2018, 3): 0.0e6, (2018, 4): 0.0e6,\n",
    "            (2019, 1): 0.0e6, (2019, 2): 0.0e6, (2019, 3): 0.0e6, (2019, 4): 0.0e6,\n",
    "            (2020, 1): 0.0e6, (2020, 2): 0.0e6, (2020, 3): 0.0e6, (2020, 4): 0.0e6,\n",
    "            (2021, 1): 518.0e6, (2021, 2): 354.0e6, (2021, 3): 279.0e6, (2021, 4): 314.0e6,\n",
    "            (2022, 1): 679.0e6, (2022, 2): 344.0e6, (2022, 3): 286.0e6, (2022, 4): 467.0e6,\n",
    "            (2023, 1): 521.0e6, (2023, 2): 282.0e6, (2023, 3): 554.0e6, (2023, 4): 433.0e6,\n",
    "            (2024, 1): 442.0e6, (2024, 2): 890.0e6, (2024, 3): 739.0e6, (2024, 4): 692.0e6,\n",
    "            (2025, 1): 595.0e6, (2025, 2): 439.0e6\n",
    "        },\n",
    "        'Automotive leasing': {\n",
    "            (2013, 1): 25.0e6, (2013, 2): 28.0e6, (2013, 3): 30.0e6, (2013, 4): 32.0e6,\n",
    "            (2014, 1): 35.0e6, (2014, 2): 38.0e6, (2014, 3): 40.0e6, (2014, 4): 42.0e6,\n",
    "            (2015, 1): 45.0e6, (2015, 2): 48.0e6, (2015, 3): 50.0e6, (2015, 4): 55.0e6,\n",
    "            (2016, 1): 60.0e6, (2016, 2): 65.0e6, (2016, 3): 70.0e6, (2016, 4): 75.0e6,\n",
    "            (2017, 1): 80.0e6, (2017, 2): 85.0e6, (2017, 3): 90.0e6, (2017, 4): 95.0e6,\n",
    "            (2018, 1): 100.0e6, (2018, 2): 110.0e6, (2018, 3): 120.0e6, (2018, 4): 130.0e6,\n",
    "            (2019, 1): 215.0e6, (2019, 2): 208.0e6, (2019, 3): 221.0e6, (2019, 4): 225.0e6,\n",
    "            (2020, 1): 239.0e6, (2020, 2): 268.0e6, (2020, 3): 265.0e6, (2020, 4): 280.0e6,\n",
    "            (2021, 1): 297.0e6, (2021, 2): 332.0e6, (2021, 3): 385.0e6, (2021, 4): 628.0e6,\n",
    "            (2022, 1): 668.0e6, (2022, 2): 588.0e6, (2022, 3): 621.0e6, (2022, 4): 599.0e6,\n",
    "            (2023, 1): 564.0e6, (2023, 2): 567.0e6, (2023, 3): 489.0e6, (2023, 4): 500.0e6,\n",
    "            (2024, 1): 476.0e6, (2024, 2): 458.0e6, (2024, 3): 446.0e6, (2024, 4): 447.0e6,\n",
    "            (2025, 1): 447.0e6, (2025, 2): 435.0e6\n",
    "        },\n",
    "        'Energy generation and storage': {\n",
    "            (2013, 1): 10.0e6, (2013, 2): 12.0e6, (2013, 3): 14.0e6, (2013, 4): 16.0e6,\n",
    "            (2014, 1): 18.0e6, (2014, 2): 20.0e6, (2014, 3): 22.0e6, (2014, 4): 24.0e6,\n",
    "            (2015, 1): 26.0e6, (2015, 2): 28.0e6, (2015, 3): 30.0e6, (2015, 4): 32.0e6,\n",
    "            (2016, 1): 35.0e6, (2016, 2): 38.0e6, (2016, 3): 40.0e6, (2016, 4): 42.0e6,\n",
    "            (2017, 1): 45.0e6, (2017, 2): 48.0e6, (2017, 3): 50.0e6, (2017, 4): 55.0e6,\n",
    "            (2018, 1): 60.0e6, (2018, 2): 65.0e6, (2018, 3): 70.0e6, (2018, 4): 75.0e6,\n",
    "            (2019, 1): 324.0e6, (2019, 2): 369.0e6, (2019, 3): 402.0e6, (2019, 4): 436.0e6,\n",
    "            (2020, 1): 293.0e6, (2020, 2): 370.0e6, (2020, 3): 579.0e6, (2020, 4): 752.0e6,\n",
    "            (2021, 1): 494.0e6, (2021, 2): 801.0e6, (2021, 3): 806.0e6, (2021, 4): 688.0e6,\n",
    "            (2022, 1): 616.0e6, (2022, 2): 866.0e6, (2022, 3): 1117.0e6, (2022, 4): 1310.0e6,\n",
    "            (2023, 1): 1529.0e6, (2023, 2): 1509.0e6, (2023, 3): 1559.0e6, (2023, 4): 1438.0e6,\n",
    "            (2024, 1): 1635.0e6, (2024, 2): 3014.0e6, (2024, 3): 2376.0e6, (2024, 4): 3061.0e6,\n",
    "            (2025, 1): 2730.0e6, (2025, 2): 2789.0e6\n",
    "        },\n",
    "        'Services and other': {\n",
    "            (2013, 1): 15.0e6, (2013, 2): 17.0e6, (2013, 3): 19.0e6, (2013, 4): 20.0e6,\n",
    "            (2014, 1): 22.0e6, (2014, 2): 24.0e6, (2014, 3): 26.0e6, (2014, 4): 28.0e6,\n",
    "            (2015, 1): 30.0e6, (2015, 2): 32.0e6, (2015, 3): 35.0e6, (2015, 4): 38.0e6,\n",
    "            (2016, 1): 40.0e6, (2016, 2): 45.0e6, (2016, 3): 48.0e6, (2016, 4): 50.0e6,\n",
    "            (2017, 1): 55.0e6, (2017, 2): 58.0e6, (2017, 3): 55.0e6, (2017, 4): 58.0e6,\n",
    "            (2018, 1): 65.0e6, (2018, 2): 70.0e6, (2018, 3): 75.0e6, (2018, 4): 80.0e6,\n",
    "            (2019, 1): 493.0e6, (2019, 2): 605.0e6, (2019, 3): 548.0e6, (2019, 4): 580.0e6,\n",
    "            (2020, 1): 560.0e6, (2020, 2): 487.0e6, (2020, 3): 581.0e6, (2020, 4): 678.0e6,\n",
    "            (2021, 1): 893.0e6, (2021, 2): 951.0e6, (2021, 3): 894.0e6, (2021, 4): 1064.0e6,\n",
    "            (2022, 1): 1279.0e6, (2022, 2): 1466.0e6, (2022, 3): 1645.0e6, (2022, 4): 1701.0e6,\n",
    "            (2023, 1): 1837.0e6, (2023, 2): 2150.0e6, (2023, 3): 2166.0e6, (2023, 4): 2166.0e6,\n",
    "            (2024, 1): 2288.0e6, (2024, 2): 2608.0e6, (2024, 3): 2790.0e6, (2024, 4): 2848.0e6,\n",
    "            (2025, 1): 2638.0e6, (2025, 2): 3046.0e6\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # --------------------------\n",
    "    # 步骤 2: 数据清理和预处理 (保持不变)\n",
    "    # --------------------------\n",
    "    if 'Product_Name' not in dim_product_df.columns:\n",
    "        product_id_to_name = {\n",
    "            'PRO001': 'Model S', 'PRO002': 'Model X', 'PRO003': 'Model 3', 'PRO004': 'Model Y', 'PRO005': 'Cybertruck',\n",
    "            'PRO007': 'Regulatory Credits', 'PRO008': 'Services', 'PRO009': 'Leasing', 'PRO010': 'Energy'\n",
    "        }\n",
    "        dim_product_df['Product_Name'] = dim_product_df['Product_ID'].map(product_id_to_name).fillna('Other')\n",
    "    \n",
    "    dim_time_df['Full_Date'] = pd.to_datetime(dim_time_df['Full_Date'])\n",
    "    \n",
    "    # --------------------------\n",
    "    # 步骤 3: 定义权重和映射\n",
    "    # --------------------------\n",
    "    non_automotive_products_map = {\n",
    "        'Automotive regulatory credits': 'PRO007',\n",
    "        'Automotive leasing': 'PRO009',\n",
    "        'Energy generation and storage': 'PRO010',\n",
    "        'Services and other': 'PRO008'\n",
    "    }\n",
    "\n",
    "    automotive_product_ids = ['PRO001', 'PRO002', 'PRO003', 'PRO004', 'PRO005']\n",
    "    non_automotive_product_ids = [p_id for p_name, p_id in non_automotive_products_map.items()]\n",
    "\n",
    "    product_weights_by_name = {\n",
    "        'Model S': 0.05, 'Model X': 0.05, 'Model 3': 0.45, 'Model Y': 0.40, 'Cybertruck': 0.05\n",
    "    }\n",
    "    \n",
    "    continent_weights = {'North America': 0.45, 'Europe': 0.30, 'Asia': 0.23, 'Oceania': 0.02}\n",
    "    country_weights = {'United States': 0.80, 'Canada': 0.20, 'China': 0.70, 'Japan': 0.18, 'South Korea': 0.13, 'Germany': 0.30, 'United Kingdom': 0.20, 'France': 0.15, 'Norway': 0.10, 'Australia': 0.75, 'New Zealand': 0.25, 'Taiwan': 0.1}\n",
    "    state_province_weights = {\n",
    "        'California': 0.40, 'Texas': 0.25, 'Florida': 0.15, 'Washington': 0.10, 'New York': 0.10,\n",
    "        'Ontario': 0.4, 'Quebec': 0.25, 'British Columbia': 0.2, 'Alberta': 0.15,\n",
    "        'Shanghai': 0.50, 'Beijing': 0.20, 'Guangdong': 0.20, 'Zhejiang': 0.10,\n",
    "        'Taipei': 0.5, 'New Taipei City': 0.2, 'Taichung': 0.1, 'Kaohsiung': 0.1, 'Tainan': 0.05, 'Taoyuan': 0.05,\n",
    "        'Bavaria': 0.40, 'North Rhine-Westphalia': 0.25, 'Baden-Württemberg': 0.15, 'Berlin': 0.10,\n",
    "        'Greater London': 0.50, 'South East England': 0.25, 'North West England': 0.15, 'West Midlands': 0.10,\n",
    "        'Île-de-France': 0.60, 'Auvergne-Rhône-Alpes': 0.20, 'Nouvelle-Aquitaine': 0.10, 'Provence-Alpes-Côte d\\'Azur': 0.10,\n",
    "        'Oslo': 0.70, 'Vestland': 0.15, 'Viken': 0.10, 'Trøndelag': 0.05,\n",
    "        'New South Wales': 0.5, 'Victoria': 0.3, 'Queensland': 0.1, 'Western Australia': 0.05, 'South Australia': 0.05,\n",
    "        'Auckland': 0.6, 'Wellington': 0.2, 'Canterbury': 0.1, 'Otago': 0.05, 'Waikato': 0.05,\n",
    "    }\n",
    "\n",
    "    asia_countries = ['China', 'Japan', 'South Korea', 'Singapore', 'India', 'Indonesia', 'Thailand', 'Malaysia', 'Taiwan']\n",
    "    oceania_countries = ['Australia', 'New Zealand']\n",
    "    europe_countries = ['Germany', 'United Kingdom', 'France', 'Norway', 'Netherlands', 'Sweden', 'Italy', 'Switzerland', 'Spain', 'Belgium', 'Austria', 'Denmark', 'Finland', 'Portugal', 'Ireland', 'Luxembourg', 'Iceland']\n",
    "    \n",
    "    def get_continent(country):\n",
    "        if country in asia_countries: return 'Asia'\n",
    "        if country in oceania_countries: return 'Oceania'\n",
    "        if country in europe_countries: return 'Europe'\n",
    "        if country in ['United States', 'Canada', 'Mexico']: return 'North America'\n",
    "        return 'Other'\n",
    "    \n",
    "    dim_geography_df['Continent'] = dim_geography_df['Country'].apply(get_continent).astype(str)\n",
    "\n",
    "    dim_geography_df['Geo_Weight'] = 0.0\n",
    "    for continent, c_weight in continent_weights.items():\n",
    "        countries_in_continent = dim_geography_df[dim_geography_df['Continent'] == continent]['Country'].unique()\n",
    "        for country in countries_in_continent:\n",
    "            country_w = country_weights.get(country, 0.01)\n",
    "            states = dim_geography_df[dim_geography_df['Country'] == country]['State_Province'].unique()\n",
    "            for state in states:\n",
    "                state_w = state_province_weights.get(state, 0.01)\n",
    "                mask = (dim_geography_df['Country'] == country) & (dim_geography_df['State_Province'] == state)\n",
    "                dim_geography_df.loc[mask, 'Geo_Weight'] = c_weight * country_w * state_w\n",
    "    dim_geography_df['Geo_Weight'] = dim_geography_df['Geo_Weight'].replace(0.0, 0.0001)\n",
    "\n",
    "    customer_ids = dim_customer_df['Customer_ID'].values\n",
    "    \n",
    "    # 修正：将 dim_prices_df 转换为易于查找的字典，使用 (年份, 季度) 作为键\n",
    "    dim_prices_df['Quarter_Start_Date'] = pd.to_datetime(dim_prices_df['Quarter_Start_Date'])\n",
    "    dim_prices_df['Year'] = dim_prices_df['Quarter_Start_Date'].dt.year\n",
    "    dim_prices_df['Quarter'] = dim_prices_df['Quarter_Start_Date'].dt.quarter\n",
    "    \n",
    "    price_lookup = dim_prices_df.set_index(['Year', 'Quarter', 'Product_ID'])[['Standard_Price_USD', 'Discounted_Price_USD']].to_dict('index')\n",
    "\n",
    "    # --------------------------\n",
    "    # 步骤 4: 精细化数据生成逻辑\n",
    "    # --------------------------\n",
    "    \n",
    "    header_written = False\n",
    "    total_generated_rows = 0\n",
    "    total_automotive_units = 0\n",
    "    \n",
    "    all_geo_ids = dim_geography_df['Geo_ID'].tolist()\n",
    "    geo_weights_dict = dim_geography_df.set_index('Geo_ID')['Geo_Weight'].to_dict()\n",
    "\n",
    "    # 创建汽车产品-地理组合及其权重\n",
    "    automotive_combos = []\n",
    "    automotive_weights = []\n",
    "    for prod_id in automotive_product_ids:\n",
    "        for geo_id in all_geo_ids:\n",
    "            if geo_id != 'GEO001':\n",
    "                prod_weight = product_weights_by_name.get(dim_product_df[dim_product_df['Product_ID'] == prod_id]['Product_Name'].iloc[0], 0)\n",
    "                geo_weight = geo_weights_dict.get(geo_id, 0)\n",
    "                if prod_weight > 0 and geo_weight > 0:\n",
    "                    automotive_combos.append((prod_id, geo_id))\n",
    "                    automotive_weights.append(prod_weight * geo_weight)\n",
    "    \n",
    "    total_automotive_weight = sum(automotive_weights)\n",
    "    automotive_probabilities = np.array(automotive_weights) / total_automotive_weight if total_automotive_weight > 0 else np.array([])\n",
    "\n",
    "    # 创建非汽车产品-地理组合及其权重\n",
    "    non_automotive_combos = []\n",
    "    non_automotive_weights = []\n",
    "    for category, prod_id in non_automotive_products_map.items():\n",
    "        if prod_id in ['PRO007', 'PRO009']: #Credits and Leasing, using GEO001\n",
    "            non_automotive_combos.append((prod_id, 'GEO001'))\n",
    "            non_automotive_weights.append(1.0)\n",
    "        else: # Services and Energy, distribute by geography\n",
    "            for geo_id in dim_geography_df[dim_geography_df['Geo_ID'] != 'GEO001']['Geo_ID'].tolist():\n",
    "                non_automotive_combos.append((prod_id, geo_id))\n",
    "                non_automotive_weights.append(geo_weights_dict.get(geo_id, 0.0001))\n",
    "    \n",
    "    total_non_automotive_weight = sum(non_automotive_weights)\n",
    "    non_automotive_probabilities = np.array(non_automotive_weights) / total_non_automotive_weight if total_non_automotive_weight > 0 else np.array([])\n",
    "    \n",
    "    # 主生成循环\n",
    "    start_year = min(y for y, q in revenue_data['Automotive sales'].keys())\n",
    "    \n",
    "    for year in range(start_year, end_date_of_data.year + 1):\n",
    "        for quarter in range(1, 5):\n",
    "            if year == 2025 and quarter > 2:\n",
    "                continue\n",
    "\n",
    "            quarter_key = (year, quarter)\n",
    "            \n",
    "            print(f\"Generating data for Year {year} Quarter {quarter}...\")\n",
    "\n",
    "            # **核心逻辑 1: 分配汽车销售收入 (调整后)**\n",
    "            automotive_revenue = revenue_data.get('Automotive sales', {}).get(quarter_key, 0)\n",
    "            if automotive_revenue > 0 and len(automotive_probabilities) > 0:\n",
    "                records = []\n",
    "                \n",
    "                # 1. 计算每个产品-地理组合的销售单位数\n",
    "                \n",
    "                # 确保每个产品都能查找到价格，否则 total_avg_price 会是 0\n",
    "                total_avg_price = 0\n",
    "                for prod_id in automotive_product_ids:\n",
    "                    price_info = price_lookup.get((year, quarter, prod_id))\n",
    "                    if price_info:\n",
    "                        product_name = dim_product_df[dim_product_df['Product_ID'] == prod_id]['Product_Name'].iloc[0]\n",
    "                        price = price_info.get('Standard_Price_USD', 0)\n",
    "                        weight = product_weights_by_name.get(product_name, 0)\n",
    "                        total_avg_price += price * weight\n",
    "\n",
    "                if total_avg_price > 0:\n",
    "                    total_units = round(automotive_revenue / total_avg_price)\n",
    "                    \n",
    "                    # 2. 按比例分配单位数\n",
    "                    distributed_units = {combo: total_units * prob for combo, prob in zip(automotive_combos, automotive_probabilities)}\n",
    "                    \n",
    "                    # 3. 生成记录\n",
    "                    for (prod_id, geo_id), units_share in distributed_units.items():\n",
    "                        units_to_generate = round(units_share)\n",
    "                        if units_to_generate > 0:\n",
    "                            try:\n",
    "                                price_info = price_lookup.get((year, quarter, prod_id))\n",
    "                                if not price_info:\n",
    "                                    continue\n",
    "                                unit_price = price_info['Standard_Price_USD']\n",
    "                                \n",
    "                                for _ in range(int(units_to_generate)):\n",
    "                                    time_id = np.random.choice(dim_time_df[(dim_time_df['Year'] == year) & (dim_time_df['Quarter_of_Year'] == quarter)]['Time_ID'])\n",
    "                                    # Ensure there are customers to choose from\n",
    "                                    available_customers = dim_customer_df[dim_customer_df['Customer_ID'] != 'CUS001']['Customer_ID']\n",
    "                                    if not available_customers.empty:\n",
    "                                        customer_id = np.random.choice(available_customers)\n",
    "                                    else:\n",
    "                                        customer_id = 'CUS001'\n",
    "                                        \n",
    "                                    records.append({\n",
    "                                        'Time_ID': time_id,\n",
    "                                        'Geo_ID': geo_id,\n",
    "                                        'Product_ID': prod_id,\n",
    "                                        'Customer_ID': customer_id,\n",
    "                                        'Sales_Units': 1,\n",
    "                                        'Is_Discounted_Sale': False,\n",
    "                                        'Revenue_USD': unit_price,\n",
    "                                        'Revenue_Category': 'Automotive sales'\n",
    "                                    })\n",
    "                            except KeyError:\n",
    "                                pass # 忽略缺失价格数据\n",
    "                    \n",
    "                    fact_sales_df_temp = pd.DataFrame(records)\n",
    "                    if not fact_sales_df_temp.empty:\n",
    "                        fact_sales_df_temp.to_csv(output_filepath, mode='a', header=not header_written, index=False, encoding='utf-8')\n",
    "                        header_written = True\n",
    "                        total_generated_rows += len(fact_sales_df_temp)\n",
    "                        total_automotive_units += fact_sales_df_temp['Sales_Units'].sum()\n",
    "\n",
    "            # **核心逻辑 2: 分配非汽车销售收入 (保持不变)**\n",
    "            for category, prod_id in non_automotive_products_map.items():\n",
    "                non_automotive_revenue = revenue_data.get(category, {}).get(quarter_key, 0)\n",
    "                if non_automotive_revenue > 0:\n",
    "                    records = []\n",
    "                    \n",
    "                    category_combos = [c for c in non_automotive_combos if c[0] == prod_id]\n",
    "                    category_weights = [w for c, w in zip(non_automotive_combos, non_automotive_weights) if c[0] == prod_id]\n",
    "                    total_cat_weight = sum(category_weights)\n",
    "                    category_probabilities = np.array(category_weights) / total_cat_weight if total_cat_weight > 0 else np.array([])\n",
    "                    \n",
    "                    if len(category_probabilities) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    distributed_revenue = {combo: non_automotive_revenue * prob for combo, prob in zip(category_combos, category_probabilities)}\n",
    "                    \n",
    "                    for (na_prod_id, na_geo_id), na_revenue_share in distributed_revenue.items():\n",
    "                        if na_revenue_share > 0:\n",
    "                            time_id = np.random.choice(dim_time_df[(dim_time_df['Year'] == year) & (dim_time_df['Quarter_of_Year'] == quarter)]['Time_ID'])\n",
    "                            records.append({\n",
    "                                'Time_ID': time_id,\n",
    "                                'Geo_ID': na_geo_id,\n",
    "                                'Product_ID': na_prod_id,\n",
    "                                'Customer_ID': 'CUS001',\n",
    "                                'Sales_Units': 1,\n",
    "                                'Is_Discounted_Sale': False,\n",
    "                                'Revenue_USD': na_revenue_share,\n",
    "                                'Revenue_Category': category\n",
    "                            })\n",
    "                    \n",
    "                    fact_sales_df_temp = pd.DataFrame(records)\n",
    "                    if not fact_sales_df_temp.empty:\n",
    "                        fact_sales_df_temp.to_csv(output_filepath, mode='a', header=not header_written, index=False, encoding='utf-8')\n",
    "                        header_written = True\n",
    "                        total_generated_rows += len(fact_sales_df_temp)\n",
    "\n",
    "    # 最终汇总验证\n",
    "    if os.path.exists(output_filepath):\n",
    "        print(\"\\n--- Generating Summary Report ---\")\n",
    "        final_df = pd.read_csv(output_filepath)\n",
    "        final_df['Full_Date'] = pd.to_datetime(final_df['Time_ID'], format='%Y%m%d')\n",
    "        final_df['Year'] = final_df['Full_Date'].dt.year\n",
    "        final_df['Quarter'] = final_df['Full_Date'].dt.quarter\n",
    "        \n",
    "        summary = final_df.groupby(['Revenue_Category', 'Year', 'Quarter'])['Revenue_USD'].sum().reset_index()\n",
    "\n",
    "        for category, quarterly_data in revenue_data.items():\n",
    "            print(f\"\\nComparing '{category}' revenue:\")\n",
    "            for (year, quarter), target_revenue in quarterly_data.items():\n",
    "                generated_revenue = summary[(summary['Revenue_Category'] == category) & (summary['Year'] == year) & (summary['Quarter'] == quarter)]['Revenue_USD'].sum()\n",
    "                \n",
    "                match = np.isclose(target_revenue, generated_revenue, atol=1e-2)\n",
    "                print(f\"  {year}Q{quarter} | Target: ${target_revenue:,.2f} | Generated: ${generated_revenue:,.2f} | Match: {match}\")\n",
    "\n",
    "    return total_generated_rows, total_automotive_units\n",
    "\n",
    "# --------------------------\n",
    "# 修正后的主程序\n",
    "# --------------------------\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    \n",
    "    print(f\"Loading all dimension tables and data sources from '{output_dir}'...\")\n",
    "    \n",
    "    dim_product_df = None\n",
    "    dim_time_df = None\n",
    "    dim_customer_df = None\n",
    "    dim_geography_df = None\n",
    "    dim_prices_df = None\n",
    "    \n",
    "    try:\n",
    "        dim_time_path = os.path.join(output_dir, 'Dim_Time.csv')\n",
    "        if not os.path.exists(dim_time_path):\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            print(\"Dim_Time.csv not found. Generating...\")\n",
    "            dim_time_df_temp = generate_dim_time_table(datetime(2013, 1, 1), datetime(2025, 6, 30))\n",
    "            dim_time_df_temp.to_csv(dim_time_path, index=False)\n",
    "            print(\"Dim_Time.csv generated.\")\n",
    "\n",
    "        # 加载 Dim_Time.csv 并确保数据类型正确\n",
    "        dim_time_df = pd.read_csv(dim_time_path)\n",
    "        dim_time_df['Full_Date'] = pd.to_datetime(dim_time_df['Full_Date'])\n",
    "        dim_time_df['Time_ID'] = dim_time_df['Full_Date'].apply(lambda x: int(x.strftime('%Y%m%d')))\n",
    "        dim_time_df['Year'] = dim_time_df['Full_Date'].dt.year\n",
    "        dim_time_df['Quarter_of_Year'] = dim_time_df['Full_Date'].dt.quarter\n",
    "        \n",
    "        # 加载其他维度表\n",
    "        dim_product_df = pd.read_csv(os.path.join(output_dir, 'Dim_Product.csv'))\n",
    "        dim_customer_df = pd.read_csv(os.path.join(output_dir, 'Dim_Customer.csv'))\n",
    "        dim_geography_df = pd.read_csv(os.path.join(output_dir, 'Dim_Geography.csv'))\n",
    "        dim_prices_df = pd.read_csv(os.path.join(output_dir, 'Dim_Prices.csv'))\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: One or more required CSV files are missing. Please ensure all dimension tables are in the '{output_dir}' directory. The file '{e.filename}' was not found.\")\n",
    "    \n",
    "    if dim_product_df is None or dim_time_df is None or dim_customer_df is None or dim_geography_df is None or dim_prices_df is None:\n",
    "        print(\"Data generation failed due to missing files.\")\n",
    "    else:\n",
    "        new_product_records = pd.DataFrame([\n",
    "            {'Product_ID': 'PRO006', 'Product_Name': 'Other Revenue'},\n",
    "            {'Product_ID': 'PRO007', 'Product_Name': 'Regulatory Credits'},\n",
    "            {'Product_ID': 'PRO008', 'Product_Name': 'Services'},\n",
    "            {'Product_ID': 'PRO009', 'Product_Name': 'Leasing'},\n",
    "            {'Product_ID': 'PRO010', 'Product_Name': 'Energy'}\n",
    "        ])\n",
    "        dim_product_df = pd.concat([dim_product_df, new_product_records], ignore_index=True)\n",
    "\n",
    "        new_customer_record = pd.DataFrame([{'Customer_ID': 'CUS001', 'First_Name': 'Global', 'Last_Name': 'Customer', 'Gender': 'NA'}])\n",
    "        dim_customer_df = pd.concat([dim_customer_df, new_customer_record], ignore_index=True)\n",
    "        \n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        output_filepath = os.path.join(output_dir, 'Fact_Sales.csv')\n",
    "        \n",
    "        if os.path.exists(output_filepath):\n",
    "            os.remove(output_filepath)\n",
    "    \n",
    "        print(\"\\nGenerating Fact_Sales table...\")\n",
    "        total_rows, total_automotive_units = generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath)\n",
    "    \n",
    "        if total_rows > 0:\n",
    "            end_time = time.time()\n",
    "            print(f\"\\nFact_Sales.csv successfully generated {total_rows:,} rows of data in {end_time - start_time:.2f} seconds.\")\n",
    "            print(f\"其中包含 {total_automotive_units:,} 条汽车销售记录。\")\n",
    "            print(\"Data generation complete!\")\n",
    "        else:\n",
    "            print(\"Data generation failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fff6e6-ef31-4632-82ea-dc3ff67cd310",
   "metadata": {},
   "source": [
    "## **有5大类销售数据** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56d81aba-bee1-4e7e-a9cd-e4e0a12373c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all dimension tables and data sources from './output_data'...\n",
      "Generating Fact_Sales table...\n",
      "Generating 4,010 automotive sales records for 2013Q1...\n",
      "Generating 4,210 automotive sales records for 2013Q2...\n",
      "Generating 4,511 automotive sales records for 2013Q3...\n",
      "Generating 5,012 automotive sales records for 2013Q4...\n",
      "Generating 7,013 automotive sales records for 2014Q1...\n",
      "Generating 7,513 automotive sales records for 2014Q2...\n",
      "Generating 8,024 automotive sales records for 2014Q3...\n",
      "Generating 8,524 automotive sales records for 2014Q4...\n",
      "Generating 9,026 automotive sales records for 2015Q1...\n",
      "Generating 9,528 automotive sales records for 2015Q2...\n",
      "Generating 10,016 automotive sales records for 2015Q3...\n",
      "Generating 11,135 automotive sales records for 2015Q4...\n",
      "Generating 15,200 automotive sales records for 2016Q1...\n",
      "Generating 16,222 automotive sales records for 2016Q2...\n",
      "Generating 18,231 automotive sales records for 2016Q3...\n",
      "Generating 20,226 automotive sales records for 2016Q4...\n",
      "Generating 25,282 automotive sales records for 2017Q1...\n",
      "Generating 28,385 automotive sales records for 2017Q2...\n",
      "Generating 41,980 automotive sales records for 2017Q3...\n",
      "Generating 44,622 automotive sales records for 2017Q4...\n",
      "Generating 46,017 automotive sales records for 2018Q1...\n",
      "Generating 54,559 automotive sales records for 2018Q2...\n",
      "Generating 92,458 automotive sales records for 2018Q3...\n",
      "Generating 97,228 automotive sales records for 2018Q4...\n",
      "Generating 48,729 automotive sales records for 2019Q1...\n",
      "Generating 72,364 automotive sales records for 2019Q2...\n",
      "Generating 71,029 automotive sales records for 2019Q3...\n",
      "Generating 86,045 automotive sales records for 2019Q4...\n",
      "Generating 94,413 automotive sales records for 2020Q1...\n",
      "Generating 94,505 automotive sales records for 2020Q2...\n",
      "Generating 144,166 automotive sales records for 2020Q3...\n",
      "Generating 173,573 automotive sales records for 2020Q4...\n",
      "Generating 160,667 automotive sales records for 2021Q1...\n",
      "Generating 184,596 automotive sales records for 2021Q2...\n",
      "Generating 220,304 automotive sales records for 2021Q3...\n",
      "Generating 293,169 automotive sales records for 2021Q4...\n",
      "Generating 300,609 automotive sales records for 2022Q1...\n",
      "Generating 261,999 automotive sales records for 2022Q2...\n",
      "Generating 345,647 automotive sales records for 2022Q3...\n",
      "Generating 391,740 automotive sales records for 2022Q4...\n",
      "Generating 365,761 automotive sales records for 2023Q1...\n",
      "Generating 393,742 automotive sales records for 2023Q2...\n",
      "Generating 361,186 automotive sales records for 2023Q3...\n",
      "Generating 398,966 automotive sales records for 2023Q4...\n",
      "Generating 310,479 automotive sales records for 2024Q1...\n",
      "Generating 349,342 automotive sales records for 2024Q2...\n",
      "Generating 358,138 automotive sales records for 2024Q3...\n",
      "Generating 362,935 automotive sales records for 2024Q4...\n",
      "Generating 238,559 automotive sales records for 2025Q1...\n",
      "Generating 306,501 automotive sales records for 2025Q2...\n",
      "Fact_Sales.csv successfully generated 8,163,220 rows of data in 110.27 seconds.\n",
      "Data generation complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "\n",
    "# --------------------------\n",
    "# Generates Dim_Time table\n",
    "# --------------------------\n",
    "def generate_dim_time_table(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generate a time dimension table (dim_time_df) with all necessary columns.\n",
    "    \"\"\"\n",
    "    time_series = pd.date_range(start=start_date, end=end_date)\n",
    "    dim_time_df = pd.DataFrame(time_series, columns=['Full_Date'])\n",
    "    \n",
    "    dim_time_df['Time_ID'] = dim_time_df['Full_Date'].apply(lambda x: int(x.strftime('%Y%m%d')))\n",
    "    \n",
    "    dim_time_df['Year'] = dim_time_df['Full_Date'].dt.year\n",
    "    dim_time_df['Quarter_of_Year'] = dim_time_df['Full_Date'].dt.quarter\n",
    "    dim_time_df['Month_of_Year'] = dim_time_df['Full_Date'].dt.month\n",
    "    dim_time_df['Day_of_Month'] = dim_time_df['Full_Date'].dt.day\n",
    "    dim_time_df['Day_of_Week'] = dim_time_df['Full_Date'].dt.dayofweek\n",
    "    dim_time_df['Week_of_Year'] = dim_time_df['Full_Date'].dt.isocalendar().week.astype(int)\n",
    "    \n",
    "    dim_time_df['Day_Name'] = dim_time_df['Full_Date'].dt.day_name()\n",
    "    dim_time_df['Month_Name'] = dim_time_df['Full_Date'].dt.month_name()\n",
    "    \n",
    "    dim_time_df['Is_Weekend'] = dim_time_df['Day_of_Week'] >= 5\n",
    "    \n",
    "    return dim_time_df\n",
    "\n",
    "def generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath):\n",
    "    \"\"\"\n",
    "    Generates the Fact_Sales table by combining all dimension tables.\n",
    "    Uses real-world Tesla sales distribution and volume data for realistic output.\n",
    "    \"\"\"\n",
    "    end_date = datetime(2025, 6, 30)\n",
    "    \n",
    "    # --------------------------\n",
    "    # Step 1: Parse and Load Data\n",
    "    # --------------------------\n",
    "    # 调换了汽车销售和汽车租赁的季度收入数据\n",
    "    revenue_data = {\n",
    "        'Automotive sales': {\n",
    "            (2013, 1): 400.0e6, (2013, 2): 420.0e6, (2013, 3): 450.0e6, (2013, 4): 500.0e6,\n",
    "            (2014, 1): 700.0e6, (2014, 2): 750.0e6, (2014, 3): 800.0e6, (2014, 4): 850.0e6,\n",
    "            (2015, 1): 900.0e6, (2015, 2): 950.0e6, (2015, 3): 1000.0e6, (2015, 4): 1100.0e6,\n",
    "            (2016, 1): 1500.0e6, (2016, 2): 1600.0e6, (2016, 3): 1800.0e6, (2016, 4): 2000.0e6,\n",
    "            (2017, 1): 2500.0e6, (2017, 2): 2800.0e6, (2017, 3): 3000.0e6, (2017, 4): 3200.0e6,\n",
    "            (2018, 1): 3300.0e6, (2018, 2): 3900.0e6, (2018, 3): 6600.0e6, (2018, 4): 7000.0e6,\n",
    "            (2019, 1): 3509.0e6, (2019, 2): 5168.0e6, (2019, 3): 5132.0e6, (2019, 4): 6143.0e6,\n",
    "            (2020, 1): 4893.0e6, (2020, 2): 4911.0e6, (2020, 3): 7346.0e6, (2020, 4): 9034.0e6,\n",
    "            (2021, 1): 8187.0e6, (2021, 2): 9520.0e6, (2021, 3): 11393.0e6, (2021, 4): 15025.0e6,\n",
    "            (2022, 1): 15514.0e6, (2022, 2): 13670.0e6, (2022, 3): 17785.0e6, (2022, 4): 20241.0e6,\n",
    "            (2023, 1): 18878.0e6, (2023, 2): 20419.0e6, (2023, 3): 18582.0e6, (2023, 4): 20630.0e6,\n",
    "            (2024, 1): 16460.0e6, (2024, 2): 18530.0e6, (2024, 3): 18831.0e6, (2024, 4): 18659.0e6,\n",
    "            (2025, 1): 12925.0e6, (2025, 2): 15787.0e6\n",
    "        },\n",
    "        'Automotive regulatory credits': {\n",
    "            (2013, 1): 0.0e6, (2013, 2): 0.0e6, (2013, 3): 0.0e6, (2013, 4): 0.0e6,\n",
    "            (2014, 1): 0.0e6, (2014, 2): 0.0e6, (2014, 3): 0.0e6, (2014, 4): 0.0e6,\n",
    "            (2015, 1): 0.0e6, (2015, 2): 0.0e6, (2015, 3): 0.0e6, (2015, 4): 0.0e6,\n",
    "            (2016, 1): 0.0e6, (2016, 2): 0.0e6, (2016, 3): 0.0e6, (2016, 4): 0.0e6,\n",
    "            (2017, 1): 0.0e6, (2017, 2): 0.0e6, (2017, 3): 0.0e6, (2017, 4): 0.0e6,\n",
    "            (2018, 1): 0.0e6, (2018, 2): 0.0e6, (2018, 3): 0.0e6, (2018, 4): 0.0e6,\n",
    "            (2019, 1): 0.0e6, (2019, 2): 0.0e6, (2019, 3): 0.0e6, (2019, 4): 0.0e6,\n",
    "            (2020, 1): 0.0e6, (2020, 2): 0.0e6, (2020, 3): 0.0e6, (2020, 4): 0.0e6,\n",
    "            (2021, 1): 518.0e6, (2021, 2): 354.0e6, (2021, 3): 279.0e6, (2021, 4): 314.0e6,\n",
    "            (2022, 1): 679.0e6, (2022, 2): 344.0e6, (2022, 3): 286.0e6, (2022, 4): 467.0e6,\n",
    "            (2023, 1): 521.0e6, (2023, 2): 282.0e6, (2023, 3): 554.0e6, (2023, 4): 433.0e6,\n",
    "            (2024, 1): 442.0e6, (2024, 2): 890.0e6, (2024, 3): 739.0e6, (2024, 4): 692.0e6,\n",
    "            (2025, 1): 595.0e6, (2025, 2): 439.0e6\n",
    "        },\n",
    "        'Automotive leasing': {\n",
    "            (2013, 1): 25.0e6, (2013, 2): 28.0e6, (2013, 3): 30.0e6, (2013, 4): 32.0e6,\n",
    "            (2014, 1): 35.0e6, (2014, 2): 38.0e6, (2014, 3): 40.0e6, (2014, 4): 42.0e6,\n",
    "            (2015, 1): 45.0e6, (2015, 2): 48.0e6, (2015, 3): 50.0e6, (2015, 4): 55.0e6,\n",
    "            (2016, 1): 60.0e6, (2016, 2): 65.0e6, (2016, 3): 70.0e6, (2016, 4): 75.0e6,\n",
    "            (2017, 1): 80.0e6, (2017, 2): 85.0e6, (2017, 3): 90.0e6, (2017, 4): 95.0e6,\n",
    "            (2018, 1): 100.0e6, (2018, 2): 110.0e6, (2018, 3): 120.0e6, (2018, 4): 130.0e6,\n",
    "            (2019, 1): 215.0e6, (2019, 2): 208.0e6, (2019, 3): 221.0e6, (2019, 4): 225.0e6,\n",
    "            (2020, 1): 239.0e6, (2020, 2): 268.0e6, (2020, 3): 265.0e6, (2020, 4): 280.0e6,\n",
    "            (2021, 1): 297.0e6, (2021, 2): 332.0e6, (2021, 3): 385.0e6, (2021, 4): 628.0e6,\n",
    "            (2022, 1): 668.0e6, (2022, 2): 588.0e6, (2022, 3): 621.0e6, (2022, 4): 599.0e6,\n",
    "            (2023, 1): 564.0e6, (2023, 2): 567.0e6, (2023, 3): 489.0e6, (2023, 4): 500.0e6,\n",
    "            (2024, 1): 476.0e6, (2024, 2): 458.0e6, (2024, 3): 446.0e6, (2024, 4): 447.0e6,\n",
    "            (2025, 1): 447.0e6, (2025, 2): 435.0e6\n",
    "        },\n",
    "        'Energy generation and storage': {\n",
    "            (2013, 1): 10.0e6, (2013, 2): 12.0e6, (2013, 3): 14.0e6, (2013, 4): 16.0e6,\n",
    "            (2014, 1): 18.0e6, (2014, 2): 20.0e6, (2014, 3): 22.0e6, (2014, 4): 24.0e6,\n",
    "            (2015, 1): 26.0e6, (2015, 2): 28.0e6, (2015, 3): 30.0e6, (2015, 4): 32.0e6,\n",
    "            (2016, 1): 35.0e6, (2016, 2): 38.0e6, (2016, 3): 40.0e6, (2016, 4): 42.0e6,\n",
    "            (2017, 1): 45.0e6, (2017, 2): 48.0e6, (2017, 3): 50.0e6, (2017, 4): 55.0e6,\n",
    "            (2018, 1): 60.0e6, (2018, 2): 65.0e6, (2018, 3): 70.0e6, (2018, 4): 75.0e6,\n",
    "            (2019, 1): 324.0e6, (2019, 2): 369.0e6, (2019, 3): 402.0e6, (2019, 4): 436.0e6,\n",
    "            (2020, 1): 293.0e6, (2020, 2): 370.0e6, (2020, 3): 579.0e6, (2020, 4): 752.0e6,\n",
    "            (2021, 1): 494.0e6, (2021, 2): 801.0e6, (2021, 3): 806.0e6, (2021, 4): 688.0e6,\n",
    "            (2022, 1): 616.0e6, (2022, 2): 866.0e6, (2022, 3): 1117.0e6, (2022, 4): 1310.0e6,\n",
    "            (2023, 1): 1529.0e6, (2023, 2): 1509.0e6, (2023, 3): 1559.0e6, (2023, 4): 1438.0e6,\n",
    "            (2024, 1): 1635.0e6, (2024, 2): 3014.0e6, (2024, 3): 2376.0e6, (2024, 4): 3061.0e6,\n",
    "            (2025, 1): 2730.0e6, (2025, 2): 2789.0e6\n",
    "        },\n",
    "        'Services and other': {\n",
    "            (2013, 1): 15.0e6, (2013, 2): 17.0e6, (2013, 3): 19.0e6, (2013, 4): 20.0e6,\n",
    "            (2014, 1): 22.0e6, (2014, 2): 24.0e6, (2014, 3): 26.0e6, (2014, 4): 28.0e6,\n",
    "            (2015, 1): 30.0e6, (2015, 2): 32.0e6, (2015, 3): 35.0e6, (2015, 4): 38.0e6,\n",
    "            (2016, 1): 40.0e6, (2016, 2): 45.0e6, (2016, 3): 48.0e6, (2016, 4): 50.0e6,\n",
    "            (2017, 1): 55.0e6, (2017, 2): 58.0e6, (2017, 3): 55.0e6, (2017, 4): 58.0e6,\n",
    "            (2018, 1): 65.0e6, (2018, 2): 70.0e6, (2018, 3): 75.0e6, (2018, 4): 80.0e6,\n",
    "            (2019, 1): 493.0e6, (2019, 2): 605.0e6, (2019, 3): 548.0e6, (2019, 4): 580.0e6,\n",
    "            (2020, 1): 560.0e6, (2020, 2): 487.0e6, (2020, 3): 581.0e6, (2020, 4): 678.0e6,\n",
    "            (2021, 1): 893.0e6, (2021, 2): 951.0e6, (2021, 3): 894.0e6, (2021, 4): 1064.0e6,\n",
    "            (2022, 1): 1279.0e6, (2022, 2): 1466.0e6, (2022, 3): 1645.0e6, (2022, 4): 1701.0e6,\n",
    "            (2023, 1): 1837.0e6, (2023, 2): 2150.0e6, (2023, 3): 2166.0e6, (2023, 4): 2166.0e6,\n",
    "            (2024, 1): 2288.0e6, (2024, 2): 2608.0e6, (2024, 3): 2790.0e6, (2024, 4): 2848.0e6,\n",
    "            (2025, 1): 2638.0e6, (2025, 2): 3046.0e6\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 2: Data Cleaning and Preprocessing\n",
    "    # --------------------------\n",
    "    product_id_to_name = {\n",
    "        'PRO001': 'Model S', 'PRO002': 'Model X', 'PRO003': 'Model 3', 'PRO004': 'Model Y',\n",
    "        'PRO005': 'Cybertruck', 'PRO006': 'Other Revenue', 'PRO007': 'Regulatory Credits',\n",
    "        'PRO008': 'Services & Other', 'PRO009': 'Leasing', 'PRO010': 'Energy Generation & Storage',\n",
    "        'PRO011': 'FSD', 'PRO012': 'Cybercab'\n",
    "    }\n",
    "    dim_product_df['Product_Name'] = dim_product_df['Product_ID'].map(product_id_to_name).fillna('Other')\n",
    "\n",
    "    asia_countries = ['China', 'Japan', 'South Korea', 'Singapore', 'India', 'Indonesia', 'Thailand', 'Malaysia', 'Taiwan']\n",
    "    oceania_countries = ['Australia', 'New Zealand']\n",
    "    europe_countries = ['Germany', 'United Kingdom', 'France', 'Norway', 'Netherlands', 'Sweden', 'Italy', 'Switzerland', 'Spain', 'Belgium', 'Austria', 'Denmark', 'Finland', 'Portugal', 'Ireland', 'Luxembourg', 'Iceland']\n",
    "    \n",
    "    def get_continent(country):\n",
    "        if country in asia_countries: return 'Asia'\n",
    "        if country in oceania_countries: return 'Oceania'\n",
    "        if country in europe_countries: return 'Europe'\n",
    "        if country in ['United States', 'Canada', 'Mexico']: return 'North America'\n",
    "        return 'Other'\n",
    "        \n",
    "    dim_geography_df['Continent'] = dim_geography_df['Country'].apply(get_continent).astype(str)\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 3: Define Weights for Geographic Distribution\n",
    "    # --------------------------\n",
    "    product_weights_by_name = {\n",
    "        'Model S': 0.05, 'Model X': 0.05, 'Model 3': 0.45, 'Model Y': 0.40, 'Cybertruck': 0.04, 'Cybercab': 0.01\n",
    "    }\n",
    "    \n",
    "    continent_weights = {'North America': 0.45, 'Europe': 0.30, 'Asia': 0.23, 'Oceania': 0.02}\n",
    "    country_weights = {'United States': 0.80, 'Canada': 0.20, 'China': 0.70, 'Japan': 0.18, 'South Korea': 0.13, 'Germany': 0.30, 'United Kingdom': 0.20, 'France': 0.15, 'Norway': 0.10, 'Australia': 0.75, 'New Zealand': 0.25, 'Taiwan': 0.1}\n",
    "    state_province_weights = {\n",
    "        'California': 0.40, 'Texas': 0.25, 'Florida': 0.15, 'Washington': 0.10, 'New York': 0.10,\n",
    "        'Ontario': 0.4, 'Quebec': 0.25, 'British Columbia': 0.2, 'Alberta': 0.15,\n",
    "        'Shanghai': 0.50, 'Beijing': 0.20, 'Guangdong': 0.20, 'Zhejiang': 0.10,\n",
    "        'Taipei': 0.5, 'New Taipei City': 0.2, 'Taichung': 0.1, 'Kaohsiung': 0.1, 'Tainan': 0.05, 'Taoyuan': 0.05,\n",
    "        'Bavaria': 0.40, 'North Rhine-Westphalia': 0.25, 'Baden-Württemberg': 0.15, 'Berlin': 0.10,\n",
    "        'Greater London': 0.50, 'South East England': 0.25, 'North West England': 0.15, 'West Midlands': 0.10,\n",
    "        'Île-de-France': 0.60, 'Auvergne-Rhône-Alpes': 0.20, 'Nouvelle-Aquitaine': 0.10, 'Provence-Alpes-Côte d\\'Azur': 0.10,\n",
    "        'Oslo': 0.70, 'Vestland': 0.15, 'Viken': 0.10, 'Trøndelag': 0.05,\n",
    "        'New South Wales': 0.5, 'Victoria': 0.3, 'Queensland': 0.1, 'Western Australia': 0.05, 'South Australia': 0.05,\n",
    "        'Auckland': 0.6, 'Wellington': 0.2, 'Canterbury': 0.1, 'Otago': 0.05, 'Waikato': 0.05,\n",
    "    }\n",
    "\n",
    "    dim_geography_df['Geo_Weight'] = 0.0\n",
    "    for continent, c_weight in continent_weights.items():\n",
    "        countries_in_continent = dim_geography_df[dim_geography_df['Continent'] == continent]['Country'].unique()\n",
    "        for country in countries_in_continent:\n",
    "            country_w = country_weights.get(country, 0.01)\n",
    "            states = dim_geography_df[dim_geography_df['Country'] == country]['State_Province'].unique()\n",
    "            for state in states:\n",
    "                state_w = state_province_weights.get(state, 0.01)\n",
    "                mask = (dim_geography_df['Country'] == country) & (dim_geography_df['State_Province'] == state)\n",
    "                dim_geography_df.loc[mask, 'Geo_Weight'] = c_weight * country_w * state_w\n",
    "    dim_geography_df['Geo_Weight'] = dim_geography_df['Geo_Weight'].replace(0.0, 0.0001)\n",
    "\n",
    "    customer_ids = dim_customer_df['Customer_ID'].values\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 4: Ensure Data Types are Consistent\n",
    "    # --------------------------\n",
    "    dim_time_df['Full_Date'] = pd.to_datetime(dim_time_df['Full_Date'])\n",
    "    \n",
    "    if 'Quarter_of_Year' not in dim_time_df.columns:\n",
    "        dim_time_df['Quarter_of_Year'] = dim_time_df['Full_Date'].dt.quarter\n",
    "    \n",
    "    dim_time_df['Year_Int'] = dim_time_df['Year'].astype(int)\n",
    "    dim_time_df['Quarter_Int'] = dim_time_df['Quarter_of_Year'].astype(int)\n",
    "    dim_time_df['Quarter_Start_Date'] = dim_time_df['Full_Date'].dt.to_period('Q').dt.start_time\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 5: Create Price Lookup Dictionary\n",
    "    # --------------------------\n",
    "    price_lookup = {}\n",
    "    if 'Standard_Price_USD' not in dim_prices_df.columns or 'Discounted_Price_USD' not in dim_prices_df.columns:\n",
    "        raise KeyError(\"Dim_Prices.csv is missing required columns.\")\n",
    "\n",
    "    dim_prices_df['Quarter_Start_Date'] = pd.to_datetime(dim_prices_df['Quarter_Start_Date'])\n",
    "    for _, row in dim_prices_df.iterrows():\n",
    "        quarter_start_date = row['Quarter_Start_Date']\n",
    "        product_id = row['Product_ID']\n",
    "        price_lookup[(quarter_start_date, product_id)] = {\n",
    "            'Standard_Price_USD': row['Standard_Price_USD'],\n",
    "            'Discounted_Price_USD': row['Discounted_Price_USD']\n",
    "        }\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 6: Define Product-Geography Combinations and Weights\n",
    "    # --------------------------\n",
    "    product_weights_dict = {\n",
    "        pid: product_weights_by_name.get(pname, 0.0001) for pid, pname in dim_product_df.set_index('Product_ID')['Product_Name'].to_dict().items()\n",
    "    }\n",
    "\n",
    "    geo_weights_dict = dim_geography_df.set_index('Geo_ID')['Geo_Weight'].to_dict()\n",
    "    \n",
    "    automotive_product_ids = ['PRO001', 'PRO002', 'PRO003', 'PRO004', 'PRO005', 'PRO012']\n",
    "    non_automotive_product_ids = ['PRO007', 'PRO008', 'PRO009', 'PRO010', 'PRO011']\n",
    "\n",
    "    # 获取所有真实的地理ID，包括可能存在的其他 ID\n",
    "    real_geo_ids = dim_geography_df['Geo_ID'].tolist()\n",
    "\n",
    "    # 构建汽车产品与地理位置的组合\n",
    "    automotive_combos = []\n",
    "    automotive_combo_weights = []\n",
    "    \n",
    "    for prod_id, geo_id in product(automotive_product_ids, real_geo_ids):\n",
    "        prod_weight = product_weights_dict.get(prod_id, 0.0001)\n",
    "        geo_weight = geo_weights_dict.get(geo_id, 0.0001)\n",
    "        automotive_combos.append((prod_id, geo_id))\n",
    "        automotive_combo_weights.append(prod_weight * geo_weight)\n",
    "\n",
    "    total_automotive_weight = sum(automotive_combo_weights)\n",
    "    if total_automotive_weight == 0:\n",
    "        print(\"Warning: Total automotive combination weight is zero. Cannot generate data.\")\n",
    "        return 0\n",
    "    \n",
    "    automotive_probabilities = np.array(automotive_combo_weights) / total_automotive_weight\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 7: Generate Fact Table Records\n",
    "    # --------------------------\n",
    "    start_year = min(y for y, q in revenue_data['Automotive sales'].keys())\n",
    "\n",
    "    total_generated_rows = 0\n",
    "    \n",
    "    non_automotive_revenue_per_transaction = {\n",
    "        'Automotive regulatory credits': 10e6,\n",
    "        'Services and other': 100e3,\n",
    "        'Automotive leasing': 100e3,\n",
    "        'Energy generation and storage': 100e3\n",
    "    }\n",
    "    \n",
    "    fsd_product_id = 'PRO011'\n",
    "    fsd_price = 12000\n",
    "\n",
    "    with open(output_filepath, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = None\n",
    "        \n",
    "        for year in range(start_year, end_date.year + 1):\n",
    "            for quarter in range(1, 5):\n",
    "                if year == 2025 and quarter > 2:\n",
    "                    continue\n",
    "                \n",
    "                quarterly_revenue = {category: revenue_data.get(category, {}).get((year, quarter), 0) for category in revenue_data}\n",
    "                \n",
    "                quarter_dates_df = dim_time_df[\n",
    "                    (dim_time_df['Year_Int'] == year) & (dim_time_df['Quarter_Int'] == quarter)\n",
    "                ]\n",
    "                \n",
    "                if quarter_dates_df.empty:\n",
    "                    print(f\"Warning: No time IDs available for Year {year} Quarter {quarter}, skipping generation.\")\n",
    "                    continue\n",
    "\n",
    "                records = []\n",
    "                \n",
    "                # 1. Handle Automotive sales\n",
    "                automotive_revenue = quarterly_revenue.get('Automotive sales', 0)\n",
    "                if automotive_revenue > 0:\n",
    "                    quarter_start_date = quarter_dates_df.iloc[0]['Quarter_Start_Date']\n",
    "                    \n",
    "                    automotive_product_prices = {\n",
    "                        prod_id: price_lookup.get((quarter_start_date, prod_id), {}).get('Standard_Price_USD', 100000)\n",
    "                        for prod_id in automotive_product_ids if prod_id in ['PRO001', 'PRO002', 'PRO003', 'PRO004', 'PRO005']\n",
    "                    }\n",
    "                    \n",
    "                    # Add Cybercab price manually\n",
    "                    automotive_product_prices['PRO012'] = 200000 \n",
    "                    \n",
    "                    weighted_average_price = sum(\n",
    "                        automotive_product_prices.get(prod, 0) * product_weights_dict.get(prod, 0) for prod in automotive_product_ids\n",
    "                    )\n",
    "                    \n",
    "                    if weighted_average_price == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    target_units = int(automotive_revenue / weighted_average_price)\n",
    "                    \n",
    "                    if target_units > 0:\n",
    "                        print(f\"Generating {target_units:,} automotive sales records for {year}Q{quarter}...\")\n",
    "                        sampled_combo_indices = np.random.choice(len(automotive_combos), size=target_units, p=automotive_probabilities)\n",
    "                        \n",
    "                        for i in range(target_units):\n",
    "                            combo_index = sampled_combo_indices[i]\n",
    "                            product_id, geo_id = automotive_combos[combo_index]\n",
    "                            \n",
    "                            time_id = np.random.choice(quarter_dates_df['Time_ID'])\n",
    "                            customer_id = np.random.choice(customer_ids)\n",
    "                            \n",
    "                            transaction_revenue = automotive_product_prices.get(product_id, weighted_average_price) * (1 + np.random.normal(0, 0.05))\n",
    "                            \n",
    "                            records.append({\n",
    "                                'Time_ID': time_id,\n",
    "                                'Geo_ID': geo_id,\n",
    "                                'Product_ID': product_id,\n",
    "                                'Customer_ID': customer_id,\n",
    "                                'Sales_Units': 1,\n",
    "                                'Is_Discounted_Sale': False,\n",
    "                                'Revenue_USD': transaction_revenue,\n",
    "                                'Revenue_Category': 'Automotive sales'\n",
    "                            })\n",
    "\n",
    "                # 2. Handle Non-Automotive Revenue\n",
    "                non_automotive_categories = [\n",
    "                    'Automotive regulatory credits',\n",
    "                    'Services and other',\n",
    "                    'Automotive leasing',\n",
    "                    'Energy generation and storage'\n",
    "                ]\n",
    "                \n",
    "                for category in non_automotive_categories:\n",
    "                    revenue = quarterly_revenue.get(category, 0)\n",
    "                    if revenue > 0:\n",
    "                        product_id = non_automotive_product_ids[non_automotive_categories.index(category)]\n",
    "                        \n",
    "                        transaction_unit = non_automotive_revenue_per_transaction.get(category, 1000)\n",
    "                        num_transactions = int(revenue / transaction_unit)\n",
    "                        if num_transactions == 0 and revenue > 0:\n",
    "                             num_transactions = 1 \n",
    "                        \n",
    "                        individual_revenue = revenue / num_transactions if num_transactions > 0 else 0\n",
    "                        \n",
    "                        for _ in range(num_transactions):\n",
    "                            time_id = np.random.choice(quarter_dates_df['Time_ID'])\n",
    "                            # 分配给一个随机的真实地理ID\n",
    "                            geo_id = np.random.choice(real_geo_ids)\n",
    "                            \n",
    "                            records.append({\n",
    "                                'Time_ID': time_id,\n",
    "                                'Geo_ID': geo_id,\n",
    "                                'Product_ID': product_id,\n",
    "                                'Customer_ID': 'CUS001',\n",
    "                                'Sales_Units': 1,\n",
    "                                'Is_Discounted_Sale': False,\n",
    "                                'Revenue_USD': individual_revenue,\n",
    "                                'Revenue_Category': category\n",
    "                            })\n",
    "                            \n",
    "                # 3. Handle FSD sales\n",
    "                fsd_revenue = quarterly_revenue.get('Services and other', 0) * 0.1 # Assume 10% of services revenue is FSD\n",
    "                if fsd_revenue > 0:\n",
    "                    num_fsd_transactions = int(fsd_revenue / fsd_price)\n",
    "                    if num_fsd_transactions == 0 and fsd_revenue > 0:\n",
    "                        num_fsd_transactions = 1\n",
    "                    \n",
    "                    fsd_per_transaction = fsd_revenue / num_fsd_transactions\n",
    "                    \n",
    "                    for _ in range(num_fsd_transactions):\n",
    "                        time_id = np.random.choice(quarter_dates_df['Time_ID'])\n",
    "                        # 分配给一个随机的真实地理ID\n",
    "                        geo_id = np.random.choice(real_geo_ids)\n",
    "                        customer_id = np.random.choice(customer_ids)\n",
    "                        \n",
    "                        records.append({\n",
    "                            'Time_ID': time_id,\n",
    "                            'Geo_ID': geo_id,\n",
    "                            'Product_ID': fsd_product_id,\n",
    "                            'Customer_ID': customer_id,\n",
    "                            'Sales_Units': 1,\n",
    "                            'Is_Discounted_Sale': False,\n",
    "                            'Revenue_USD': fsd_per_transaction,\n",
    "                            'Revenue_Category': 'Services & Other'\n",
    "                        })\n",
    "                \n",
    "                fact_sales_df_temp = pd.DataFrame(records)\n",
    "                \n",
    "                if not fact_sales_df_temp.empty:\n",
    "                    if writer is None:\n",
    "                        fact_sales_df_temp.to_csv(f, header=True, index=False, encoding='utf-8')\n",
    "                        writer = True\n",
    "                    else:\n",
    "                        fact_sales_df_temp.to_csv(f, header=False, index=False, encoding='utf-8')\n",
    "                    total_generated_rows += len(fact_sales_df_temp)\n",
    "    \n",
    "    return total_generated_rows\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    \n",
    "    print(f\"Loading all dimension tables and data sources from '{output_dir}'...\")\n",
    "    \n",
    "    dim_product_df = None\n",
    "    dim_time_df = None\n",
    "    dim_customer_df = None\n",
    "    dim_geography_df = None\n",
    "    dim_prices_df = None\n",
    "    \n",
    "    try:\n",
    "        dim_time_path = os.path.join(output_dir, 'Dim_Time.csv')\n",
    "        if not os.path.exists(dim_time_path):\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            print(\"Dim_Time.csv not found. Generating...\")\n",
    "            dim_time_df = generate_dim_time_table(datetime(2013, 1, 1), datetime(2025, 6, 30))\n",
    "            dim_time_df.to_csv(dim_time_path, index=False)\n",
    "            print(\"Dim_Time.csv generated.\")\n",
    "\n",
    "        dim_product_df = pd.read_csv(os.path.join(output_dir, 'Dim_Product.csv'))\n",
    "        dim_time_df = pd.read_csv(dim_time_path)\n",
    "        dim_customer_df = pd.read_csv(os.path.join(output_dir, 'Dim_Customer.csv'))\n",
    "        dim_geography_df = pd.read_csv(os.path.join(output_dir, 'Dim_Geography.csv'))\n",
    "        dim_prices_df = pd.read_csv(os.path.join(output_dir, 'Dim_Prices.csv'))\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: One or more required CSV files are missing. Please ensure all dimension tables are in the '{output_dir}' directory. The file '{e.filename}' was not found.\")\n",
    "    \n",
    "    if dim_product_df is None or dim_time_df is None or dim_customer_df is None or dim_geography_df is None or dim_prices_df is None:\n",
    "        print(\"Data generation failed due to missing files.\")\n",
    "    else:\n",
    "        new_product_records = pd.DataFrame([\n",
    "            {'Product_ID': 'PRO006', 'Product_Name': 'Other Revenue'},\n",
    "            {'Product_ID': 'PRO007', 'Product_Name': 'Regulatory Credits'},\n",
    "            {'Product_ID': 'PRO008', 'Product_Name': 'Services & Other'},\n",
    "            {'Product_ID': 'PRO009', 'Product_Name': 'Leasing'},\n",
    "            {'Product_ID': 'PRO010', 'Product_Name': 'Energy Generation & Storage'},\n",
    "            {'Product_ID': 'PRO011', 'Product_Name': 'FSD'},\n",
    "            {'Product_ID': 'PRO012', 'Product_Name': 'Cybercab'}\n",
    "        ])\n",
    "        dim_product_df = pd.concat([dim_product_df, new_product_records], ignore_index=True)\n",
    "\n",
    "        new_customer_record = pd.DataFrame([{'Customer_ID': 'CUS001', 'First_Name': 'Global', 'Last_Name': 'Customer', 'Gender': 'NA'}])\n",
    "        dim_customer_df = pd.concat([dim_customer_df, new_customer_record], ignore_index=True)\n",
    "        \n",
    "        # 移除了所有创建新的地理ID的逻辑\n",
    "        \n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        output_filepath = os.path.join(output_dir, 'Fact_Sales.csv')\n",
    "        \n",
    "        if os.path.exists(output_filepath):\n",
    "            os.remove(output_filepath)\n",
    "    \n",
    "        print(\"Generating Fact_Sales table...\")\n",
    "        total_rows = generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath)\n",
    "    \n",
    "        if total_rows > 0:\n",
    "            end_time = time.time()\n",
    "            print(f\"Fact_Sales.csv successfully generated {total_rows:,} rows of data in {end_time - start_time:.2f} seconds.\")\n",
    "            print(\"Data generation complete!\")\n",
    "        else:\n",
    "            print(\"Data generation failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8f8a51-f6fa-4bf1-85eb-3a297f1f03e1",
   "metadata": {},
   "source": [
    "## **800版本** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14550c37-61cc-43e6-b0c8-56edec77ab27",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all dimension tables and data sources from './output_data'...\n",
      "所有维度表加载成功。\n",
      "\n",
      "开始整理和生成销售事实表...\n",
      "\n",
      "--------------------\n",
      "开始遍历所有维度ID...\n",
      "--------------------\n",
      "找到的 'Automotive Leasing' 产品ID数量: 4\n",
      "找到的 'Energy Generation & Storage' 产品ID数量: 4\n",
      "找到的 'Automotive Sales' 产品ID数量: 3138\n",
      "找到的 'Automotive Regulatory Credits' 产品ID数量: 1\n",
      "找到的 'Services & Other' 产品ID数量: 4\n",
      "找到的地理ID数量: 432\n",
      "遍历成功，开始生成销售事实表。\n",
      "--------------------\n",
      "Generated 23,642 records for year 2013.\n",
      "Generated 31,950 records for year 2014.\n",
      "Generated 52,044 records for year 2015.\n",
      "Generated 76,287 records for year 2016.\n",
      "Generated 103,419 records for year 2017.\n",
      "Generated 245,395 records for year 2018.\n",
      "Generated 367,200 records for year 2019.\n",
      "Generated 499,454 records for year 2020.\n",
      "Generated 936,027 records for year 2021.\n",
      "Generated 1,313,851 records for year 2022.\n",
      "Generated 1,808,581 records for year 2023.\n",
      "Generated 1,713,810 records for year 2024.\n",
      "Generated 850,000 records for year 2025.\n",
      "\n",
      "Total car deliveries generated: 8,021,660\n",
      "\n",
      "Fact_Sales.csv successfully generated 8,021,660 rows of data in 153.28 seconds.\n",
      "数据生成完成!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def generate_transaction_id(system_id: str) -> str:\n",
    "    \"\"\"\n",
    "    根据给定的编码规则生成一个唯一的交易ID。\n",
    "\n",
    "    编码规则: TR + 时间戳(YYMMDDHHmmss) + 系统/商户ID + 随机数(6位)\n",
    "    例如: TR250901201234ABC987654\n",
    "\n",
    "    Args:\n",
    "        system_id: 3位系统或商户ID，例如 'WEB', 'POS'。\n",
    "\n",
    "    Returns:\n",
    "        生成的交易ID字符串。\n",
    "    \"\"\"\n",
    "    # 验证系统ID的长度是否为3位\n",
    "    if len(system_id) != 3:\n",
    "        raise ValueError(\"System ID must be exactly 3 characters long.\")\n",
    "\n",
    "    # 1. 固定前缀\n",
    "    prefix = \"TR\"\n",
    "\n",
    "    # 2. 生成时间戳 (YYMMDDHHmmss)\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(\"%y%m%d%H%M%S\")\n",
    "\n",
    "    # 3. 随机数/序列号 (这里为了演示，使用6位随机数)\n",
    "    # 在实际生产环境中，建议使用原子性的自增序列号来保证唯一性\n",
    "    random_part = str(random.randint(100000, 999999))\n",
    "\n",
    "    # 4. 拼接所有部分\n",
    "    transaction_id = f\"{prefix}{timestamp}{system_id.upper()}{random_part}\"\n",
    "\n",
    "    return transaction_id\n",
    "\n",
    "def generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath):\n",
    "    \"\"\"\n",
    "    Generates the Fact_Sales table by combining all dimension tables.\n",
    "    Uses real-world Tesla sales distribution and volume data for realistic output.\n",
    "    \"\"\"\n",
    "    end_date = datetime(2025, 6, 30)\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 1: Parse and Load Data (Hardcoded for this example)\n",
    "    # --------------------------\n",
    "    # This data is used to drive the generation volume and should be consistent\n",
    "    # with the categories in dim_product_df.\n",
    "    # 此数据源为特斯拉2013-2025Q2的季度交付量（Delivery）数据，用于驱动“Automotive Sales”的记录生成\n",
    "    # 来源：特斯拉公开财报，数据以千辆（k）为单位，实际交付数量需乘以1000\n",
    "    delivery_data = {\n",
    "        'Automotive Sales': {\n",
    "            (2013, 1): 4900, (2013, 2): 6350, (2013, 3): 5500, (2013, 4): 6892,\n",
    "            (2014, 1): 6450, (2014, 2): 7575, (2014, 3): 7785, (2014, 4): 10140,\n",
    "            (2015, 1): 11532, (2015, 2): 11532, (2015, 3): 11580, (2015, 4): 17400,\n",
    "            (2016, 1): 14810, (2016, 2): 14402, (2016, 3): 24823, (2016, 4): 22252,\n",
    "            (2017, 1): 25418, (2017, 2): 22000, (2017, 3): 26131, (2017, 4): 29870,\n",
    "            (2018, 1): 29980, (2018, 2): 40740, (2018, 3): 83775, (2018, 4): 90900,\n",
    "            (2019, 1): 63000, (2019, 2): 95200, (2019, 3): 97000, (2019, 4): 112000,\n",
    "            (2020, 1): 88400, (2020, 2): 90891, (2020, 3): 139593, (2020, 4): 180570,\n",
    "            (2021, 1): 184877, (2021, 2): 201250, (2021, 3): 241300, (2021, 4): 308600,\n",
    "            (2022, 1): 310048, (2022, 2): 254695, (2022, 3): 343830, (2022, 4): 405278,\n",
    "            (2023, 1): 422875, (2023, 2): 466140, (2023, 3): 435059, (2023, 4): 484507,\n",
    "            (2024, 1): 386810, (2024, 2): 442000, (2024, 3): 440000, (2024, 4): 445000,\n",
    "            (2025, 1): 400000, (2025, 2): 450000\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 原始的收入数据，可以作为参考\n",
    "    revenue_data = {\n",
    "        'Automotive sales': {\n",
    "            (2013, 1): 400.0e6, (2013, 2): 420.0e6, (2013, 3): 450.0e6, (2013, 4): 500.0e6,\n",
    "            (2014, 1): 700.0e6, (2014, 2): 750.0e6, (2014, 3): 800.0e6, (2014, 4): 850.0e6,\n",
    "            (2015, 1): 900.0e6, (2015, 2): 950.0e6, (2015, 3): 1000.0e6, (2015, 4): 1100.0e6,\n",
    "            (2016, 1): 1500.0e6, (2016, 2): 1600.0e6, (2016, 3): 1800.0e6, (2016, 4): 2000.0e6,\n",
    "            (2017, 1): 2500.0e6, (2017, 2): 2800.0e6, (2017, 3): 3000.0e6, (2017, 4): 3200.0e6,\n",
    "            (2018, 1): 3300.0e6, (2018, 2): 3900.0e6, (2018, 3): 6600.0e6, (2018, 4): 7000.0e6,\n",
    "            (2019, 1): 3509.0e6, (2019, 2): 5168.0e6, (2019, 3): 5132.0e6, (2019, 4): 6143.0e6,\n",
    "            (2020, 1): 4893.0e6, (2020, 2): 4911.0e6, (2020, 3): 7346.0e6, (2020, 4): 9034.0e6,\n",
    "            (2021, 1): 8187.0e6, (2021, 2): 9520.0e6, (2021, 3): 11393.0e6, (2021, 4): 15025.0e6,\n",
    "            (2022, 1): 15514.0e6, (2022, 2): 13670.0e6, (2022, 3): 17785.0e6, (2022, 4): 20241.0e6,\n",
    "            (2023, 1): 18878.0e6, (2023, 2): 20419.0e6, (2023, 3): 18582.0e6, (2023, 4): 20630.0e6,\n",
    "            (2024, 1): 16460.0e6, (2024, 2): 18530.0e6, (2024, 3): 18831.0e6, (2024, 4): 18659.0e6,\n",
    "            (2025, 1): 12925.0e6, (2025, 2): 15787.0e6\n",
    "        },\n",
    "        'Automotive regulatory credits': {\n",
    "            (2013, 1): 0.0e6, (2013, 2): 0.0e6, (2013, 3): 0.0e6, (2013, 4): 0.0e6,\n",
    "            (2014, 1): 0.0e6, (2014, 2): 0.0e6, (2014, 3): 0.0e6, (2014, 4): 0.0e6,\n",
    "            (2015, 1): 0.0e6, (2015, 2): 0.0e6, (2015, 3): 0.0e6, (2015, 4): 0.0e6,\n",
    "            (2016, 1): 0.0e6, (2016, 2): 0.0e6, (2016, 3): 0.0e6, (2016, 4): 0.0e6,\n",
    "            (2017, 1): 0.0e6, (2017, 2): 0.0e6, (2017, 3): 0.0e6, (2017, 4): 0.0e6,\n",
    "            (2018, 1): 0.0e6, (2018, 2): 0.0e6, (2018, 3): 0.0e6, (2018, 4): 0.0e6,\n",
    "            (2019, 1): 0.0e6, (2019, 2): 0.0e6, (2019, 3): 0.0e6, (2019, 4): 0.0e6,\n",
    "            (2020, 1): 0.0e6, (2020, 2): 0.0e6, (2020, 3): 0.0e6, (2020, 4): 0.0e6,\n",
    "            (2021, 1): 518.0e6, (2021, 2): 354.0e6, (2021, 3): 279.0e6, (2021, 4): 314.0e6,\n",
    "            (2022, 1): 679.0e6, (2022, 2): 344.0e6, (2022, 3): 286.0e6, (2022, 4): 467.0e6,\n",
    "            (2023, 1): 521.0e6, (2023, 2): 282.0e6, (2023, 3): 554.0e6, (2023, 4): 433.0e6,\n",
    "            (2024, 1): 442.0e6, (2024, 2): 890.0e6, (2024, 3): 739.0e6, (2024, 4): 692.0e6,\n",
    "            (2025, 1): 595.0e6, (2025, 2): 439.0e6\n",
    "        },\n",
    "        'Automotive leasing': {\n",
    "            (2013, 1): 25.0e6, (2013, 2): 28.0e6, (2013, 3): 30.0e6, (2013, 4): 32.0e6,\n",
    "            (2014, 1): 35.0e6, (2014, 2): 38.0e6, (2014, 3): 40.0e6, (2014, 4): 42.0e6,\n",
    "            (2015, 1): 45.0e6, (2015, 2): 48.0e6, (2015, 3): 50.0e6, (2015, 4): 55.0e6,\n",
    "            (2016, 1): 60.0e6, (2016, 2): 65.0e6, (2016, 3): 70.0e6, (2016, 4): 75.0e6,\n",
    "            (2017, 1): 80.0e6, (2017, 2): 85.0e6, (2017, 3): 90.0e6, (2017, 4): 95.0e6,\n",
    "            (2018, 1): 100.0e6, (2018, 2): 110.0e6, (2018, 3): 120.0e6, (2018, 4): 130.0e6,\n",
    "            (2019, 1): 215.0e6, (2019, 2): 208.0e6, (2019, 3): 221.0e6, (2019, 4): 225.0e6,\n",
    "            (2020, 1): 239.0e6, (2020, 2): 268.0e6, (2020, 3): 265.0e6, (2020, 4): 280.0e6,\n",
    "            (2021, 1): 297.0e6, (2021, 2): 332.0e6, (2021, 3): 385.0e6, (2021, 4): 628.0e6,\n",
    "            (2022, 1): 668.0e6, (2022, 2): 588.0e6, (2022, 3): 621.0e6, (2022, 4): 599.0e6,\n",
    "            (2023, 1): 564.0e6, (2023, 2): 567.0e6, (2023, 3): 489.0e6, (2023, 4): 500.0e6,\n",
    "            (2024, 1): 476.0e6, (2024, 2): 458.0e6, (2024, 3): 446.0e6, (2024, 4): 447.0e6,\n",
    "            (2025, 1): 447.0e6, (2025, 2): 435.0e6\n",
    "        },\n",
    "        'Energy generation and storage': {\n",
    "            (2013, 1): 10.0e6, (2013, 2): 12.0e6, (2013, 3): 14.0e6, (2013, 4): 16.0e6,\n",
    "            (2014, 1): 18.0e6, (2014, 2): 20.0e6, (2014, 3): 22.0e6, (2014, 4): 24.0e6,\n",
    "            (2015, 1): 26.0e6, (2015, 2): 28.0e6, (2015, 3): 30.0e6, (2015, 4): 32.0e6,\n",
    "            (2016, 1): 35.0e6, (2016, 2): 38.0e6, (2016, 3): 40.0e6, (2016, 4): 42.0e6,\n",
    "            (2017, 1): 45.0e6, (2017, 2): 48.0e6, (2017, 3): 50.0e6, (2017, 4): 55.0e6,\n",
    "            (2018, 1): 60.0e6, (2018, 2): 65.0e6, (2018, 3): 70.0e6, (2018, 4): 75.0e6,\n",
    "            (2019, 1): 324.0e6, (2019, 2): 369.0e6, (2019, 3): 402.0e6, (2019, 4): 436.0e6,\n",
    "            (2020, 1): 293.0e6, (2020, 2): 370.0e6, (2020, 3): 579.0e6, (2020, 4): 752.0e6,\n",
    "            (2021, 1): 494.0e6, (2021, 2): 801.0e6, (2021, 3): 806.0e6, (2021, 4): 688.0e6,\n",
    "            (2022, 1): 616.0e6, (2022, 2): 866.0e6, (2022, 3): 1117.0e6, (2022, 4): 1310.0e6,\n",
    "            (2023, 1): 1529.0e6, (2023, 2): 1509.0e6, (2023, 3): 1559.0e6, (2023, 4): 1438.0e6,\n",
    "            (2024, 1): 1635.0e6, (2024, 2): 3014.0e6, (2024, 3): 2376.0e6, (2024, 4): 3061.0e6,\n",
    "            (2025, 1): 2730.0e6, (2025, 2): 2789.0e6\n",
    "        },\n",
    "        'Services and other': {\n",
    "            (2013, 1): 15.0e6, (2013, 2): 17.0e6, (2013, 3): 19.0e6, (2013, 4): 20.0e6,\n",
    "            (2014, 1): 22.0e6, (2014, 2): 24.0e6, (2014, 3): 26.0e6, (2014, 4): 28.0e6,\n",
    "            (2015, 1): 30.0e6, (2015, 2): 32.0e6, (2015, 3): 35.0e6, (2015, 4): 38.0e6,\n",
    "            (2016, 1): 40.0e6, (2016, 2): 45.0e6, (2016, 3): 48.0e6, (2016, 4): 50.0e6,\n",
    "            (2017, 1): 55.0e6, (2017, 2): 58.0e6, (2017, 3): 55.0e6, (2017, 4): 58.0e6,\n",
    "            (2018, 1): 65.0e6, (2018, 2): 70.0e6, (2018, 3): 75.0e6, (2018, 4): 80.0e6,\n",
    "            (2019, 1): 493.0e6, (2019, 2): 605.0e6, (2019, 3): 548.0e6, (2019, 4): 580.0e6,\n",
    "            (2020, 1): 560.0e6, (2020, 2): 487.0e6, (2020, 3): 581.0e6, (2020, 4): 678.0e6,\n",
    "            (2021, 1): 893.0e6, (2021, 2): 951.0e6, (2021, 3): 894.0e6, (2021, 4): 1064.0e6,\n",
    "            (2022, 1): 1279.0e6, (2022, 2): 1466.0e6, (2022, 3): 1645.0e6, (2022, 4): 1701.0e6,\n",
    "            (2023, 1): 1837.0e6, (2023, 2): 2150.0e6, (2023, 3): 2166.0e6, (2023, 4): 2166.0e6,\n",
    "            (2024, 1): 2288.0e6, (2024, 2): 2608.0e6, (2024, 3): 2790.0e6, (2024, 4): 2848.0e6,\n",
    "            (2025, 1): 2638.0e6, (2025, 2): 3046.0e6\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Define and calculate geographical weights\n",
    "    asia_countries = ['China', 'Japan', 'South Korea', 'Singapore', 'India', 'Indonesia', 'Thailand', 'Malaysia', 'Taiwan']\n",
    "    oceania_countries = ['Australia', 'New Zealand']\n",
    "    europe_countries = ['Germany', 'United Kingdom', 'France', 'Norway', 'Netherlands', 'Sweden', 'Italy', 'Switzerland', 'Spain', 'Belgium', 'Austria', 'Denmark', 'Finland', 'Portugal', 'Ireland', 'Luxembourg', 'Iceland']\n",
    "    def get_continent(country):\n",
    "        if country in asia_countries: return 'Asia'\n",
    "        if country in oceania_countries: return 'Oceania'\n",
    "        if country in europe_countries: return 'Europe'\n",
    "        if country in ['United States', 'Canada', 'Mexico']: return 'North America'\n",
    "        return 'Other'\n",
    "    \n",
    "    dim_geography_df['Continent'] = dim_geography_df['Country'].apply(get_continent).astype(str)\n",
    "    dim_geography_df['Geo_Weight'] = 0.0\n",
    "    continent_weights = {'North America': 0.45, 'Europe': 0.30, 'Asia': 0.23, 'Oceania': 0.02, 'Other': 0.001}\n",
    "    country_weights = {'United States': 0.80, 'Canada': 0.20, 'China': 0.70, 'Japan': 0.18, 'South Korea': 0.13, 'Germany': 0.30, 'United Kingdom': 0.20, 'France': 0.15, 'Norway': 0.10, 'Australia': 0.75, 'New Zealand': 0.25, 'Taiwan': 0.1}\n",
    "    state_province_weights = {\n",
    "        'California': 0.40, 'Texas': 0.25, 'Florida': 0.15, 'Washington': 0.10, 'New York': 0.10,\n",
    "        'Ontario': 0.4, 'Quebec': 0.25, 'British Columbia': 0.2, 'Alberta': 0.15,\n",
    "        'Shanghai': 0.50, 'Beijing': 0.20, 'Guangdong': 0.20, 'Zhejiang': 0.10,\n",
    "        'Taipei': 0.5, 'New Taipei City': 0.2, 'Taichung': 0.1, 'Kaohsiung': 0.1, 'Tainan': 0.05, 'Taoyuan': 0.05,\n",
    "        'Bavaria': 0.40, 'North Rhine-Westphalia': 0.25, 'Baden-Württemberg': 0.15, 'Berlin': 0.10,\n",
    "        'Greater London': 0.50, 'South East England': 0.25, 'North West England': 0.15, 'West Midlands': 0.10,\n",
    "        'Île-de-France': 0.60, 'Auvergne-Rhône-Alpes': 0.20, 'Nouvelle-Aquitaine': 0.10, 'Provence-Alpes-Côte d\\'Azur': 0.10,\n",
    "        'Oslo': 0.70, 'Vestland': 0.15, 'Viken': 0.10, 'Trøndelag': 0.05,\n",
    "        'New South Wales': 0.5, 'Victoria': 0.3, 'Queensland': 0.1, 'Western Australia': 0.05, 'South Australia': 0.05,\n",
    "        'Auckland': 0.6, 'Wellington': 0.2, 'Canterbury': 0.1, 'Otago': 0.05, 'Waikato': 0.05,\n",
    "    }\n",
    "    \n",
    "    for _, row in dim_geography_df.iterrows():\n",
    "        continent = row['Continent']\n",
    "        country = row['Country']\n",
    "        state = row['State_Province']\n",
    "        \n",
    "        c_weight = continent_weights.get(continent, 0.001)\n",
    "        country_w = country_weights.get(country, 0.01)\n",
    "        state_w = state_province_weights.get(state, 0.01)\n",
    "        \n",
    "        dim_geography_df.loc[(dim_geography_df['Geo_ID'] == row['Geo_ID']), 'Geo_Weight'] = c_weight * country_w * state_w\n",
    "    dim_geography_df['Geo_Weight'] = dim_geography_df['Geo_Weight'].replace(0.0, 0.0001)\n",
    "\n",
    "    customer_ids = dim_customer_df['Customer_ID'].values\n",
    "    dim_time_df['Full_Date'] = pd.to_datetime(dim_time_df['Full_Date'])\n",
    "    if 'Quarter_of_Year' not in dim_time_df.columns:\n",
    "        dim_time_df['Quarter_of_Year'] = dim_time_df['Full_Date'].dt.quarter\n",
    "    dim_time_df['Year_Int'] = dim_time_df['Year'].astype(int)\n",
    "    dim_time_df['Quarter_Int'] = dim_time_df['Quarter_of_Year'].astype(int)\n",
    "    dim_time_df['Quarter_Start_Date'] = dim_time_df['Full_Date'].dt.to_period('Q').dt.start_time\n",
    "    \n",
    "    price_lookup = {}\n",
    "    if 'Standard_Price_USD' not in dim_prices_df.columns or 'Discounted_Price_USD' not in dim_prices_df.columns:\n",
    "        raise KeyError(\"Dim_Prices.csv is missing required columns.\")\n",
    "    dim_prices_df['Quarter_Start_Date'] = pd.to_datetime(dim_prices_df['Quarter_Start_Date'])\n",
    "    for _, row in dim_prices_df.iterrows():\n",
    "        quarter_start_date = row['Quarter_Start_Date']\n",
    "        product_id = row['Product_ID']\n",
    "        price_lookup[(quarter_start_date, product_id)] = {\n",
    "            'Standard_Price_USD': row['Standard_Price_USD'],\n",
    "            'Discounted_Price_USD': row['Discounted_Price_USD']\n",
    "        }\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 2: Dynamically Map Products to Categories\n",
    "    # --------------------------\n",
    "    \n",
    "    # 使用所有独特的产品类别\n",
    "    all_product_categories = dim_product_df['Product_Category'].unique().tolist()\n",
    "    \n",
    "    category_to_product_ids = defaultdict(list)\n",
    "    for _, row in dim_product_df.iterrows():\n",
    "        category_to_product_ids[row['Product_Category']].append(row['Product_ID'])\n",
    "\n",
    "    print(\"\\n--------------------\")\n",
    "    print(\"开始遍历所有维度ID...\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    # 打印总结信息，使用动态获取的类别\n",
    "    for category in all_product_categories:\n",
    "        print(f\"找到的 '{category}' 产品ID数量: {len(category_to_product_ids[category])}\")\n",
    "    print(f\"找到的地理ID数量: {len(dim_geography_df['Geo_ID'].tolist())}\")\n",
    "\n",
    "    print(\"遍历成功，开始生成销售事实表。\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    # 预先计算一次地理概率，避免在循环中重复计算\n",
    "    geo_weights_dict = dim_geography_df.set_index('Geo_ID')['Geo_Weight'].to_dict()\n",
    "    real_geo_ids = dim_geography_df['Geo_ID'].tolist()\n",
    "    geo_weights_array = np.array(list(geo_weights_dict.values()))\n",
    "    total_geo_weight = sum(geo_weights_dict.values())\n",
    "    \n",
    "    if total_geo_weight > 0:\n",
    "        geo_probabilities = geo_weights_array / total_geo_weight\n",
    "    else:\n",
    "        num_geos = len(real_geo_ids)\n",
    "        geo_probabilities = np.full(num_geos, 1.0 / num_geos)\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 3: Generate Fact Table Records\n",
    "    # --------------------------\n",
    "    start_year = min(y for y, q in delivery_data['Automotive Sales'].keys())\n",
    "    total_generated_rows = 0\n",
    "    total_car_deliveries = 0 # 新增：用于跟踪汽车交付总数\n",
    "    \n",
    "    # 定义每笔交易的平均收入（针对非按件销售的类别）\n",
    "    transaction_revenue_per_category = {\n",
    "        'Automotive Regulatory Credits': 10e6,\n",
    "        'Services & Other': 100e3,\n",
    "        'Automotive Leasing': 100e3,\n",
    "        'Energy Generation & Storage': 100e3,\n",
    "    }\n",
    "\n",
    "    with open(output_filepath, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = None\n",
    "        \n",
    "        for year in range(start_year, end_date.year + 1):\n",
    "            yearly_rows_generated = 0\n",
    "            for quarter in range(1, 5):\n",
    "                if year == 2025 and quarter > 2:\n",
    "                    continue\n",
    "                \n",
    "                quarter_dates_df = dim_time_df[\n",
    "                    (dim_time_df['Year_Int'] == year) & (dim_time_df['Quarter_Int'] == quarter)\n",
    "                ]\n",
    "                \n",
    "                if quarter_dates_df.empty:\n",
    "                    continue\n",
    "\n",
    "                records = []\n",
    "                \n",
    "                # 为每笔交易生成一个唯一的ID\n",
    "                system_id = \"WEB\" # 假设交易来自网页端\n",
    "                \n",
    "                for category_name in all_product_categories:\n",
    "                    if category_name == 'Automotive Sales':\n",
    "                        # 从交付量数据中获取目标数量\n",
    "                        target_units = delivery_data.get(category_name, {}).get((year, quarter), 0)\n",
    "                        \n",
    "                        if target_units > 0:\n",
    "                            quarter_start_date = quarter_dates_df.iloc[0]['Quarter_Start_Date']\n",
    "                            product_ids_for_category = category_to_product_ids.get(category_name)\n",
    "\n",
    "                            if not product_ids_for_category:\n",
    "                                continue\n",
    "\n",
    "                            # 随机选择产品和地理位置\n",
    "                            sampled_product_ids = np.random.choice(product_ids_for_category, size=target_units)\n",
    "                            sampled_geo_ids = np.random.choice(real_geo_ids, size=target_units, p=geo_probabilities)\n",
    "                            \n",
    "                            for i in range(target_units):\n",
    "                                product_id = sampled_product_ids[i]\n",
    "                                geo_id = sampled_geo_ids[i]\n",
    "                                time_id = np.random.choice(quarter_dates_df['Time_ID'])\n",
    "                                customer_id = np.random.choice(customer_ids)\n",
    "                                \n",
    "                                # 根据产品价格估算收入，增加一些随机性\n",
    "                                base_price = price_lookup.get((quarter_start_date, product_id), {}).get('Standard_Price_USD', 100000)\n",
    "                                transaction_revenue = base_price * (1 + np.random.normal(0, 0.05))\n",
    "                                \n",
    "                                records.append({\n",
    "                                    'TransactionID': generate_transaction_id(system_id),\n",
    "                                    'Time_ID': time_id,\n",
    "                                    'Geo_ID': geo_id,\n",
    "                                    'Product_ID': product_id,\n",
    "                                    'Customer_ID': customer_id,\n",
    "                                    'Sales_Units': 1,\n",
    "                                    'Is_Discounted_Sale': False,\n",
    "                                    'Revenue_USD': transaction_revenue,\n",
    "                                    'Revenue_Category': category_name\n",
    "                                })\n",
    "                            total_car_deliveries += target_units\n",
    "                    else:\n",
    "                        # 对于其他类别，仍使用原始的收入数据进行计算\n",
    "                        revenue = revenue_data.get(category_name, {}).get((year, quarter), 0)\n",
    "                        product_ids_for_category = category_to_product_ids.get(category_name)\n",
    "                        \n",
    "                        if revenue > 0 and product_ids_for_category:\n",
    "                            transaction_unit = transaction_revenue_per_category.get(category_name, 1000)\n",
    "                            num_transactions = int(revenue / transaction_unit)\n",
    "                            if num_transactions == 0:\n",
    "                                num_transactions = 1\n",
    "                            \n",
    "                            individual_revenue = revenue / num_transactions if num_transactions > 0 else 0\n",
    "                            \n",
    "                            for _ in range(num_transactions):\n",
    "                                time_id = np.random.choice(quarter_dates_df['Time_ID'])\n",
    "                                geo_id = np.random.choice(real_geo_ids, p=geo_probabilities)\n",
    "                                product_id = np.random.choice(product_ids_for_category)\n",
    "                                \n",
    "                                records.append({\n",
    "                                    'TransactionID': generate_transaction_id(system_id),\n",
    "                                    'Time_ID': time_id,\n",
    "                                    'Geo_ID': geo_id,\n",
    "                                    'Product_ID': product_id,\n",
    "                                    'Customer_ID': 'CUS001',\n",
    "                                    'Sales_Units': 1,\n",
    "                                    'Is_Discounted_Sale': False,\n",
    "                                    'Revenue_USD': individual_revenue,\n",
    "                                    'Revenue_Category': category_name\n",
    "                                })\n",
    "                \n",
    "                fact_sales_df_temp = pd.DataFrame(records)\n",
    "                \n",
    "                if not fact_sales_df_temp.empty:\n",
    "                    if writer is None:\n",
    "                        fact_sales_df_temp.to_csv(f, header=True, index=False, encoding='utf-8')\n",
    "                        writer = True\n",
    "                    else:\n",
    "                        fact_sales_df_temp.to_csv(f, header=False, index=False, encoding='utf-8')\n",
    "                    total_generated_rows += len(fact_sales_df_temp)\n",
    "                    yearly_rows_generated += len(fact_sales_df_temp)\n",
    "            \n",
    "            if yearly_rows_generated > 0:\n",
    "                print(f\"Generated {yearly_rows_generated:,} records for year {year}.\")\n",
    "\n",
    "    print(f\"\\nTotal car deliveries generated: {total_car_deliveries:,}\")\n",
    "    return total_generated_rows\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    \n",
    "    print(f\"Loading all dimension tables and data sources from '{output_dir}'...\")\n",
    "    \n",
    "    dim_product_df = None\n",
    "    dim_time_df = None\n",
    "    dim_customer_df = None\n",
    "    dim_geography_df = None\n",
    "    dim_prices_df = None\n",
    "    \n",
    "    try:\n",
    "        dim_product_df = pd.read_csv(os.path.join(output_dir, 'Dim_Product.csv'))\n",
    "        dim_time_df = pd.read_csv(os.path.join(output_dir, 'Dim_Time.csv'))\n",
    "        dim_customer_df = pd.read_csv(os.path.join(output_dir, 'Dim_Customer.csv'))\n",
    "        dim_geography_df = pd.read_csv(os.path.join(output_dir, 'Dim_Geography.csv'))\n",
    "        dim_prices_df = pd.read_csv(os.path.join(output_dir, 'Dim_Prices.csv'))\n",
    "        \n",
    "        print(\"所有维度表加载成功。\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: One or more required CSV files are missing. Please ensure all dimension tables are in the '{output_dir}' directory. The file '{e.filename}' was not found.\")\n",
    "        print(\"Data generation failed due to missing files.\")\n",
    "        exit()\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    output_filepath = os.path.join(output_dir, 'Fact_Sales.csv')\n",
    "    \n",
    "    if os.path.exists(output_filepath):\n",
    "        os.remove(output_filepath)\n",
    "\n",
    "    print(\"\\n开始整理和生成销售事实表...\")\n",
    "    total_rows = generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath)\n",
    "    \n",
    "    if total_rows > 0:\n",
    "        end_time = time.time()\n",
    "        print(f\"\\nFact_Sales.csv successfully generated {total_rows:,} rows of data in {end_time - start_time:.2f} seconds.\")\n",
    "        print(\"数据生成完成!\")\n",
    "    else:\n",
    "        print(\"数据生成失败。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd3706a-4845-4f03-966f-382edc5bde1a",
   "metadata": {},
   "source": [
    "## **500万行速度优化（做了价格平均）** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbc3213a-b74d-4bef-986a-a3aada27a028",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all dimension tables and data sources from './output_data'...\n",
      "所有维度表加载成功。\n",
      "\n",
      "开始整理和生成销售事实表...\n",
      "\n",
      "--------------------\n",
      "开始遍历所有维度ID...\n",
      "--------------------\n",
      "找到的 'Automotive Leasing' 产品ID数量: 4\n",
      "找到的 'Energy Generation & Storage' 产品ID数量: 4\n",
      "找到的 'Automotive Sales' 产品ID数量: 3138\n",
      "找到的 'Automotive Regulatory Credits' 产品ID数量: 1\n",
      "找到的 'Services & Other' 产品ID数量: 4\n",
      "找到的地理ID数量: 432\n",
      "遍历成功，开始生成销售事实表。\n",
      "--------------------\n",
      "Generated 24,505 records for year 2013.\n",
      "Generated 42,140 records for year 2014.\n",
      "Generated 53,865 records for year 2015.\n",
      "Generated 92,330 records for year 2016.\n",
      "Generated 151,490 records for year 2017.\n",
      "Generated 270,200 records for year 2018.\n",
      "Generated 295,659 records for year 2019.\n",
      "Generated 380,819 records for year 2020.\n",
      "Generated 634,035 records for year 2021.\n",
      "Generated 965,059 records for year 2022.\n",
      "Generated 1,146,280 records for year 2023.\n",
      "Generated 1,130,744 records for year 2024.\n",
      "Generated 479,851 records for year 2025.\n",
      "\n",
      "Total generated records: 5,666,977\n",
      "\n",
      "Fact_Sales.csv successfully generated 5,666,977 rows of data in 32.99 seconds.\n",
      "数据生成完成!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def generate_transaction_id(system_id: str) -> str:\n",
    "    \"\"\"\n",
    "    根据给定的编码规则生成一个唯一的交易ID。\n",
    "\n",
    "    编码规则: TR + 时间戳(YYMMDDHHmmss) + 系统/商户ID + 随机数(6位)\n",
    "    例如: TR250901201234ABC987654\n",
    "\n",
    "    Args:\n",
    "        system_id: 3位系统或商户ID，例如 'WEB', 'POS'。\n",
    "\n",
    "    Returns:\n",
    "        生成的交易ID字符串。\n",
    "    \"\"\"\n",
    "    # 验证系统ID的长度是否为3位\n",
    "    if len(system_id) != 3:\n",
    "        raise ValueError(\"System ID must be exactly 3 characters long.\")\n",
    "\n",
    "    # 1. 固定前缀\n",
    "    prefix = \"TR\"\n",
    "\n",
    "    # 2. 生成时间戳 (YYMMDDHHmmss)\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(\"%y%m%d%H%M%S\")\n",
    "\n",
    "    # 3. 随机数/序列号 (这里为了演示，使用6位随机数)\n",
    "    # 在实际生产环境中，建议使用原子性的自增序列号来保证唯一性\n",
    "    random_part = str(random.randint(100000, 999999))\n",
    "\n",
    "    # 4. 拼接所有部分\n",
    "    transaction_id = f\"{prefix}{timestamp}{system_id.upper()}{random_part}\"\n",
    "\n",
    "    return transaction_id\n",
    "\n",
    "def generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath):\n",
    "    \"\"\"\n",
    "    Generates the Fact_Sales table by combining all dimension tables.\n",
    "    Uses real-world Tesla sales distribution and volume data for realistic output.\n",
    "    \"\"\"\n",
    "    end_date = datetime(2025, 6, 30)\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 1: Parse and Load Data (Hardcoded for this example)\n",
    "    # --------------------------\n",
    "    # 此数据源为特斯拉2013-2025Q2的季度收入数据（Revenue）\n",
    "    # 来源：特斯拉公开财报，单位为百万美元（M），实际收入需乘以1,000,000\n",
    "    revenue_data = {\n",
    "        'Automotive Sales': {           \n",
    "            (2013, 1): 400.0e6, (2013, 2): 420.0e6, (2013, 3): 450.0e6, (2013, 4): 500.0e6,\n",
    "            (2014, 1): 700.0e6, (2014, 2): 750.0e6, (2014, 3): 800.0e6, (2014, 4): 850.0e6,\n",
    "            (2015, 1): 900.0e6, (2015, 2): 950.0e6, (2015, 3): 1000.0e6, (2015, 4): 1100.0e6,\n",
    "            (2016, 1): 1500.0e6, (2016, 2): 1600.0e6, (2016, 3): 1800.0e6, (2016, 4): 2000.0e6,\n",
    "            (2017, 1): 2500.0e6, (2017, 2): 2800.0e6, (2017, 3): 3000.0e6, (2017, 4): 3200.0e6,\n",
    "            (2018, 1): 3300.0e6, (2018, 2): 3900.0e6, (2018, 3): 6600.0e6, (2018, 4): 7000.0e6,\n",
    "            (2019, 1): 3509.0e6, (2019, 2): 5168.0e6, (2019, 3): 5132.0e6, (2019, 4): 6143.0e6,\n",
    "            (2020, 1): 4893.0e6, (2020, 2): 4911.0e6, (2020, 3): 7346.0e6, (2020, 4): 9034.0e6,\n",
    "            (2021, 1): 8187.0e6, (2021, 2): 9520.0e6, (2021, 3): 11393.0e6, (2021, 4): 15025.0e6,\n",
    "            (2022, 1): 15514.0e6, (2022, 2): 13670.0e6, (2022, 3): 17785.0e6, (2022, 4): 20241.0e6,\n",
    "            (2023, 1): 18878.0e6, (2023, 2): 20419.0e6, (2023, 3): 18582.0e6, (2023, 4): 20630.0e6,\n",
    "            (2024, 1): 16460.0e6, (2024, 2): 18530.0e6, (2024, 3): 18831.0e6, (2024, 4): 18659.0e6,\n",
    "            (2025, 1): 12925.0e6, (2025, 2): 15787.0e6\n",
    "        },\n",
    "        'Automotive Regulatory Credits': {\n",
    "            (2013, 1): 0, (2013, 2): 0, (2013, 3): 0, (2013, 4): 0,\n",
    "            (2014, 1): 0, (2014, 2): 0, (2014, 3): 0, (2014, 4): 0,\n",
    "            (2015, 1): 0, (2015, 2): 0, (2015, 3): 0, (2015, 4): 0,\n",
    "            (2016, 1): 0, (2016, 2): 0, (2016, 3): 0, (2016, 4): 0,\n",
    "            (2017, 1): 0, (2017, 2): 0, (2017, 3): 0, (2017, 4): 0,\n",
    "            (2018, 1): 0, (2018, 2): 0, (2018, 3): 0, (2018, 4): 0,\n",
    "            (2019, 1): 0, (2019, 2): 0, (2019, 3): 0, (2019, 4): 0,\n",
    "            (2020, 1): 0, (2020, 2): 0, (2020, 3): 0, (2020, 4): 0,\n",
    "            (2021, 1): 518.0e6, (2021, 2): 354.0e6, (2021, 3): 279.0e6, (2021, 4): 314.0e6,\n",
    "            (2022, 1): 679.0e6, (2022, 2): 344.0e6, (2022, 3): 286.0e6, (2022, 4): 467.0e6,\n",
    "            (2023, 1): 521.0e6, (2023, 2): 282.0e6, (2023, 3): 554.0e6, (2023, 4): 433.0e6,\n",
    "            (2024, 1): 442.0e6, (2024, 2): 890.0e6, (2024, 3): 739.0e6, (2024, 4): 692.0e6,\n",
    "            (2025, 1): 595.0e6, (2025, 2): 439.0e6\n",
    "        },\n",
    "        'Automotive Leasing': {\n",
    "            (2013, 1): 25.0e6, (2013, 2): 28.0e6, (2013, 3): 30.0e6, (2013, 4): 32.0e6,\n",
    "            (2014, 1): 35.0e6, (2014, 2): 38.0e6, (2014, 3): 40.0e6, (2014, 4): 42.0e6,\n",
    "            (2015, 1): 45.0e6, (2015, 2): 48.0e6, (2015, 3): 50.0e6, (2015, 4): 55.0e6,\n",
    "            (2016, 1): 60.0e6, (2016, 2): 65.0e6, (2016, 3): 70.0e6, (2016, 4): 75.0e6,\n",
    "            (2017, 1): 80.0e6, (2017, 2): 85.0e6, (2017, 3): 90.0e6, (2017, 4): 95.0e6,\n",
    "            (2018, 1): 100.0e6, (2018, 2): 110.0e6, (2018, 3): 120.0e6, (2018, 4): 130.0e6,\n",
    "            (2019, 1): 215.0e6, (2019, 2): 208.0e6, (2019, 3): 221.0e6, (2019, 4): 225.0e6,\n",
    "            (2020, 1): 239.0e6, (2020, 2): 268.0e6, (2020, 3): 265.0e6, (2020, 4): 280.0e6,\n",
    "            (2021, 1): 297.0e6, (2021, 2): 332.0e6, (2021, 3): 385.0e6, (2021, 4): 628.0e6,\n",
    "            (2022, 1): 668.0e6, (2022, 2): 588.0e6, (2022, 3): 621.0e6, (2022, 4): 599.0e6,\n",
    "            (2023, 1): 564.0e6, (2023, 2): 567.0e6, (2023, 3): 489.0e6, (2023, 4): 500.0e6,\n",
    "            (2024, 1): 476.0e6, (2024, 2): 458.0e6, (2024, 3): 446.0e6, (2024, 4): 447.0e6,\n",
    "            (2025, 1): 447.0e6, (2025, 2): 435.0e6\n",
    "        },\n",
    "        'Energy Generation & Storage': {\n",
    "            (2013, 1): 10.0e6, (2013, 2): 12.0e6, (2013, 3): 14.0e6, (2013, 4): 16.0e6,\n",
    "            (2014, 1): 18.0e6, (2014, 2): 20.0e6, (2014, 3): 22.0e6, (2014, 4): 24.0e6,\n",
    "            (2015, 1): 26.0e6, (2015, 2): 28.0e6, (2015, 3): 30.0e6, (2015, 4): 32.0e6,\n",
    "            (2016, 1): 35.0e6, (2016, 2): 38.0e6, (2016, 3): 40.0e6, (2016, 4): 42.0e6,\n",
    "            (2017, 1): 45.0e6, (2017, 2): 48.0e6, (2017, 3): 50.0e6, (2017, 4): 55.0e6,\n",
    "            (2018, 1): 60.0e6, (2018, 2): 65.0e6, (2018, 3): 70.0e6, (2018, 4): 75.0e6,\n",
    "            (2019, 1): 324.0e6, (2019, 2): 369.0e6, (2019, 3): 402.0e6, (2019, 4): 436.0e6,\n",
    "            (2020, 1): 293.0e6, (2020, 2): 370.0e6, (2020, 3): 579.0e6, (2020, 4): 752.0e6,\n",
    "            (2021, 1): 494.0e6, (2021, 2): 801.0e6, (2021, 3): 806.0e6, (2021, 4): 688.0e6,\n",
    "            (2022, 1): 616.0e6, (2022, 2): 866.0e6, (2022, 3): 1117.0e6, (2022, 4): 1310.0e6,\n",
    "            (2023, 1): 1529.0e6, (2023, 2): 1509.0e6, (2023, 3): 1559.0e6, (2023, 4): 1438.0e6,\n",
    "            (2024, 1): 1635.0e6, (2024, 2): 3014.0e6, (2024, 3): 2376.0e6, (2024, 4): 3061.0e6,\n",
    "            (2025, 1): 2730.0e6, (2025, 2): 2789.0e6\n",
    "        },\n",
    "        'Services & Other': {\n",
    "            (2013, 1): 15.0e6, (2013, 2): 17.0e6, (2013, 3): 19.0e6, (2013, 4): 20.0e6,\n",
    "            (2014, 1): 22.0e6, (2014, 2): 24.0e6, (2014, 3): 26.0e6, (2014, 4): 28.0e6,\n",
    "            (2015, 1): 30.0e6, (2015, 2): 32.0e6, (2015, 3): 35.0e6, (2015, 4): 38.0e6,\n",
    "            (2016, 1): 40.0e6, (2016, 2): 45.0e6, (2016, 3): 48.0e6, (2016, 4): 50.0e6,\n",
    "            (2017, 1): 55.0e6, (2017, 2): 58.0e6, (2017, 3): 55.0e6, (2017, 4): 58.0e6,\n",
    "            (2018, 1): 65.0e6, (2018, 2): 70.0e6, (2018, 3): 75.0e6, (2018, 4): 80.0e6,\n",
    "            (2019, 1): 493.0e6, (2019, 2): 605.0e6, (2019, 3): 548.0e6, (2019, 4): 580.0e6,\n",
    "            (2020, 1): 560.0e6, (2020, 2): 487.0e6, (2020, 3): 581.0e6, (2020, 4): 678.0e6,\n",
    "            (2021, 1): 893.0e6, (2021, 2): 951.0e6, (2021, 3): 894.0e6, (2021, 4): 1064.0e6,\n",
    "            (2022, 1): 1279.0e6, (2022, 2): 1466.0e6, (2022, 3): 1645.0e6, (2022, 4): 1701.0e6,\n",
    "            (2023, 1): 1837.0e6, (2023, 2): 2150.0e6, (2023, 3): 2166.0e6, (2023, 4): 2166.0e6,\n",
    "            (2024, 1): 2288.0e6, (2024, 2): 2608.0e6, (2024, 3): 2790.0e6, (2024, 4): 2848.0e6,\n",
    "            (2025, 1): 2638.0e6, (2025, 2): 3046.0e6\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 原始的交付量数据，可以作为参考\n",
    "    delivery_data = {\n",
    "        'Automotive Sales': {           \n",
    "            (2013, 1): 400.0, (2013, 2): 420.0, (2013, 3): 450.0, (2013, 4): 500.0,\n",
    "            (2014, 1): 700.0, (2014, 2): 750.0, (2014, 3): 800.0, (2014, 4): 850.0,\n",
    "            (2015, 1): 900.0, (2015, 2): 950.0, (2015, 3): 1000.0, (2015, 4): 1100.0,\n",
    "            (2016, 1): 1500.0, (2016, 2): 1600.0, (2016, 3): 1800.0, (2016, 4): 2000.0,\n",
    "            (2017, 1): 2500.0, (2017, 2): 2800.0, (2017, 3): 3000.0, (2017, 4): 3200.0,\n",
    "            (2018, 1): 3300.0, (2018, 2): 3900.0, (2018, 3): 6600.0, (2018, 4): 7000.0,\n",
    "            (2019, 1): 3509.0, (2019, 2): 5168.0, (2019, 3): 5132.0, (2019, 4): 6143.0,\n",
    "            (2020, 1): 4893.0, (2020, 2): 4911.0, (2020, 3): 7346.0, (2020, 4): 9034.0,\n",
    "            (2021, 1): 8187.0, (2021, 2): 9520.0, (2021, 3): 11393.0, (2021, 4): 15025.0,\n",
    "            (2022, 1): 15514.0, (2022, 2): 13670.0, (2022, 3): 17785.0, (2022, 4): 20241.0,\n",
    "            (2023, 1): 18878.0, (2023, 2): 20419.0, (2023, 3): 18582.0, (2023, 4): 20630.0,\n",
    "            (2024, 1): 16460.0, (2024, 2): 18530.0, (2024, 3): 18831.0, (2024, 4): 18659.0,\n",
    "            (2025, 1): 12925.0, (2025, 2): 15787.0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Define and calculate geographical weights\n",
    "    asia_countries = ['China', 'Japan', 'South Korea', 'Singapore', 'India', 'Indonesia', 'Thailand', 'Malaysia', 'Taiwan']\n",
    "    oceania_countries = ['Australia', 'New Zealand']\n",
    "    europe_countries = ['Germany', 'United Kingdom', 'France', 'Norway', 'Netherlands', 'Sweden', 'Italy', 'Switzerland', 'Spain', 'Belgium', 'Austria', 'Denmark', 'Finland', 'Portugal', 'Ireland', 'Luxembourg', 'Iceland']\n",
    "    def get_continent(country):\n",
    "        if country in asia_countries: return 'Asia'\n",
    "        if country in oceania_countries: return 'Oceania'\n",
    "        if country in europe_countries: return 'Europe'\n",
    "        if country in ['United States', 'Canada', 'Mexico']: return 'North America'\n",
    "        return 'Other'\n",
    "    \n",
    "    dim_geography_df['Continent'] = dim_geography_df['Country'].apply(get_continent).astype(str)\n",
    "    dim_geography_df['Geo_Weight'] = 0.0\n",
    "    continent_weights = {'North America': 0.45, 'Europe': 0.30, 'Asia': 0.23, 'Oceania': 0.02, 'Other': 0.001}\n",
    "    country_weights = {'United States': 0.80, 'Canada': 0.20, 'China': 0.70, 'Japan': 0.18, 'South Korea': 0.13, 'Germany': 0.30, 'United Kingdom': 0.20, 'France': 0.15, 'Norway': 0.10, 'Australia': 0.75, 'New Zealand': 0.25, 'Taiwan': 0.1}\n",
    "    state_province_weights = {\n",
    "        'California': 0.40, 'Texas': 0.25, 'Florida': 0.15, 'Washington': 0.10, 'New York': 0.10,\n",
    "        'Ontario': 0.4, 'Quebec': 0.25, 'British Columbia': 0.2, 'Alberta': 0.15,\n",
    "        'Shanghai': 0.50, 'Beijing': 0.20, 'Guangdong': 0.20, 'Zhejiang': 0.10,\n",
    "        'Taipei': 0.5, 'New Taipei City': 0.2, 'Taichung': 0.1, 'Kaohsiung': 0.1, 'Tainan': 0.05, 'Taoyuan': 0.05,\n",
    "        'Bavaria': 0.40, 'North Rhine-Westphalia': 0.25, 'Baden-Württemberg': 0.15, 'Berlin': 0.10,\n",
    "        'Greater London': 0.50, 'South East England': 0.25, 'North West England': 0.15, 'West Midlands': 0.10,\n",
    "        'Île-de-France': 0.60, 'Auvergne-Rhône-Alpes': 0.20, 'Nouvelle-Aquitaine': 0.10, 'Provence-Alpes-Côte d\\'Azur': 0.10,\n",
    "        'Oslo': 0.70, 'Vestland': 0.15, 'Viken': 0.10, 'Trøndelag': 0.05,\n",
    "        'New South Wales': 0.5, 'Victoria': 0.3, 'Queensland': 0.1, 'Western Australia': 0.05, 'South Australia': 0.05,\n",
    "        'Auckland': 0.6, 'Wellington': 0.2, 'Canterbury': 0.1, 'Otago': 0.05, 'Waikato': 0.05,\n",
    "    }\n",
    "    \n",
    "    for _, row in dim_geography_df.iterrows():\n",
    "        continent = row['Continent']\n",
    "        country = row['Country']\n",
    "        state = row['State_Province']\n",
    "        \n",
    "        c_weight = continent_weights.get(continent, 0.001)\n",
    "        country_w = country_weights.get(country, 0.01)\n",
    "        state_w = state_province_weights.get(state, 0.01)\n",
    "        \n",
    "        dim_geography_df.loc[(dim_geography_df['Geo_ID'] == row['Geo_ID']), 'Geo_Weight'] = c_weight * country_w * state_w\n",
    "    dim_geography_df['Geo_Weight'] = dim_geography_df['Geo_Weight'].replace(0.0, 0.0001)\n",
    "\n",
    "    customer_ids = dim_customer_df['Customer_ID'].values\n",
    "    dim_time_df['Full_Date'] = pd.to_datetime(dim_time_df['Full_Date'])\n",
    "    if 'Quarter_of_Year' not in dim_time_df.columns:\n",
    "        dim_time_df['Quarter_of_Year'] = dim_time_df['Full_Date'].dt.quarter\n",
    "    dim_time_df['Year_Int'] = dim_time_df['Year'].astype(int)\n",
    "    dim_time_df['Quarter_Int'] = dim_time_df['Quarter_of_Year'].astype(int)\n",
    "    dim_time_df['Quarter_Start_Date'] = dim_time_df['Full_Date'].dt.to_period('Q').dt.start_time\n",
    "    \n",
    "    price_lookup = {}\n",
    "    if 'Standard_Price_USD' not in dim_prices_df.columns or 'Discounted_Price_USD' not in dim_prices_df.columns:\n",
    "        raise KeyError(\"Dim_Prices.csv is missing required columns.\")\n",
    "    dim_prices_df['Quarter_Start_Date'] = pd.to_datetime(dim_prices_df['Quarter_Start_Date'])\n",
    "    for _, row in dim_prices_df.iterrows():\n",
    "        quarter_start_date = row['Quarter_Start_Date']\n",
    "        product_id = row['Product_ID']\n",
    "        price_lookup[(quarter_start_date, product_id)] = {\n",
    "            'Standard_Price_USD': row['Standard_Price_USD'],\n",
    "            'Discounted_Price_USD': row['Discounted_Price_USD']\n",
    "        }\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 2: Dynamically Map Products to Categories\n",
    "    # --------------------------\n",
    "    \n",
    "    # 使用所有独特的产品类别\n",
    "    all_product_categories = dim_product_df['Product_Category'].unique().tolist()\n",
    "    \n",
    "    category_to_product_ids = defaultdict(list)\n",
    "    for _, row in dim_product_df.iterrows():\n",
    "        category_to_product_ids[row['Product_Category']].append(row['Product_ID'])\n",
    "\n",
    "    print(\"\\n--------------------\")\n",
    "    print(\"开始遍历所有维度ID...\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    # 打印总结信息，使用动态获取的类别\n",
    "    for category in all_product_categories:\n",
    "        print(f\"找到的 '{category}' 产品ID数量: {len(category_to_product_ids[category])}\")\n",
    "    print(f\"找到的地理ID数量: {len(dim_geography_df['Geo_ID'].tolist())}\")\n",
    "\n",
    "    print(\"遍历成功，开始生成销售事实表。\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    # 预先计算一次地理概率，避免在循环中重复计算\n",
    "    geo_weights_dict = dim_geography_df.set_index('Geo_ID')['Geo_Weight'].to_dict()\n",
    "    real_geo_ids = dim_geography_df['Geo_ID'].tolist()\n",
    "    geo_weights_array = np.array(list(geo_weights_dict.values()))\n",
    "    total_geo_weight = sum(geo_weights_dict.values())\n",
    "    \n",
    "    if total_geo_weight > 0:\n",
    "        geo_probabilities = geo_weights_array / total_geo_weight\n",
    "    else:\n",
    "        num_geos = len(real_geo_ids)\n",
    "        geo_probabilities = np.full(num_geos, 1.0 / num_geos)\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 3: Generate Fact Table Records\n",
    "    # --------------------------\n",
    "    start_year = min(y for y, q in revenue_data['Automotive Sales'].keys())\n",
    "    total_generated_rows = 0\n",
    "    \n",
    "    # 定义每笔交易的平均收入（针对非按件销售的类别）\n",
    "    transaction_revenue_per_category = {\n",
    "        'Automotive Regulatory Credits': 10e6,\n",
    "        'Services & Other': 100e3,\n",
    "        'Automotive Leasing': 100e3,\n",
    "        'Energy Generation & Storage': 100e3,\n",
    "    }\n",
    "    \n",
    "    # 针对'Automotive Sales'，定义一个平均交易金额，用于从总收入估算交易笔数\n",
    "    avg_car_price = 80000  # 假设一辆汽车的平均价格为80,000美元\n",
    "    \n",
    "    with open(output_filepath, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = None\n",
    "        \n",
    "        for year in range(start_year, end_date.year + 1):\n",
    "            yearly_rows_generated = 0\n",
    "            for quarter in range(1, 5):\n",
    "                if year == 2025 and quarter > 2:\n",
    "                    continue\n",
    "                \n",
    "                quarter_dates_df = dim_time_df[\n",
    "                    (dim_time_df['Year_Int'] == year) & (dim_time_df['Quarter_Int'] == quarter)\n",
    "                ]\n",
    "                \n",
    "                if quarter_dates_df.empty:\n",
    "                    continue\n",
    "\n",
    "                records = []\n",
    "                \n",
    "                # 为每笔交易生成一个唯一的ID\n",
    "                system_id = \"WEB\" # 假设交易来自网页端\n",
    "                \n",
    "                for category_name in all_product_categories:\n",
    "                    revenue = revenue_data.get(category_name, {}).get((year, quarter), 0)\n",
    "                    product_ids_for_category = category_to_product_ids.get(category_name)\n",
    "                    \n",
    "                    if not product_ids_for_category:\n",
    "                        continue\n",
    "\n",
    "                    if revenue > 0:\n",
    "                        if category_name == 'Automotive Sales':\n",
    "                            # 使用收入数据除以平均价格来估算交易笔数\n",
    "                            num_transactions = int(revenue / avg_car_price)\n",
    "                            if num_transactions == 0:\n",
    "                                num_transactions = 1\n",
    "                            individual_revenue = revenue / num_transactions\n",
    "                        else:\n",
    "                            # 对于其他类别，使用已定义的平均交易收入来估算交易笔数\n",
    "                            transaction_unit = transaction_revenue_per_category.get(category_name, 1000)\n",
    "                            num_transactions = int(revenue / transaction_unit)\n",
    "                            if num_transactions == 0:\n",
    "                                num_transactions = 1\n",
    "                            individual_revenue = revenue / num_transactions\n",
    "                        \n",
    "                        sampled_product_ids = np.random.choice(product_ids_for_category, size=num_transactions)\n",
    "                        sampled_geo_ids = np.random.choice(real_geo_ids, size=num_transactions, p=geo_probabilities)\n",
    "                        sampled_customer_ids = np.random.choice(customer_ids, size=num_transactions)\n",
    "                        sampled_time_ids = np.random.choice(quarter_dates_df['Time_ID'].values, size=num_transactions)\n",
    "                        \n",
    "                        # 确保 Revenue_USD 的总和接近于原始收入\n",
    "                        # 在这里使用一个简单的随机分配，使总和接近\n",
    "                        revenue_per_record = individual_revenue\n",
    "                        \n",
    "                        for i in range(num_transactions):\n",
    "                            records.append({\n",
    "                                'TransactionID': generate_transaction_id(system_id),\n",
    "                                'Time_ID': sampled_time_ids[i],\n",
    "                                'Geo_ID': sampled_geo_ids[i],\n",
    "                                'Product_ID': sampled_product_ids[i],\n",
    "                                'Customer_ID': sampled_customer_ids[i],\n",
    "                                'Sales_Units': 1,\n",
    "                                'Is_Discounted_Sale': False,\n",
    "                                'Revenue_USD': revenue_per_record * (1 + np.random.normal(0, 0.05)),\n",
    "                                'Revenue_Category': category_name\n",
    "                            })\n",
    "                \n",
    "                fact_sales_df_temp = pd.DataFrame(records)\n",
    "                \n",
    "                if not fact_sales_df_temp.empty:\n",
    "                    if writer is None:\n",
    "                        fact_sales_df_temp.to_csv(f, header=True, index=False, encoding='utf-8')\n",
    "                        writer = True\n",
    "                    else:\n",
    "                        fact_sales_df_temp.to_csv(f, header=False, index=False, encoding='utf-8')\n",
    "                    total_generated_rows += len(fact_sales_df_temp)\n",
    "                    yearly_rows_generated += len(fact_sales_df_temp)\n",
    "            \n",
    "            if yearly_rows_generated > 0:\n",
    "                print(f\"Generated {yearly_rows_generated:,} records for year {year}.\")\n",
    "\n",
    "    print(f\"\\nTotal generated records: {total_generated_rows:,}\")\n",
    "    return total_generated_rows\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    \n",
    "    print(f\"Loading all dimension tables and data sources from '{output_dir}'...\")\n",
    "    \n",
    "    dim_product_df = None\n",
    "    dim_time_df = None\n",
    "    dim_customer_df = None\n",
    "    dim_geography_df = None\n",
    "    dim_prices_df = None\n",
    "    \n",
    "    try:\n",
    "        dim_product_df = pd.read_csv(os.path.join(output_dir, 'Dim_Product.csv'))\n",
    "        dim_time_df = pd.read_csv(os.path.join(output_dir, 'Dim_Time.csv'))\n",
    "        dim_customer_df = pd.read_csv(os.path.join(output_dir, 'Dim_Customer.csv'))\n",
    "        dim_geography_df = pd.read_csv(os.path.join(output_dir, 'Dim_Geography.csv'))\n",
    "        dim_prices_df = pd.read_csv(os.path.join(output_dir, 'Dim_Prices.csv'))\n",
    "        \n",
    "        print(\"所有维度表加载成功。\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: One or more required CSV files are missing. Please ensure all dimension tables are in the '{output_dir}' directory. The file '{e.filename}' was not found.\")\n",
    "        print(\"Data generation failed due to missing files.\")\n",
    "        exit()\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    output_filepath = os.path.join(output_dir, 'Fact_Sales.csv')\n",
    "    \n",
    "    if os.path.exists(output_filepath):\n",
    "        os.remove(output_filepath)\n",
    "\n",
    "    print(\"\\n开始整理和生成销售事实表...\")\n",
    "    total_rows = generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath)\n",
    "    \n",
    "    if total_rows > 0:\n",
    "        end_time = time.time()\n",
    "        print(f\"\\nFact_Sales.csv successfully generated {total_rows:,} rows of data in {end_time - start_time:.2f} seconds.\")\n",
    "        print(\"数据生成完成!\")\n",
    "    else:\n",
    "        print(\"数据生成失败。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac866b1-16fb-4f3f-99b3-27a9f4aaea26",
   "metadata": {},
   "source": [
    "## **800万行速度优化 修改车辆数（做了价格平均）** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0967344f-2217-4a6f-9b21-d4b5301ff43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all dimension tables and data sources from './output_data'...\n",
      "所有维度表加载成功。\n",
      "\n",
      "开始整理和生成销售事实表...\n",
      "\n",
      "--------------------\n",
      "开始遍历所有维度ID...\n",
      "--------------------\n",
      "找到的 'Automotive Leasing' 产品ID数量: 4\n",
      "找到的 'Energy Generation & Storage' 产品ID数量: 4\n",
      "找到的 'Automotive Sales' 产品ID数量: 3138\n",
      "找到的 'Automotive Regulatory Credits' 产品ID数量: 1\n",
      "找到的 'Services & Other' 产品ID数量: 4\n",
      "找到的地理ID数量: 432\n",
      "遍历成功，开始生成销售事实表。\n",
      "--------------------\n",
      "Generated 24,822 records for year 2013.\n",
      "Generated 41,149 records for year 2014.\n",
      "Generated 55,148 records for year 2015.\n",
      "Generated 82,431 records for year 2016.\n",
      "Generated 111,178 records for year 2017.\n",
      "Generated 255,120 records for year 2018.\n",
      "Generated 413,460 records for year 2019.\n",
      "Generated 552,974 records for year 2020.\n",
      "Generated 1,018,478 records for year 2021.\n",
      "Generated 1,438,786 records for year 2022.\n",
      "Generated 1,973,499 records for year 2023.\n",
      "Generated 1,943,555 records for year 2024.\n",
      "Generated 770,952 records for year 2025.\n",
      "\n",
      "Total generated records: 8,681,552\n",
      "\n",
      "Fact_Sales.csv successfully generated 8,681,552 rows of data in 50.43 seconds.\n",
      "数据生成完成!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def generate_transaction_id(system_id: str) -> str:\n",
    "    \"\"\"\n",
    "    根据给定的编码规则生成一个唯一的交易ID。\n",
    "    编码规则: TR + 时间戳(YYMMDDHHmmss) + 系统/商户ID + 随机数(6位)\n",
    "    例如: TR250901201234ABC987654\n",
    "\n",
    "    Args:\n",
    "        system_id: 3位系统或商户ID，例如 'WEB', 'POS'。\n",
    "\n",
    "    Returns:\n",
    "        生成的交易ID字符串。\n",
    "    \"\"\"\n",
    "    if len(system_id) != 3:\n",
    "        raise ValueError(\"System ID must be exactly 3 characters long.\")\n",
    "    \n",
    "    prefix = \"TR\"\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(\"%y%m%d%H%M%S\")\n",
    "    random_part = str(random.randint(100000, 999999))\n",
    "    \n",
    "    transaction_id = f\"{prefix}{timestamp}{system_id.upper()}{random_part}\"\n",
    "    \n",
    "    return transaction_id\n",
    "\n",
    "def generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath):\n",
    "    \"\"\"\n",
    "    Generates the Fact_Sales table by combining all dimension tables.\n",
    "    Uses real-world Tesla sales distribution and volume data for realistic output.\n",
    "    \"\"\"\n",
    "    end_date = datetime(2025, 6, 30)\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 1: Parse and Load Data (Hardcoded for this example)\n",
    "    # --------------------------\n",
    "    # 特斯拉2013-2025Q2的季度收入数据（Revenue）\n",
    "    revenue_data = {\n",
    "        'Automotive Sales': {        \n",
    "            (2013, 1): 400.0e6, (2013, 2): 420.0e6, (2013, 3): 450.0e6, (2013, 4): 500.0e6,\n",
    "            (2014, 1): 700.0e6, (2014, 2): 750.0e6, (2014, 3): 800.0e6, (2014, 4): 850.0e6,\n",
    "            (2015, 1): 900.0e6, (2015, 2): 950.0e6, (2015, 3): 1000.0e6, (2015, 4): 1100.0e6,\n",
    "            (2016, 1): 1500.0e6, (2016, 2): 1600.0e6, (2016, 3): 1800.0e6, (2016, 4): 2000.0e6,\n",
    "            (2017, 1): 2500.0e6, (2017, 2): 2800.0e6, (2017, 3): 3000.0e6, (2017, 4): 3200.0e6,\n",
    "            (2018, 1): 3300.0e6, (2018, 2): 3900.0e6, (2018, 3): 6600.0e6, (2018, 4): 7000.0e6,\n",
    "            (2019, 1): 3509.0e6, (2019, 2): 5168.0e6, (2019, 3): 5132.0e6, (2019, 4): 6143.0e6,\n",
    "            (2020, 1): 4893.0e6, (2020, 2): 4911.0e6, (2020, 3): 7346.0e6, (2020, 4): 9034.0e6,\n",
    "            (2021, 1): 8187.0e6, (2021, 2): 9520.0e6, (2021, 3): 11393.0e6, (2021, 4): 15025.0e6,\n",
    "            (2022, 1): 15514.0e6, (2022, 2): 13670.0e6, (2022, 3): 17785.0e6, (2022, 4): 20241.0e6,\n",
    "            (2023, 1): 18878.0e6, (2023, 2): 20419.0e6, (2023, 3): 18582.0e6, (2023, 4): 20630.0e6,\n",
    "            (2024, 1): 16460.0e6, (2024, 2): 18530.0e6, (2024, 3): 18831.0e6, (2024, 4): 18659.0e6,\n",
    "            (2025, 1): 12925.0e6, (2025, 2): 15787.0e6\n",
    "        },\n",
    "        'Automotive Regulatory Credits': {\n",
    "            (2013, 1): 0, (2013, 2): 0, (2013, 3): 0, (2013, 4): 0,\n",
    "            (2014, 1): 0, (2014, 2): 0, (2014, 3): 0, (2014, 4): 0,\n",
    "            (2015, 1): 0, (2015, 2): 0, (2015, 3): 0, (2015, 4): 0,\n",
    "            (2016, 1): 0, (2016, 2): 0, (2016, 3): 0, (2016, 4): 0,\n",
    "            (2017, 1): 0, (2017, 2): 0, (2017, 3): 0, (2017, 4): 0,\n",
    "            (2018, 1): 0, (2018, 2): 0, (2018, 3): 0, (2018, 4): 0,\n",
    "            (2019, 1): 0, (2019, 2): 0, (2019, 3): 0, (2019, 4): 0,\n",
    "            (2020, 1): 0, (2020, 2): 0, (2020, 3): 0, (2020, 4): 0,\n",
    "            (2021, 1): 518.0e6, (2021, 2): 354.0e6, (2021, 3): 279.0e6, (2021, 4): 314.0e6,\n",
    "            (2022, 1): 679.0e6, (2022, 2): 344.0e6, (2022, 3): 286.0e6, (2022, 4): 467.0e6,\n",
    "            (2023, 1): 521.0e6, (2023, 2): 282.0e6, (2023, 3): 554.0e6, (2023, 4): 433.0e6,\n",
    "            (2024, 1): 442.0e6, (2024, 2): 890.0e6, (2024, 3): 739.0e6, (2024, 4): 692.0e6,\n",
    "            (2025, 1): 595.0e6, (2025, 2): 439.0e6\n",
    "        },\n",
    "        'Automotive Leasing': {\n",
    "            (2013, 1): 25.0e6, (2013, 2): 28.0e6, (2013, 3): 30.0e6, (2013, 4): 32.0e6,\n",
    "            (2014, 1): 35.0e6, (2014, 2): 38.0e6, (2014, 3): 40.0e6, (2014, 4): 42.0e6,\n",
    "            (2015, 1): 45.0e6, (2015, 2): 48.0e6, (2015, 3): 50.0e6, (2015, 4): 55.0e6,\n",
    "            (2016, 1): 60.0e6, (2016, 2): 65.0e6, (2016, 3): 70.0e6, (2016, 4): 75.0e6,\n",
    "            (2017, 1): 80.0e6, (2017, 2): 85.0e6, (2017, 3): 90.0e6, (2017, 4): 95.0e6,\n",
    "            (2018, 1): 100.0e6, (2018, 2): 110.0e6, (2018, 3): 120.0e6, (2018, 4): 130.0e6,\n",
    "            (2019, 1): 215.0e6, (2019, 2): 208.0e6, (2019, 3): 221.0e6, (2019, 4): 225.0e6,\n",
    "            (2020, 1): 239.0e6, (2020, 2): 268.0e6, (2020, 3): 265.0e6, (2020, 4): 280.0e6,\n",
    "            (2021, 1): 297.0e6, (2021, 2): 332.0e6, (2021, 3): 385.0e6, (2021, 4): 628.0e6,\n",
    "            (2022, 1): 668.0e6, (2022, 2): 588.0e6, (2022, 3): 621.0e6, (2022, 4): 599.0e6,\n",
    "            (2023, 1): 564.0e6, (2023, 2): 567.0e6, (2023, 3): 489.0e6, (2023, 4): 500.0e6,\n",
    "            (2024, 1): 476.0e6, (2024, 2): 458.0e6, (2024, 3): 446.0e6, (2024, 4): 447.0e6,\n",
    "            (2025, 1): 447.0e6, (2025, 2): 435.0e6\n",
    "        },\n",
    "        'Energy Generation & Storage': {\n",
    "            (2013, 1): 10.0e6, (2013, 2): 12.0e6, (2013, 3): 14.0e6, (2013, 4): 16.0e6,\n",
    "            (2014, 1): 18.0e6, (2014, 2): 20.0e6, (2014, 3): 22.0e6, (2014, 4): 24.0e6,\n",
    "            (2015, 1): 26.0e6, (2015, 2): 28.0e6, (2015, 3): 30.0e6, (2015, 4): 32.0e6,\n",
    "            (2016, 1): 35.0e6, (2016, 2): 38.0e6, (2016, 3): 40.0e6, (2016, 4): 42.0e6,\n",
    "            (2017, 1): 45.0e6, (2017, 2): 48.0e6, (2017, 3): 50.0e6, (2017, 4): 55.0e6,\n",
    "            (2018, 1): 60.0e6, (2018, 2): 65.0e6, (2018, 3): 70.0e6, (2018, 4): 75.0e6,\n",
    "            (2019, 1): 324.0e6, (2019, 2): 369.0e6, (2019, 3): 402.0e6, (2019, 4): 436.0e6,\n",
    "            (2020, 1): 293.0e6, (2020, 2): 370.0e6, (2020, 3): 579.0e6, (2020, 4): 752.0e6,\n",
    "            (2021, 1): 494.0e6, (2021, 2): 801.0e6, (2021, 3): 806.0e6, (2021, 4): 688.0e6,\n",
    "            (2022, 1): 616.0e6, (2022, 2): 866.0e6, (2022, 3): 1117.0e6, (2022, 4): 1310.0e6,\n",
    "            (2023, 1): 1529.0e6, (2023, 2): 1509.0e6, (2023, 3): 1559.0e6, (2023, 4): 1438.0e6,\n",
    "            (2024, 1): 1635.0e6, (2024, 2): 3014.0e6, (2024, 3): 2376.0e6, (2024, 4): 3061.0e6,\n",
    "            (2025, 1): 2730.0e6, (2025, 2): 2789.0e6\n",
    "        },\n",
    "        'Services & Other': {\n",
    "            (2013, 1): 15.0e6, (2013, 2): 17.0e6, (2013, 3): 19.0e6, (2013, 4): 20.0e6,\n",
    "            (2014, 1): 22.0e6, (2014, 2): 24.0e6, (2014, 3): 26.0e6, (2014, 4): 28.0e6,\n",
    "            (2015, 1): 30.0e6, (2015, 2): 32.0e6, (2015, 3): 35.0e6, (2015, 4): 38.0e6,\n",
    "            (2016, 1): 40.0e6, (2016, 2): 45.0e6, (2016, 3): 48.0e6, (2016, 4): 50.0e6,\n",
    "            (2017, 1): 55.0e6, (2017, 2): 58.0e6, (2017, 3): 55.0e6, (2017, 4): 58.0e6,\n",
    "            (2018, 1): 65.0e6, (2018, 2): 70.0e6, (2018, 3): 75.0e6, (2018, 4): 80.0e6,\n",
    "            (2019, 1): 493.0e6, (2019, 2): 605.0e6, (2019, 3): 548.0e6, (2019, 4): 580.0e6,\n",
    "            (2020, 1): 560.0e6, (2020, 2): 487.0e6, (2020, 3): 581.0e6, (2020, 4): 678.0e6,\n",
    "            (2021, 1): 893.0e6, (2021, 2): 951.0e6, (2021, 3): 894.0e6, (2021, 4): 1064.0e6,\n",
    "            (2022, 1): 1279.0e6, (2022, 2): 1466.0e6, (2022, 3): 1645.0e6, (2022, 4): 1701.0e6,\n",
    "            (2023, 1): 1837.0e6, (2023, 2): 2150.0e6, (2023, 3): 2166.0e6, (2023, 4): 2166.0e6,\n",
    "            (2024, 1): 2288.0e6, (2024, 2): 2608.0e6, (2024, 3): 2790.0e6, (2024, 4): 2848.0e6,\n",
    "            (2025, 1): 2638.0e6, (2025, 2): 3046.0e6\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 优化点1：引入真实的季度交付量数据\n",
    "    delivery_data_official = {\n",
    "        'Automotive Sales': {\n",
    "            (2013, 1): 4900, (2013, 2): 5150, (2013, 3): 5500, (2013, 4): 6892,\n",
    "            (2014, 1): 7535, (2014, 2): 8763, (2014, 3): 9834, (2014, 4): 11627,\n",
    "            (2015, 1): 10045, (2015, 2): 11532, (2015, 3): 11603, (2015, 4): 17478,\n",
    "            (2016, 1): 14815, (2016, 2): 14402, (2016, 3): 24882, (2016, 4): 22252,\n",
    "            (2017, 1): 25418, (2017, 2): 22000, (2017, 3): 26150, (2017, 4): 29870,\n",
    "            (2018, 1): 29980, (2018, 2): 40740, (2018, 3): 83500, (2018, 4): 90700,\n",
    "            (2019, 1): 63000, (2019, 2): 95200, (2019, 3): 97000, (2019, 4): 112000,\n",
    "            (2020, 1): 88400, (2020, 2): 90891, (2020, 3): 139593, (2020, 4): 180570,\n",
    "            (2021, 1): 184800, (2021, 2): 201304, (2021, 3): 241300, (2021, 4): 308600,\n",
    "            (2022, 1): 310048, (2022, 2): 254695, (2022, 3): 343830, (2022, 4): 405278,\n",
    "            (2023, 1): 422875, (2023, 2): 466140, (2023, 3): 435059, (2023, 4): 484507,\n",
    "            (2024, 1): 386810, (2024, 2): 442000, (2024, 3): 450000, (2024, 4): 440000,\n",
    "            (2025, 1): 300000, (2025, 2): 350000\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Define and calculate geographical weights\n",
    "    asia_countries = ['China', 'Japan', 'South Korea', 'Singapore', 'India', 'Indonesia', 'Thailand', 'Malaysia', 'Taiwan']\n",
    "    oceania_countries = ['Australia', 'New Zealand']\n",
    "    europe_countries = ['Germany', 'United Kingdom', 'France', 'Norway', 'Netherlands', 'Sweden', 'Italy', 'Switzerland', 'Spain', 'Belgium', 'Austria', 'Denmark', 'Finland', 'Portugal', 'Ireland', 'Luxembourg', 'Iceland']\n",
    "    def get_continent(country):\n",
    "        if country in asia_countries: return 'Asia'\n",
    "        if country in oceania_countries: return 'Oceania'\n",
    "        if country in europe_countries: return 'Europe'\n",
    "        if country in ['United States', 'Canada', 'Mexico']: return 'North America'\n",
    "        return 'Other'\n",
    "    \n",
    "    dim_geography_df['Continent'] = dim_geography_df['Country'].apply(get_continent).astype(str)\n",
    "    dim_geography_df['Geo_Weight'] = 0.0\n",
    "    continent_weights = {'North America': 0.45, 'Europe': 0.30, 'Asia': 0.23, 'Oceania': 0.02, 'Other': 0.001}\n",
    "    country_weights = {'United States': 0.80, 'Canada': 0.20, 'China': 0.70, 'Japan': 0.18, 'South Korea': 0.13, 'Germany': 0.30, 'United Kingdom': 0.20, 'France': 0.15, 'Norway': 0.10, 'Australia': 0.75, 'New Zealand': 0.25, 'Taiwan': 0.1}\n",
    "    state_province_weights = {\n",
    "        'California': 0.40, 'Texas': 0.25, 'Florida': 0.15, 'Washington': 0.10, 'New York': 0.10,\n",
    "        'Ontario': 0.4, 'Quebec': 0.25, 'British Columbia': 0.2, 'Alberta': 0.15,\n",
    "        'Shanghai': 0.50, 'Beijing': 0.20, 'Guangdong': 0.20, 'Zhejiang': 0.10,\n",
    "        'Taipei': 0.5, 'New Taipei City': 0.2, 'Taichung': 0.1, 'Kaohsiung': 0.1, 'Tainan': 0.05, 'Taoyuan': 0.05,\n",
    "        'Bavaria': 0.40, 'North Rhine-Westphalia': 0.25, 'Baden-Württemberg': 0.15, 'Berlin': 0.10,\n",
    "        'Greater London': 0.50, 'South East England': 0.25, 'North West England': 0.15, 'West Midlands': 0.10,\n",
    "        'Île-de-France': 0.60, 'Auvergne-Rhône-Alpes': 0.20, 'Nouvelle-Aquitaine': 0.10, 'Provence-Alpes-Côte d\\'Azur': 0.10,\n",
    "        'Oslo': 0.70, 'Vestland': 0.15, 'Viken': 0.10, 'Trøndelag': 0.05,\n",
    "        'New South Wales': 0.5, 'Victoria': 0.3, 'Queensland': 0.1, 'Western Australia': 0.05, 'South Australia': 0.05,\n",
    "        'Auckland': 0.6, 'Wellington': 0.2, 'Canterbury': 0.1, 'Otago': 0.05, 'Waikato': 0.05,\n",
    "    }\n",
    "    \n",
    "    for _, row in dim_geography_df.iterrows():\n",
    "        continent = row['Continent']\n",
    "        country = row['Country']\n",
    "        state = row['State_Province']\n",
    "        \n",
    "        c_weight = continent_weights.get(continent, 0.001)\n",
    "        country_w = country_weights.get(country, 0.01)\n",
    "        state_w = state_province_weights.get(state, 0.01)\n",
    "        \n",
    "        dim_geography_df.loc[(dim_geography_df['Geo_ID'] == row['Geo_ID']), 'Geo_Weight'] = c_weight * country_w * state_w\n",
    "    dim_geography_df['Geo_Weight'] = dim_geography_df['Geo_Weight'].replace(0.0, 0.0001)\n",
    "\n",
    "    customer_ids = dim_customer_df['Customer_ID'].values\n",
    "    dim_time_df['Full_Date'] = pd.to_datetime(dim_time_df['Full_Date'])\n",
    "    if 'Quarter_of_Year' not in dim_time_df.columns:\n",
    "        dim_time_df['Quarter_of_Year'] = dim_time_df['Full_Date'].dt.quarter\n",
    "    dim_time_df['Year_Int'] = dim_time_df['Year'].astype(int)\n",
    "    dim_time_df['Quarter_Int'] = dim_time_df['Quarter_of_Year'].astype(int)\n",
    "    dim_time_df['Quarter_Start_Date'] = dim_time_df['Full_Date'].dt.to_period('Q').dt.start_time\n",
    "    \n",
    "    price_lookup = {}\n",
    "    if 'Standard_Price_USD' not in dim_prices_df.columns or 'Discounted_Price_USD' not in dim_prices_df.columns:\n",
    "        raise KeyError(\"Dim_Prices.csv is missing required columns.\")\n",
    "    dim_prices_df['Quarter_Start_Date'] = pd.to_datetime(dim_prices_df['Quarter_Start_Date'])\n",
    "    for _, row in dim_prices_df.iterrows():\n",
    "        quarter_start_date = row['Quarter_Start_Date']\n",
    "        product_id = row['Product_ID']\n",
    "        price_lookup[(quarter_start_date, product_id)] = {\n",
    "            'Standard_Price_USD': row['Standard_Price_USD'],\n",
    "            'Discounted_Price_USD': row['Discounted_Price_USD']\n",
    "        }\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 2: Dynamically Map Products to Categories\n",
    "    # --------------------------\n",
    "    \n",
    "    all_product_categories = dim_product_df['Product_Category'].unique().tolist()\n",
    "    \n",
    "    category_to_product_ids = defaultdict(list)\n",
    "    for _, row in dim_product_df.iterrows():\n",
    "        category_to_product_ids[row['Product_Category']].append(row['Product_ID'])\n",
    "\n",
    "    print(\"\\n--------------------\")\n",
    "    print(\"开始遍历所有维度ID...\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    for category in all_product_categories:\n",
    "        print(f\"找到的 '{category}' 产品ID数量: {len(category_to_product_ids[category])}\")\n",
    "    print(f\"找到的地理ID数量: {len(dim_geography_df['Geo_ID'].tolist())}\")\n",
    "\n",
    "    print(\"遍历成功，开始生成销售事实表。\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    geo_weights_dict = dim_geography_df.set_index('Geo_ID')['Geo_Weight'].to_dict()\n",
    "    real_geo_ids = dim_geography_df['Geo_ID'].tolist()\n",
    "    geo_weights_array = np.array(list(geo_weights_dict.values()))\n",
    "    total_geo_weight = sum(geo_weights_dict.values())\n",
    "    \n",
    "    if total_geo_weight > 0:\n",
    "        geo_probabilities = geo_weights_array / total_geo_weight\n",
    "    else:\n",
    "        num_geos = len(real_geo_ids)\n",
    "        geo_probabilities = np.full(num_geos, 1.0 / num_geos)\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 3: Generate Fact Table Records\n",
    "    # --------------------------\n",
    "    start_year = min(y for y, q in revenue_data['Automotive Sales'].keys())\n",
    "    total_generated_rows = 0\n",
    "    \n",
    "    # 定义每笔交易的平均收入（针对非按件销售的类别）\n",
    "    transaction_revenue_per_category = {\n",
    "        'Automotive Regulatory Credits': 10e6,\n",
    "        'Services & Other': 100e3,\n",
    "        'Automotive Leasing': 100e3,\n",
    "        'Energy Generation & Storage': 100e3,\n",
    "    }\n",
    "    \n",
    "    with open(output_filepath, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = None\n",
    "        \n",
    "        for year in range(start_year, end_date.year + 1):\n",
    "            yearly_rows_generated = 0\n",
    "            for quarter in range(1, 5):\n",
    "                if year == 2025 and quarter > 2:\n",
    "                    continue\n",
    "                \n",
    "                quarter_dates_df = dim_time_df[\n",
    "                    (dim_time_df['Year_Int'] == year) & (dim_time_df['Quarter_Int'] == quarter)\n",
    "                ]\n",
    "                \n",
    "                if quarter_dates_df.empty:\n",
    "                    continue\n",
    "\n",
    "                records = []\n",
    "                system_id = \"WEB\"\n",
    "                \n",
    "                for category_name in all_product_categories:\n",
    "                    revenue = revenue_data.get(category_name, {}).get((year, quarter), 0)\n",
    "                    product_ids_for_category = category_to_product_ids.get(category_name)\n",
    "                    \n",
    "                    if not product_ids_for_category:\n",
    "                        continue\n",
    "\n",
    "                    if revenue > 0:\n",
    "                        if category_name == 'Automotive Sales':\n",
    "                            # 优化点2：使用实际交付量作为交易笔数\n",
    "                            num_transactions = delivery_data_official['Automotive Sales'].get((year, quarter), 0)\n",
    "                            if num_transactions == 0:\n",
    "                                continue\n",
    "                            \n",
    "                            individual_revenue = revenue / num_transactions\n",
    "                        else:\n",
    "                            transaction_unit = transaction_revenue_per_category.get(category_name, 1000)\n",
    "                            num_transactions = int(revenue / transaction_unit)\n",
    "                            if num_transactions == 0:\n",
    "                                num_transactions = 1\n",
    "                            individual_revenue = revenue / num_transactions\n",
    "                        \n",
    "                        sampled_product_ids = np.random.choice(product_ids_for_category, size=num_transactions)\n",
    "                        sampled_geo_ids = np.random.choice(real_geo_ids, size=num_transactions, p=geo_probabilities)\n",
    "                        sampled_customer_ids = np.random.choice(customer_ids, size=num_transactions)\n",
    "                        sampled_time_ids = np.random.choice(quarter_dates_df['Time_ID'].values, size=num_transactions)\n",
    "                        \n",
    "                        revenue_per_record = individual_revenue\n",
    "                        \n",
    "                        for i in range(num_transactions):\n",
    "                            records.append({\n",
    "                                'TransactionID': generate_transaction_id(system_id),\n",
    "                                'Time_ID': sampled_time_ids[i],\n",
    "                                'Geo_ID': sampled_geo_ids[i],\n",
    "                                'Product_ID': sampled_product_ids[i],\n",
    "                                'Customer_ID': sampled_customer_ids[i],\n",
    "                                'Sales_Units': 1 if category_name == 'Automotive Sales' else 1,\n",
    "                                'Is_Discounted_Sale': False,\n",
    "                                'Revenue_USD': revenue_per_record * (1 + np.random.normal(0, 0.05)),\n",
    "                                'Revenue_Category': category_name\n",
    "                            })\n",
    "                \n",
    "                fact_sales_df_temp = pd.DataFrame(records)\n",
    "                \n",
    "                if not fact_sales_df_temp.empty:\n",
    "                    if writer is None:\n",
    "                        fact_sales_df_temp.to_csv(f, header=True, index=False, encoding='utf-8')\n",
    "                        writer = True\n",
    "                    else:\n",
    "                        fact_sales_df_temp.to_csv(f, header=False, index=False, encoding='utf-8')\n",
    "                    total_generated_rows += len(fact_sales_df_temp)\n",
    "                    yearly_rows_generated += len(fact_sales_df_temp)\n",
    "            \n",
    "            if yearly_rows_generated > 0:\n",
    "                print(f\"Generated {yearly_rows_generated:,} records for year {year}.\")\n",
    "\n",
    "    print(f\"\\nTotal generated records: {total_generated_rows:,}\")\n",
    "    return total_generated_rows\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    \n",
    "    print(f\"Loading all dimension tables and data sources from '{output_dir}'...\")\n",
    "    \n",
    "    dim_product_df = None\n",
    "    dim_time_df = None\n",
    "    dim_customer_df = None\n",
    "    dim_geography_df = None\n",
    "    dim_prices_df = None\n",
    "    \n",
    "    try:\n",
    "        dim_product_df = pd.read_csv(os.path.join(output_dir, 'Dim_Product.csv'))\n",
    "        dim_time_df = pd.read_csv(os.path.join(output_dir, 'Dim_Time.csv'))\n",
    "        dim_customer_df = pd.read_csv(os.path.join(output_dir, 'Dim_Customer.csv'))\n",
    "        dim_geography_df = pd.read_csv(os.path.join(output_dir, 'Dim_Geography.csv'))\n",
    "        dim_prices_df = pd.read_csv(os.path.join(output_dir, 'Dim_Prices.csv'))\n",
    "        \n",
    "        print(\"所有维度表加载成功。\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: One or more required CSV files are missing. Please ensure all dimension tables are in the '{output_dir}' directory. The file '{e.filename}' was not found.\")\n",
    "        print(\"Data generation failed due to missing files.\")\n",
    "        exit()\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    output_filepath = os.path.join(output_dir, 'Fact_Sales.csv')\n",
    "    \n",
    "    if os.path.exists(output_filepath):\n",
    "        os.remove(output_filepath)\n",
    "\n",
    "    print(\"\\n开始整理和生成销售事实表...\")\n",
    "    total_rows = generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath)\n",
    "    \n",
    "    if total_rows > 0:\n",
    "        end_time = time.time()\n",
    "        print(f\"\\nFact_Sales.csv successfully generated {total_rows:,} rows of data in {end_time - start_time:.2f} seconds.\")\n",
    "        print(\"数据生成完成!\")\n",
    "    else:\n",
    "        print(\"数据生成失败。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e572ed4d-7d7a-4674-a7ce-6cecdccdd415",
   "metadata": {},
   "source": [
    "## **遍历、加载维度表的数据计算和生成事实表** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1df3498-927b-4ef7-a9ce-da614ac789d2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all dimension tables and data sources from './output_data'...\n",
      "所有维度表加载成功。\n",
      "\n",
      "开始整理和生成销售事实表...\n",
      "\n",
      "--------------------\n",
      "开始遍历所有维度ID...\n",
      "--------------------\n",
      "找到的 'Automotive Leasing' 产品ID数量: 4\n",
      "找到的 'Energy Generation & Storage' 产品ID数量: 4\n",
      "找到的 'Automotive Sales' 产品ID数量: 3138\n",
      "找到的 'Automotive Regulatory Credits' 产品ID数量: 1\n",
      "找到的 'Services & Other' 产品ID数量: 4\n",
      "找到的地理ID数量: 432\n",
      "遍历成功，开始生成销售事实表。\n",
      "--------------------\n",
      "Generated 23,800 records for year 2013.\n",
      "Generated 32,100 records for year 2014.\n",
      "Generated 44,900 records for year 2015.\n",
      "Generated 60,800 records for year 2016.\n",
      "Generated 77,400 records for year 2017.\n",
      "Generated 102,000 records for year 2018.\n",
      "Generated 462,600 records for year 2019.\n",
      "Generated 535,200 records for year 2020.\n",
      "Generated 824,740 records for year 2021.\n",
      "Generated 1,249,350 records for year 2022.\n",
      "Generated 1,649,180 records for year 2023.\n",
      "Generated 2,247,450 records for year 2024.\n",
      "Generated 1,209,520 records for year 2025.\n",
      "\n",
      "Total generated records: 8,519,040\n",
      "\n",
      "Fact_Sales.csv successfully generated 852,084 rows of data in 51.88 seconds.\n",
      "数据生成完成!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def generate_transaction_id(system_id: str) -> str:\n",
    "    \"\"\"\n",
    "    根据给定的编码规则生成一个唯一的交易ID。\n",
    "\n",
    "    编码规则: TR + 时间戳(YYMMDDHHmmss) + 系统/商户ID + 随机数(6位)\n",
    "    例如: TR250901201234ABC987654\n",
    "\n",
    "    Args:\n",
    "        system_id: 3位系统或商户ID，例如 'WEB', 'POS'。\n",
    "\n",
    "    Returns:\n",
    "        生成的交易ID字符串。\n",
    "    \"\"\"\n",
    "    # 验证系统ID的长度是否为3位\n",
    "    if len(system_id) != 3:\n",
    "        raise ValueError(\"System ID must be exactly 3 characters long.\")\n",
    "\n",
    "    # 1. 固定前缀\n",
    "    prefix = \"TR\"\n",
    "\n",
    "    # 2. 生成时间戳 (YYMMDDHHmmss)\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(\"%y%m%d%H%M%S\")\n",
    "\n",
    "    # 3. 随机数/序列号 (这里为了演示，使用6位随机数)\n",
    "    # 在实际生产环境中，建议使用原子性的自增序列号来保证唯一性\n",
    "    random_part = str(random.randint(100000, 999999))\n",
    "\n",
    "    # 4. 拼接所有部分\n",
    "    transaction_id = f\"{prefix}{timestamp}{system_id.upper()}{random_part}\"\n",
    "\n",
    "    return transaction_id\n",
    "\n",
    "def generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath, scale_factor=1):\n",
    "    \"\"\"\n",
    "    Generates the Fact_Sales table by combining all dimension tables.\n",
    "    Uses real-world Tesla sales distribution and volume data for realistic output.\n",
    "    \n",
    "    Args:\n",
    "        scale_factor (int): A multiplier to scale the total number of records.\n",
    "    \"\"\"\n",
    "    end_date = datetime(2025, 6, 30)\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 1: Parse and Load Data (Hardcoded for this example)\n",
    "    # --------------------------\n",
    "    # 此数据源为特斯拉2013-2025Q2的季度收入数据（Revenue）\n",
    "    # 来源：特斯拉公开财报，单位为百万美元（M），实际收入需乘以1,000,000\n",
    "    revenue_data = {\n",
    "        'Automotive Sales': {      \n",
    "            (2013, 1): 400.0e6, (2013, 2): 420.0e6, (2013, 3): 450.0e6, (2013, 4): 500.0e6,\n",
    "            (2014, 1): 700.0e6, (2014, 2): 750.0e6, (2014, 3): 800.0e6, (2014, 4): 850.0e6,\n",
    "            (2015, 1): 900.0e6, (2015, 2): 950.0e6, (2015, 3): 1000.0e6, (2015, 4): 1100.0e6,\n",
    "            (2016, 1): 1500.0e6, (2016, 2): 1600.0e6, (2016, 3): 1800.0e6, (2016, 4): 2000.0e6,\n",
    "            (2017, 1): 2500.0e6, (2017, 2): 2800.0e6, (2017, 3): 3000.0e6, (2017, 4): 3200.0e6,\n",
    "            (2018, 1): 3300.0e6, (2018, 2): 3900.0e6, (2018, 3): 6600.0e6, (2018, 4): 7000.0e6,\n",
    "            (2019, 1): 3509.0e6, (2019, 2): 5168.0e6, (2019, 3): 5132.0e6, (2019, 4): 6143.0e6,\n",
    "            (2020, 1): 4893.0e6, (2020, 2): 4911.0e6, (2020, 3): 7346.0e6, (2020, 4): 9034.0e6,\n",
    "            (2021, 1): 8187.0e6, (2021, 2): 9520.0e6, (2021, 3): 11393.0e6, (2021, 4): 15025.0e6,\n",
    "            (2022, 1): 15514.0e6, (2022, 2): 13670.0e6, (2022, 3): 17785.0e6, (2022, 4): 20241.0e6,\n",
    "            (2023, 1): 18878.0e6, (2023, 2): 20419.0e6, (2023, 3): 18582.0e6, (2023, 4): 20630.0e6,\n",
    "            (2024, 1): 16460.0e6, (2024, 2): 18530.0e6, (2024, 3): 18831.0e6, (2024, 4): 18659.0e6,\n",
    "            (2025, 1): 12925.0e6, (2025, 2): 15787.0e6\n",
    "        },\n",
    "        'Automotive Regulatory Credits': {\n",
    "            (2013, 1): 0, (2013, 2): 0, (2013, 3): 0, (2013, 4): 0,\n",
    "            (2014, 1): 0, (2014, 2): 0, (2014, 3): 0, (2014, 4): 0,\n",
    "            (2015, 1): 0, (2015, 2): 0, (2015, 3): 0, (2015, 4): 0,\n",
    "            (2016, 1): 0, (2016, 2): 0, (2016, 3): 0, (2016, 4): 0,\n",
    "            (2017, 1): 0, (2017, 2): 0, (2017, 3): 0, (2017, 4): 0,\n",
    "            (2018, 1): 0, (2018, 2): 0, (2018, 3): 0, (2018, 4): 0,\n",
    "            (2019, 1): 0, (2019, 2): 0, (2019, 3): 0, (2019, 4): 0,\n",
    "            (2020, 1): 0, (2020, 2): 0, (2020, 3): 0, (2020, 4): 0,\n",
    "            (2021, 1): 518.0e6, (2021, 2): 354.0e6, (2021, 3): 279.0e6, (2021, 4): 314.0e6,\n",
    "            (2022, 1): 679.0e6, (2022, 2): 344.0e6, (2022, 3): 286.0e6, (2022, 4): 467.0e6,\n",
    "            (2023, 1): 521.0e6, (2023, 2): 282.0e6, (2023, 3): 554.0e6, (2023, 4): 433.0e6,\n",
    "            (2024, 1): 442.0e6, (2024, 2): 890.0e6, (2024, 3): 739.0e6, (2024, 4): 692.0e6,\n",
    "            (2025, 1): 595.0e6, (2025, 2): 439.0e6\n",
    "        },\n",
    "        'Automotive Leasing': {\n",
    "            (2013, 1): 25.0e6, (2013, 2): 28.0e6, (2013, 3): 30.0e6, (2013, 4): 32.0e6,\n",
    "            (2014, 1): 35.0e6, (2014, 2): 38.0e6, (2014, 3): 40.0e6, (2014, 4): 42.0e6,\n",
    "            (2015, 1): 45.0e6, (2015, 2): 48.0e6, (2015, 3): 50.0e6, (2015, 4): 55.0e6,\n",
    "            (2016, 1): 60.0e6, (2016, 2): 65.0e6, (2016, 3): 70.0e6, (2016, 4): 75.0e6,\n",
    "            (2017, 1): 80.0e6, (2017, 2): 85.0e6, (2017, 3): 90.0e6, (2017, 4): 95.0e6,\n",
    "            (2018, 1): 100.0e6, (2018, 2): 110.0e6, (2018, 3): 120.0e6, (2018, 4): 130.0e6,\n",
    "            (2019, 1): 215.0e6, (2019, 2): 208.0e6, (2019, 3): 221.0e6, (2019, 4): 225.0e6,\n",
    "            (2020, 1): 239.0e6, (2020, 2): 268.0e6, (2020, 3): 265.0e6, (2020, 4): 280.0e6,\n",
    "            (2021, 1): 297.0e6, (2021, 2): 332.0e6, (2021, 3): 385.0e6, (2021, 4): 628.0e6,\n",
    "            (2022, 1): 668.0e6, (2022, 2): 588.0e6, (2022, 3): 621.0e6, (2022, 4): 599.0e6,\n",
    "            (2023, 1): 564.0e6, (2023, 2): 567.0e6, (2023, 3): 489.0e6, (2023, 4): 500.0e6,\n",
    "            (2024, 1): 476.0e6, (2024, 2): 458.0e6, (2024, 3): 446.0e6, (2024, 4): 447.0e6,\n",
    "            (2025, 1): 447.0e6, (2025, 2): 435.0e6\n",
    "        },\n",
    "        'Energy Generation & Storage': {\n",
    "            (2013, 1): 10.0e6, (2013, 2): 12.0e6, (2013, 3): 14.0e6, (2013, 4): 16.0e6,\n",
    "            (2104, 1): 18.0e6, (2014, 2): 20.0e6, (2014, 3): 22.0e6, (2014, 4): 24.0e6,\n",
    "            (2015, 1): 26.0e6, (2015, 2): 28.0e6, (2015, 3): 30.0e6, (2015, 4): 32.0e6,\n",
    "            (2016, 1): 35.0e6, (2016, 2): 38.0e6, (2016, 3): 40.0e6, (2016, 4): 42.0e6,\n",
    "            (2017, 1): 45.0e6, (2017, 2): 48.0e6, (2017, 3): 50.0e6, (2017, 4): 55.0e6,\n",
    "            (2018, 1): 60.0e6, (2018, 2): 65.0e6, (2018, 3): 70.0e6, (2018, 4): 75.0e6,\n",
    "            (2019, 1): 324.0e6, (2019, 2): 369.0e6, (2019, 3): 402.0e6, (2019, 4): 436.0e6,\n",
    "            (2020, 1): 293.0e6, (2020, 2): 370.0e6, (2020, 3): 579.0e6, (2020, 4): 752.0e6,\n",
    "            (2021, 1): 494.0e6, (2021, 2): 801.0e6, (2021, 3): 806.0e6, (2021, 4): 688.0e6,\n",
    "            (2022, 1): 616.0e6, (2022, 2): 866.0e6, (2022, 3): 1117.0e6, (2022, 4): 1310.0e6,\n",
    "            (2023, 1): 1529.0e6, (2023, 2): 1509.0e6, (2023, 3): 1559.0e6, (2023, 4): 1438.0e6,\n",
    "            (2024, 1): 1635.0e6, (2024, 2): 3014.0e6, (2024, 3): 2376.0e6, (2024, 4): 3061.0e6,\n",
    "            (2025, 1): 2730.0e6, (2025, 2): 2789.0e6\n",
    "        },\n",
    "        'Services & Other': {\n",
    "            (2013, 1): 15.0e6, (2013, 2): 17.0e6, (2013, 3): 19.0e6, (2013, 4): 20.0e6,\n",
    "            (2014, 1): 22.0e6, (2014, 2): 24.0e6, (2014, 3): 26.0e6, (2014, 4): 28.0e6,\n",
    "            (2015, 1): 30.0e6, (2015, 2): 32.0e6, (2015, 3): 35.0e6, (2015, 4): 38.0e6,\n",
    "            (2016, 1): 40.0e6, (2016, 2): 45.0e6, (2016, 3): 48.0e6, (2016, 4): 50.0e6,\n",
    "            (2017, 1): 55.0e6, (2017, 2): 58.0e6, (2017, 3): 55.0e6, (2017, 4): 58.0e6,\n",
    "            (2018, 1): 65.0e6, (2018, 2): 70.0e6, (2018, 3): 75.0e6, (2018, 4): 80.0e6,\n",
    "            (2019, 1): 493.0e6, (2019, 2): 605.0e6, (2019, 3): 548.0e6, (2019, 4): 580.0e6,\n",
    "            (2020, 1): 560.0e6, (2020, 2): 487.0e6, (2020, 3): 581.0e6, (2020, 4): 678.0e6,\n",
    "            (2021, 1): 893.0e6, (2021, 2): 951.0e6, (2021, 3): 894.0e6, (2021, 4): 1064.0e6,\n",
    "            (2022, 1): 1279.0e6, (2022, 2): 1466.0e6, (2022, 3): 1645.0e6, (2022, 4): 1701.0e6,\n",
    "            (2023, 1): 1837.0e6, (2023, 2): 2150.0e6, (2023, 3): 2166.0e6, (2023, 4): 2166.0e6,\n",
    "            (2024, 1): 2288.0e6, (2024, 2): 2608.0e6, (2024, 3): 2790.0e6, (2024, 4): 2848.0e6,\n",
    "            (2025, 1): 2638.0e6, (2025, 2): 3046.0e6\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 定义每笔交易的平均收入（针对非按件销售的类别）\n",
    "    transaction_revenue_per_category = {\n",
    "        'Automotive Regulatory Credits': 10e6,\n",
    "        'Services & Other': 100e3,\n",
    "        'Automotive Leasing': 100e3,\n",
    "        'Energy Generation & Storage': 100e3,\n",
    "    }\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 2: Define Product Distribution Weights\n",
    "    # --------------------------\n",
    "    # 模拟不同时期各个汽车型号的市场份额变化\n",
    "    # 注意：这些权重是模拟数据，旨在使生成的数据更具现实感\n",
    "    automotive_product_distribution = {\n",
    "        'Model S': {\n",
    "            '2013-2016': 0.8,\n",
    "            '2017-2018': 0.3,\n",
    "            '2019-2022': 0.1,\n",
    "            '2023-2025': 0.05,\n",
    "        },\n",
    "        'Model X': {\n",
    "            '2015-2018': 0.2,\n",
    "            '2019-2022': 0.1,\n",
    "            '2023-2025': 0.05,\n",
    "        },\n",
    "        'Model 3': {\n",
    "            '2017-2018': 0.5,\n",
    "            '2019-2022': 0.6,\n",
    "            '2023-2025': 0.4,\n",
    "        },\n",
    "        'Model Y': {\n",
    "            '2020-2022': 0.2,\n",
    "            '2023-2025': 0.4,\n",
    "        },\n",
    "        'Cybertruck': {\n",
    "            '2023-2025': 0.1,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Define and calculate geographical weights\n",
    "    asia_countries = ['China', 'Japan', 'South Korea', 'Singapore', 'India', 'Indonesia', 'Thailand', 'Malaysia', 'Taiwan']\n",
    "    oceania_countries = ['Australia', 'New Zealand']\n",
    "    europe_countries = ['Germany', 'United Kingdom', 'France', 'Norway', 'Netherlands', 'Sweden', 'Italy', 'Switzerland', 'Spain', 'Belgium', 'Austria', 'Denmark', 'Finland', 'Portugal', 'Ireland', 'Luxembourg', 'Iceland']\n",
    "    def get_continent(country):\n",
    "        if country in asia_countries: return 'Asia'\n",
    "        if country in oceania_countries: return 'Oceania'\n",
    "        if country in europe_countries: return 'Europe'\n",
    "        if country in ['United States', 'Canada', 'Mexico']: return 'North America'\n",
    "        return 'Other'\n",
    "    \n",
    "    dim_geography_df['Continent'] = dim_geography_df['Country'].apply(get_continent).astype(str)\n",
    "    dim_geography_df['Geo_Weight'] = 0.0\n",
    "    continent_weights = {'North America': 0.45, 'Europe': 0.30, 'Asia': 0.23, 'Oceania': 0.02, 'Other': 0.001}\n",
    "    country_weights = {'United States': 0.80, 'Canada': 0.20, 'China': 0.70, 'Japan': 0.18, 'South Korea': 0.13, 'Germany': 0.30, 'United Kingdom': 0.20, 'France': 0.15, 'Norway': 0.10, 'Australia': 0.75, 'New Zealand': 0.25, 'Taiwan': 0.1}\n",
    "    state_province_weights = {\n",
    "        'California': 0.40, 'Texas': 0.25, 'Florida': 0.15, 'Washington': 0.10, 'New York': 0.10,\n",
    "        'Ontario': 0.4, 'Quebec': 0.25, 'British Columbia': 0.2, 'Alberta': 0.15,\n",
    "        'Shanghai': 0.50, 'Beijing': 0.20, 'Guangdong': 0.20, 'Zhejiang': 0.10,\n",
    "        'Taipei': 0.5, 'New Taipei City': 0.2, 'Taichung': 0.1, 'Kaohsiung': 0.1, 'Tainan': 0.05, 'Taoyuan': 0.05,\n",
    "        'Bavaria': 0.40, 'North Rhine-Westphalia': 0.25, 'Baden-Württemberg': 0.15, 'Berlin': 0.10,\n",
    "        'Greater London': 0.50, 'South East England': 0.25, 'North West England': 0.15, 'West Midlands': 0.10,\n",
    "        'Île-de-France': 0.60, 'Auvergne-Rhône-Alpes': 0.20, 'Nouvelle-Aquitaine': 0.10, 'Provence-Alpes-Côte d\\'Azur': 0.10,\n",
    "        'Oslo': 0.70, 'Vestland': 0.15, 'Viken': 0.10, 'Trøndelag': 0.05,\n",
    "        'New South Wales': 0.5, 'Victoria': 0.3, 'Queensland': 0.1, 'Western Australia': 0.05, 'South Australia': 0.05,\n",
    "        'Auckland': 0.6, 'Wellington': 0.2, 'Canterbury': 0.1, 'Otago': 0.05, 'Waikato': 0.05,\n",
    "    }\n",
    "    \n",
    "    for _, row in dim_geography_df.iterrows():\n",
    "        continent = row['Continent']\n",
    "        country = row['Country']\n",
    "        state = row['State_Province']\n",
    "        \n",
    "        c_weight = continent_weights.get(continent, 0.001)\n",
    "        country_w = country_weights.get(country, 0.01)\n",
    "        state_w = state_province_weights.get(state, 0.01)\n",
    "        \n",
    "        dim_geography_df.loc[(dim_geography_df['Geo_ID'] == row['Geo_ID']), 'Geo_Weight'] = c_weight * country_w * state_w\n",
    "    dim_geography_df['Geo_Weight'] = dim_geography_df['Geo_Weight'].replace(0.0, 0.0001)\n",
    "\n",
    "    customer_ids = dim_customer_df['Customer_ID'].values\n",
    "    dim_time_df['Full_Date'] = pd.to_datetime(dim_time_df['Full_Date'])\n",
    "    if 'Quarter_of_Year' not in dim_time_df.columns:\n",
    "        dim_time_df['Quarter_of_Year'] = dim_time_df['Full_Date'].dt.quarter\n",
    "    dim_time_df['Year_Int'] = dim_time_df['Year'].astype(int)\n",
    "    dim_time_df['Quarter_Int'] = dim_time_df['Quarter_of_Year'].astype(int)\n",
    "    dim_time_df['Quarter_Start_Date'] = dim_time_df['Full_Date'].dt.to_period('Q').dt.start_time\n",
    "    \n",
    "    price_lookup = {}\n",
    "    if 'Standard_Price_USD' not in dim_prices_df.columns or 'Discounted_Price_USD' not in dim_prices_df.columns:\n",
    "        raise KeyError(\"Dim_Prices.csv is missing required columns.\")\n",
    "    dim_prices_df['Quarter_Start_Date'] = pd.to_datetime(dim_prices_df['Quarter_Start_Date'])\n",
    "    for _, row in dim_prices_df.iterrows():\n",
    "        quarter_start_date = row['Quarter_Start_Date']\n",
    "        product_id = row['Product_ID']\n",
    "        price_lookup[(quarter_start_date, product_id)] = {\n",
    "            'Standard_Price_USD': row['Standard_Price_USD'],\n",
    "            'Discounted_Price_USD': row['Discounted_Price_USD']\n",
    "        }\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 3: Dynamically Map Products to Categories\n",
    "    # --------------------------\n",
    "    \n",
    "    # 使用所有独特的产品类别\n",
    "    all_product_categories = dim_product_df['Product_Category'].unique().tolist()\n",
    "    \n",
    "    category_to_product_ids = defaultdict(list)\n",
    "    product_id_to_name = dim_product_df.set_index('Product_ID')['Product_Name'].to_dict()\n",
    "    \n",
    "    for _, row in dim_product_df.iterrows():\n",
    "        category_to_product_ids[row['Product_Category']].append(row['Product_ID'])\n",
    "\n",
    "    print(\"\\n--------------------\")\n",
    "    print(\"开始遍历所有维度ID...\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    # 打印总结信息，使用动态获取的类别\n",
    "    for category in all_product_categories:\n",
    "        print(f\"找到的 '{category}' 产品ID数量: {len(category_to_product_ids[category])}\")\n",
    "    print(f\"找到的地理ID数量: {len(dim_geography_df['Geo_ID'].tolist())}\")\n",
    "\n",
    "    print(\"遍历成功，开始生成销售事实表。\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    # 预先计算一次地理概率，避免在循环中重复计算\n",
    "    geo_weights_dict = dim_geography_df.set_index('Geo_ID')['Geo_Weight'].to_dict()\n",
    "    real_geo_ids = dim_geography_df['Geo_ID'].tolist()\n",
    "    geo_weights_array = np.array(list(geo_weights_dict.values()))\n",
    "    total_geo_weight = sum(geo_weights_dict.values())\n",
    "    \n",
    "    if total_geo_weight > 0:\n",
    "        geo_probabilities = geo_weights_array / total_geo_weight\n",
    "    else:\n",
    "        num_geos = len(real_geo_ids)\n",
    "        geo_probabilities = np.full(num_geos, 1.0 / num_geos)\n",
    "\n",
    "    # --------------------------\n",
    "    # Step 4: Generate Fact Table Records\n",
    "    # --------------------------\n",
    "    start_year = min(y for y, q in revenue_data['Automotive Sales'].keys())\n",
    "    total_generated_rows = 0\n",
    "    \n",
    "    with open(output_filepath, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = None\n",
    "        \n",
    "        for year in range(start_year, end_date.year + 1):\n",
    "            yearly_rows_generated = 0\n",
    "            for quarter in range(1, 5):\n",
    "                if year == 2025 and quarter > 2:\n",
    "                    continue\n",
    "                \n",
    "                quarter_dates_df = dim_time_df[\n",
    "                    (dim_time_df['Year_Int'] == year) & (dim_time_df['Quarter_Int'] == quarter)\n",
    "                ]\n",
    "                \n",
    "                if quarter_dates_df.empty:\n",
    "                    continue\n",
    "\n",
    "                records = []\n",
    "                \n",
    "                # 为每笔交易生成一个唯一的ID\n",
    "                system_id = \"WEB\" # 假设交易来自网页端\n",
    "                \n",
    "                for category_name in all_product_categories:\n",
    "                    revenue = revenue_data.get(category_name, {}).get((year, quarter), 0)\n",
    "                    \n",
    "                    if revenue > 0:\n",
    "                        if category_name == 'Automotive Sales':\n",
    "                            # 1. 动态获取 'Automotive Sales' 类别下的所有产品\n",
    "                            automotive_product_ids = category_to_product_ids.get(category_name, [])\n",
    "                            \n",
    "                            # 2. 如果该类别下没有产品，则跳过\n",
    "                            if not automotive_product_ids:\n",
    "                                continue\n",
    "                            \n",
    "                            # 3. 为每个产品分配权重，优先使用硬编码的权重，未列出的产品使用默认权重\n",
    "                            current_product_weights = {}\n",
    "                            total_assigned_weight = 0\n",
    "                            \n",
    "                            # 将 hardcoded_distribution 转换为 product_id 到 weight 的映射\n",
    "                            hardcoded_product_id_weights = {}\n",
    "                            for p_name, time_weights in automotive_product_distribution.items():\n",
    "                                matching_product_df = dim_product_df[dim_product_df['Product_Name'] == p_name]\n",
    "                                if not matching_product_df.empty:\n",
    "                                    product_id = matching_product_df['Product_ID'].iloc[0]\n",
    "                                    for time_range, weight in time_weights.items():\n",
    "                                        start_y, end_y = map(int, time_range.split('-'))\n",
    "                                        if start_y <= year <= end_y:\n",
    "                                            hardcoded_product_id_weights[product_id] = weight\n",
    "                                            total_assigned_weight += weight\n",
    "                                else:\n",
    "                                    # 这部分不再打印警告，因为我们现在会处理所有产品，而不仅仅是硬编码的\n",
    "                                    pass\n",
    "\n",
    "                            # 计算剩余的未分配权重\n",
    "                            remaining_weight = max(0, 1.0 - total_assigned_weight)\n",
    "                            unassigned_product_ids = [pid for pid in automotive_product_ids if pid not in hardcoded_product_id_weights]\n",
    "                            default_weight = remaining_weight / len(unassigned_product_ids) if unassigned_product_ids else 0\n",
    "\n",
    "                            # 分配默认权重给剩余产品\n",
    "                            for pid in unassigned_product_ids:\n",
    "                                current_product_weights[pid] = default_weight\n",
    "\n",
    "                            # 合并硬编码和默认权重\n",
    "                            current_product_weights.update(hardcoded_product_id_weights)\n",
    "                            \n",
    "                            # 4. 再次确保权重总和为1\n",
    "                            total_weight = sum(current_product_weights.values())\n",
    "                            if total_weight > 0:\n",
    "                                normalized_weights = {p_id: w / total_weight for p_id, w in current_product_weights.items()}\n",
    "                            else: # 如果没有有效权重，则平均分配\n",
    "                                normalized_weights = {p_id: 1.0 / len(current_product_weights) for p_id in current_product_weights.keys()}\n",
    "\n",
    "                            # 5. 计算加权平均价格\n",
    "                            weighted_avg_price = 0\n",
    "                            for product_id, weight in normalized_weights.items():\n",
    "                                quarter_start_date = quarter_dates_df['Quarter_Start_Date'].iloc[0]\n",
    "                                price_info = price_lookup.get((quarter_start_date, product_id))\n",
    "                                if price_info:\n",
    "                                    weighted_avg_price += price_info['Standard_Price_USD'] * weight\n",
    "\n",
    "                            if weighted_avg_price == 0:\n",
    "                                continue\n",
    "                            \n",
    "                            # 6. 根据加权平均价格估算交易数量\n",
    "                            # --- 关键修改：在这里应用缩放因子 ---\n",
    "                            num_transactions = int(revenue / weighted_avg_price)\n",
    "                            num_transactions *= scale_factor\n",
    "                            if num_transactions == 0:\n",
    "                                num_transactions = 1\n",
    "                            \n",
    "                            # 7. 根据归一化权重生成交易记录\n",
    "                            for _ in range(num_transactions):\n",
    "                                sampled_product_id = random.choices(list(normalized_weights.keys()), weights=list(normalized_weights.values()), k=1)[0]\n",
    "                                quarter_start_date = quarter_dates_df['Quarter_Start_Date'].iloc[0]\n",
    "                                price_info = price_lookup.get((quarter_start_date, sampled_product_id))\n",
    "\n",
    "                                if price_info:\n",
    "                                    is_discounted = random.random() < 0.2\n",
    "                                    revenue_per_record = price_info['Discounted_Price_USD'] if is_discounted else price_info['Standard_Price_USD']\n",
    "                                    \n",
    "                                    records.append({\n",
    "                                        'TransactionID': generate_transaction_id(system_id),\n",
    "                                        'Time_ID': random.choice(quarter_dates_df['Time_ID'].values),\n",
    "                                        'Geo_ID': random.choices(real_geo_ids, weights=geo_probabilities, k=1)[0],\n",
    "                                        'Product_ID': sampled_product_id,\n",
    "                                        'Customer_ID': random.choice(customer_ids),\n",
    "                                        'Sales_Units': 1,\n",
    "                                        'Is_Discounted_Sale': is_discounted,\n",
    "                                        'Revenue_USD': revenue_per_record * (1 + np.random.normal(0, 0.01)),\n",
    "                                        'Revenue_Category': category_name\n",
    "                                    })\n",
    "                        else:\n",
    "                            # Original logic for other categories remains the same\n",
    "                            product_ids_for_category = category_to_product_ids.get(category_name)\n",
    "                            transaction_unit = transaction_revenue_per_category.get(category_name, 1000)\n",
    "                            num_transactions = int(revenue / transaction_unit)\n",
    "                            # --- 关键修改：在这里应用缩放因子 ---\n",
    "                            num_transactions *= scale_factor\n",
    "                            if num_transactions == 0:\n",
    "                                num_transactions = 1\n",
    "                            \n",
    "                            sampled_product_ids = np.random.choice(product_ids_for_category, size=num_transactions)\n",
    "                            sampled_geo_ids = np.random.choice(real_geo_ids, size=num_transactions, p=geo_probabilities)\n",
    "                            sampled_customer_ids = np.random.choice(customer_ids, size=num_transactions)\n",
    "                            sampled_time_ids = np.random.choice(quarter_dates_df['Time_ID'].values, size=num_transactions)\n",
    "\n",
    "                            for i in range(num_transactions):\n",
    "                                records.append({\n",
    "                                    'TransactionID': generate_transaction_id(system_id),\n",
    "                                    'Time_ID': sampled_time_ids[i],\n",
    "                                    'Geo_ID': sampled_geo_ids[i],\n",
    "                                    'Product_ID': sampled_product_ids[i],\n",
    "                                    'Customer_ID': sampled_customer_ids[i],\n",
    "                                    'Sales_Units': 1,\n",
    "                                    'Is_Discounted_Sale': False,\n",
    "                                    'Revenue_USD': revenue / num_transactions * (1 + np.random.normal(0, 0.05)),\n",
    "                                    'Revenue_Category': category_name\n",
    "                                })\n",
    "                \n",
    "                fact_sales_df_temp = pd.DataFrame(records)\n",
    "                \n",
    "                if not fact_sales_df_temp.empty:\n",
    "                    if writer is None:\n",
    "                        fact_sales_df_temp.to_csv(f, header=True, index=False, encoding='utf-8')\n",
    "                        writer = True\n",
    "                    else:\n",
    "                        fact_sales_df_temp.to_csv(f, header=False, index=False, encoding='utf-8')\n",
    "                    total_generated_rows += len(fact_sales_df_temp)\n",
    "                    yearly_rows_generated += len(fact_sales_df_temp)\n",
    "            \n",
    "            if yearly_rows_generated > 0:\n",
    "                print(f\"Generated {yearly_rows_generated:,} records for year {year}.\")\n",
    "\n",
    "    print(f\"\\nTotal generated records: {total_generated_rows:,}\")\n",
    "    return total_rows\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    \n",
    "    print(f\"Loading all dimension tables and data sources from '{output_dir}'...\")\n",
    "    \n",
    "    dim_product_df = None\n",
    "    dim_time_df = None\n",
    "    dim_customer_df = None\n",
    "    dim_geography_df = None\n",
    "    dim_prices_df = None\n",
    "    \n",
    "    try:\n",
    "        dim_product_df = pd.read_csv(os.path.join(output_dir, 'Dim_Product.csv'))\n",
    "        dim_time_df = pd.read_csv(os.path.join(output_dir, 'Dim_Time.csv'))\n",
    "        dim_customer_df = pd.read_csv(os.path.join(output_dir, 'Dim_Customer.csv'))\n",
    "        dim_geography_df = pd.read_csv(os.path.join(output_dir, 'Dim_Geography.csv'))\n",
    "        dim_prices_df = pd.read_csv(os.path.join(output_dir, 'Dim_Prices.csv'))\n",
    "        \n",
    "        print(\"所有维度表加载成功。\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: One or more required CSV files are missing. Please ensure all dimension tables are in the '{output_dir}' directory. The file '{e.filename}' was not found.\")\n",
    "        print(\"Data generation failed due to missing files.\")\n",
    "        exit()\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    output_filepath = os.path.join(output_dir, 'Fact_Sales.csv')\n",
    "    \n",
    "    if os.path.exists(output_filepath):\n",
    "        os.remove(output_filepath)\n",
    "\n",
    "    print(\"\\n开始整理和生成销售事实表...\")\n",
    "    # --- 关键修改：在这里调用函数时传入一个更大的缩放因子，例如 10 ---\n",
    "    total_rows = generate_fact_sales(\n",
    "        dim_product_df, \n",
    "        dim_time_df, \n",
    "        dim_customer_df, \n",
    "        dim_geography_df, \n",
    "        dim_prices_df, \n",
    "        output_filepath, \n",
    "        scale_factor=10\n",
    "    )\n",
    "    \n",
    "    if total_rows > 0:\n",
    "        end_time = time.time()\n",
    "        print(f\"\\nFact_Sales.csv successfully generated {total_rows:,} rows of data in {end_time - start_time:.2f} seconds.\")\n",
    "        print(\"数据生成完成!\")\n",
    "    else:\n",
    "        print(\"数据生成失败。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e59ea6-b51e-4b2f-b709-9fa0db7132e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5200a96-0373-4a73-9b65-c0f3ad2ff1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2e6bb7f-03d7-4a68-ae2d-78a510942510",
   "metadata": {},
   "source": [
    "### **1/6: 生成 Dim_Product 表 （覆盖绝大部分特斯拉产品）(简单静态数据)维度表更可能需要更新Update或追加Append。例如，新产品发布，此时就需要更新Update或追加Append表中的相应记录。这种变化管理被称为“缓慢变化维度”（Slowly Changing Dimension, SCD）** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24d09db5-faee-4bf3-86ba-7310c0d8c313",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Dim_Product table...\n",
      "Saving Dim_Product.csv...\n",
      "Dim_Product.csv has been successfully generated with 3151 rows in 0.01 seconds.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"1/6: Generate Dim_Product Table with detailed configurations.\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import product\n",
    "from datetime import date\n",
    "\n",
    "# Use a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def generate_dim_product():\n",
    "    \"\"\"\n",
    "    Generates the Dim_Product table with all product and configuration details.\n",
    "    \"\"\"\n",
    "    # 基础产品信息 (Base products)\n",
    "    base_products = {\n",
    "        'Model 3': 'Automotive',\n",
    "        'Model Y': 'Automotive',\n",
    "        'Model S': 'Automotive',\n",
    "        'Model X': 'Automotive',\n",
    "        'Cybertruck': 'Automotive'\n",
    "    }\n",
    "\n",
    "    # 汽车版本和价格 (Variants and their prices)\n",
    "    variants = {\n",
    "        'Model 3': {\n",
    "            'Rear-Wheel Drive': np.nan,\n",
    "            'Long Range RWD': np.nan,\n",
    "            'Long Range AWD': np.nan,\n",
    "            'Performance': np.nan\n",
    "        },\n",
    "        'Model Y': {\n",
    "            'Standard Range RWD': np.nan,\n",
    "            'Long Range RWD': np.nan,\n",
    "            'Long Range AWD': np.nan,\n",
    "            'Performance': np.nan,\n",
    "            'Model Y L (3-Row)': np.nan\n",
    "        },\n",
    "        'Model S': {\n",
    "            'Long Range AWD': np.nan,\n",
    "            'Plaid': np.nan\n",
    "        },\n",
    "        'Model X': {\n",
    "            'All-Wheel Drive': np.nan,\n",
    "            'Plaid': np.nan\n",
    "        },\n",
    "        'Cybertruck': {\n",
    "            'Long Range': np.nan,\n",
    "            'AWD': np.nan,\n",
    "            'Cyberbeast': np.nan\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 可配置选项和价格 (Configurable options and their prices)\n",
    "    options = {\n",
    "        'Paint_Color': {\n",
    "            'Solid Black': np.nan, 'Deep Blue Metallic': np.nan, 'Stealth Grey': np.nan,\n",
    "            'Ultra Red': np.nan, 'Quicksilver': np.nan, 'Pearl White Multi-Coat': np.nan, 'None': np.nan\n",
    "        },\n",
    "        'Wheel_Type': {\n",
    "            'Aero Wheels': np.nan, '19\" Nova Wheels': np.nan, 'Crossflow 19\"': np.nan,\n",
    "            'Helix 20\"': np.nan, 'Base Wheels': np.nan, 'Performance Wheels': np.nan, 'None': np.nan\n",
    "        },\n",
    "        'Interior_Type': {\n",
    "            'Black Interior': np.nan, 'Black and White Interior': np.nan, 'Cream Interior': np.nan, 'None': np.nan\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Define product release dates for ID ordering\n",
    "    # Use a dictionary to map product models to their approximate release dates\n",
    "    release_dates = {\n",
    "        'Model S': date(2012, 6, 1),\n",
    "        'Model X': date(2015, 9, 1),\n",
    "        'Model 3': date(2017, 7, 1),\n",
    "        'Model Y': date(2020, 1, 1),\n",
    "        'Cybertruck': date(2023, 11, 1),\n",
    "        'N/A': date(2010, 1, 1) # A generic early date for non-automotive products\n",
    "    }\n",
    "\n",
    "    all_products = []\n",
    "\n",
    "    # Generate all automotive product configurations first\n",
    "    for model, category in base_products.items():\n",
    "        if model in variants:\n",
    "            variant_names = list(variants[model].keys())\n",
    "            paint_colors = list(options['Paint_Color'].keys())\n",
    "            wheel_types = list(options['Wheel_Type'].keys())\n",
    "            interior_types = list(options['Interior_Type'].keys())\n",
    "            \n",
    "            combinations = list(product(variant_names, paint_colors, wheel_types, interior_types))\n",
    "            \n",
    "            for combo in combinations:\n",
    "                variant, paint, wheel, interior = combo\n",
    "                product_name = f\"{model} {variant} - {paint} - {wheel} - {interior}\"\n",
    "                all_products.append({\n",
    "                    'Product_Name': product_name,\n",
    "                    'Product_Category': category,\n",
    "                    'Product_Model': model,\n",
    "                    'Product_Variant': variant,\n",
    "                    'Paint_Color': paint,\n",
    "                    'Wheel_Type': wheel,\n",
    "                    'Interior_Type': interior\n",
    "                })\n",
    "\n",
    "    # Add non-automotive products, including the missing ones\n",
    "    non_automotive_products = [\n",
    "        ('Model 3 LR RWD Lease (24mo)', 'Automotive Leasing', 'Lease', np.nan, np.nan, np.nan),\n",
    "        ('Model 3 LR RWD Lease (36mo)', 'Automotive Leasing', 'Lease', np.nan, np.nan, np.nan),\n",
    "        ('Model Y LR RWD Lease (24mo)', 'Automotive Leasing', 'Lease', np.nan, np.nan, np.nan),\n",
    "        ('Model Y LR RWD Lease (36mo)', 'Automotive Leasing', 'Lease', np.nan, np.nan, np.nan),\n",
    "        ('Solar Panels', 'Energy Generation & Storage', 'Solar Panel', np.nan, np.nan, np.nan),\n",
    "        ('Solar Roof', 'Energy Generation & Storage', 'Solar Roof', np.nan, np.nan, np.nan),\n",
    "        ('Powerwall 3', 'Energy Generation & Storage', 'Powerwall', np.nan, np.nan, np.nan),\n",
    "        ('Megapack', 'Energy Generation & Storage', 'Megapack', np.nan, np.nan, np.nan),\n",
    "        ('FSD (Full Self-Driving)', 'Automotive', 'Feature', np.nan, np.nan, np.nan),\n",
    "        ('CyberCab (2026 Placeholder)', 'Automotive', 'Service', np.nan, np.nan, np.nan),\n",
    "        ('Regulatory Credits', 'Financial & Regulatory', 'Credit', np.nan, np.nan, np.nan),\n",
    "        ('Charging Equipment', 'Services & Other', 'Accessory', np.nan, np.nan, np.nan),\n",
    "        ('Vehicle Accessories', 'Services & Other', 'Accessory', np.nan, np.nan, np.nan),\n",
    "        ('Apparel', 'Services & Other', 'Apparel', np.nan, np.nan, np.nan),\n",
    "        ('Lifestyle', 'Services & Other', 'Lifestyle', np.nan, np.nan, np.nan),\n",
    "    ]\n",
    "\n",
    "    for prod_name, cat, variant, paint, wheel, interior in non_automotive_products:\n",
    "        all_products.append({\n",
    "            'Product_Name': prod_name,\n",
    "            'Product_Category': cat,\n",
    "            'Product_Model': 'N/A', # Use 'N/A' for non-automotive products\n",
    "            'Product_Variant': variant,\n",
    "            'Paint_Color': paint,\n",
    "            'Wheel_Type': wheel,\n",
    "            'Interior_Type': interior\n",
    "        })\n",
    "\n",
    "    # Sort products by their release date to ensure a logical ID sequence\n",
    "    all_products.sort(key=lambda x: release_dates.get(x['Product_Model'], date(2010, 1, 1)))\n",
    "\n",
    "    # Assign sequential Product_ID to the sorted list\n",
    "    for i, prod in enumerate(all_products):\n",
    "        prod['Product_ID'] = f'PRO{i+1:03d}'\n",
    "    \n",
    "    # Define columns with the price column removed\n",
    "    columns = [\n",
    "        'Product_ID', 'Product_Name', 'Product_Category', 'Product_Variant',\n",
    "        'Paint_Color', 'Wheel_Type', 'Interior_Type'\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(all_products, columns=columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Generating Dim_Product table...\")\n",
    "    dim_product_df = generate_dim_product()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(\"Saving Dim_Product.csv...\")\n",
    "    # 修改了这一行，确保 NA 值被正确写入 CSV 文件\n",
    "    dim_product_df.to_csv(os.path.join(output_dir, 'Dim_Product.csv'), index=False, encoding='utf-8', na_rep='NA')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Dim_Product.csv has been successfully generated with {len(dim_product_df)} rows in {end_time - start_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c53d0b-cce6-4926-9728-61833d0ef3b5",
   "metadata": {},
   "source": [
    "### **2/6: 生成 Dim_Time 表 (单一向前数据)维度表只追加Append。每一个时间点、每一天、每一个月都是一个既定的、永恒不变的事实。你无法“更新”昨天或去年的日期，此时就需要追加Append表中的相应记录。没有复杂的版本控制机制（Slowly Changing Dimension, SCD）** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f94191e-eb6b-4a29-9662-942dfbb397a9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Dim_Time table...\n",
      "Saving Dim_Time.csv...\n",
      "Dim_Time.csv has been successfully generated with 4,748 rows in 0.02 seconds.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"2/6: Generate Dim_Time Table\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "# Use a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def generate_dim_time():\n",
    "    \"\"\"Generates the Dim_Time table.\"\"\"\n",
    "    # 修改起始年份为 2013\n",
    "    start_date = datetime.date(2013, 1, 1)\n",
    "    end_date = datetime.date(2025, 12, 31)\n",
    "    date_range = [start_date + datetime.timedelta(days=x) for x in range(0, (end_date - start_date).days + 1)]\n",
    "\n",
    "    data = []\n",
    "    time_id_counter = 1\n",
    "    for date in date_range:\n",
    "        # Generate the new Time_ID format (T + 7 digits)\n",
    "        time_id = f'T{time_id_counter:07d}'\n",
    "        \n",
    "        data.append([\n",
    "            time_id,\n",
    "            date,\n",
    "            date.year,\n",
    "            f\"Q{((date.month - 1) // 3) + 1}\",\n",
    "            date.month,\n",
    "            date.day,\n",
    "            date.isocalendar()[1],\n",
    "            date.isoweekday(),\n",
    "            date.strftime('%A')\n",
    "        ])\n",
    "        time_id_counter += 1\n",
    "    \n",
    "    return pd.DataFrame(data, columns=['Time_ID', 'Full_Date', 'Year', 'Quarter', 'Month', 'Day', 'Week_of_Year', 'Day_of_Week', 'Day_Name'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Generating Dim_Time table...\")\n",
    "    dim_time_df = generate_dim_time()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(\"Saving Dim_Time.csv...\")\n",
    "    dim_time_df.to_csv(os.path.join(output_dir, 'Dim_Time.csv'), index=False, encoding='utf-8')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Dim_Time.csv has been successfully generated with {len(dim_time_df):,} rows in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eea8d8-16b1-4f9d-85d7-fabef3cea65b",
   "metadata": {},
   "source": [
    "### **3/6: 生成 Dim_Customer 表 （修改性别和年龄分布）(相对静态数据)维度表更可能需要更新Update或追加Append。例如，一个客户的收入水平或家庭住址可能会发生变化，此时就需要更新Update或追加Append表中的相应记录。这种变化管理被称为“缓慢变化维度”（Slowly Changing Dimension, SCD）** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43821275-ac37-4dff-b170-3a76c42b4ba5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Dim_Customer table...\n",
      "Saving Dim_Customer.csv...\n",
      "Dim_Customer.csv has been successfully generated with 50015 rows in 0.97 seconds.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"3/6: Generate Dim_Customer Table\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Use a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def generate_dim_customer(num_customers=50000):\n",
    "    \"\"\"Generates the Dim_Customer table.\"\"\"\n",
    "    \n",
    "    # 调整性别分布，偏向男性\n",
    "    genders = ['Male', 'Female']\n",
    "    gender_probs = [0.75, 0.25] # Male: 75%, Female: 25%\n",
    "\n",
    "    # 调整年龄组分布，偏向中年群体\n",
    "    age_groups = ['<25', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "    age_probs = [0.05, 0.20, 0.35, 0.25, 0.10, 0.05]\n",
    "    \n",
    "    # 调整收入水平分布，偏向中高收入\n",
    "    income_levels = ['Low', 'Medium', 'High']\n",
    "    income_probs = [0.10, 0.80, 0.10]\n",
    "    \n",
    "    first_names = ['James', 'Mary', 'John', 'Patricia', 'Robert', 'Jennifer', 'Michael', 'Linda', 'William', 'Elizabeth', 'David', 'Susan', 'Richard', 'Jessica', 'Joseph', 'Sarah', 'Thomas', 'Karen', 'Charles', 'Nancy', 'Christopher', 'Lisa', 'Daniel', 'Betty', 'Paul', 'Margaret', 'Mark', 'Sandra', 'Donald', 'Ashley', 'George', 'Kimberly', 'Kenneth', 'Donna', 'Steven', 'Emily', 'Edward', 'Carol', 'Brian', 'Michelle', 'Ronald', 'Amanda', 'Anthony', 'Melissa', 'Kevin', 'Deborah', 'Jason', 'Stephanie', 'Jeff', 'Maria', 'Gary', 'Heather', 'Timothy', 'Nicole', 'Jose', 'Denise', 'Larry', 'Megan', 'Jeffrey', 'Christina', 'Frank', 'Alexis', 'Scott', 'Tiffany', 'Eric', 'Lauren', 'Stephen', 'Rachel', 'Andrew', 'Crystal', 'Raymond', 'Kayla', 'Ryan', 'Danielle', 'Jacob', 'Brittany', 'Nicholas', 'Emma', 'Jonathan', 'Samantha', 'Laura', 'Alexis', 'Joshua', 'Brandon', 'Justin', 'Daniel', 'Daniel', 'Taylor']\n",
    "    last_names = ['Smith', 'Johnson', 'Williams', 'Jones', 'Brown', 'Davis', 'Miller', 'Wilson', 'Moore', 'Taylor', 'Anderson', 'Thomas', 'Jackson', 'White', 'Harris', 'Martin', 'Thompson', 'Garcia', 'Martinez', 'Robinson', 'Clark', 'Rodriguez', 'Lewis', 'Lee', 'Walker', 'Hall', 'Allen', 'Young', 'Hernandez', 'King', 'Wright', 'Lopez', 'Hill', 'Scott', 'Green', 'Adams', 'Baker', 'Gonzalez', 'Nelson', 'Carter', 'Mitchell', 'Perez', 'Roberts', 'Turner', 'Phillips', 'Campbell', 'Parker', 'Evans', 'Edwards', 'Collins', 'Stewart', 'Sanchez', 'Morris', 'Rogers', 'Reed', 'Cook', 'Morgan', 'Bell', 'Murphy', 'Bailey', 'Rivera', 'Cooper', 'Richardson', 'Cox', 'Howard', 'Ward', 'Torres', 'Peterson', 'Gray', 'Ramirez', 'James', 'Watson', 'Brooks', 'Kelly', 'Sanders', 'Price', 'Bennett', 'Wood', 'Barnes', 'Ross', 'Henderson', 'Coleman', 'Jenkins', 'Perry', 'Powell', 'Long', 'Patterson', 'Hughes', 'Flores', 'Washington', 'Butler', 'Simmons', 'Foster', 'Gonzales', 'Bryant', 'Alexander', 'Russell', 'Griffin', 'Diaz', 'Hayes', 'Myers', 'Ford', 'Hamilton', 'Graham', 'Sullivan', 'Wallace', 'Woods', 'Cole', 'West', 'Jordan', 'Owens', 'Reynolds', 'Fisher', 'Ellis', 'Harrison', 'Gibson', 'Mcdonald', 'Cruz', 'Marshall', 'Ortiz', 'Gomez', 'Murray', 'Freeman', 'Wells', 'Webb', 'Simpson', 'Stevens', 'Tucker', 'Porter', 'Hunter', 'Hicks', 'Crawford', 'Henry', 'Boyd', 'Mason', 'Kennedy', 'Warren', 'Dixon', 'Ramos', 'Reid', 'Carr', 'Chavez', 'Gibson']\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # 跟踪每个组合的序号，确保不重复\n",
    "    combination_tracker = {}\n",
    "    \n",
    "    # 随机生成个人客户数据\n",
    "    for _ in range(num_customers):\n",
    "        full_name = f\"{random.choice(first_names)} {random.choice(last_names)}\"\n",
    "        \n",
    "        # 使用 np.random.choice 并指定概率\n",
    "        gender_raw = np.random.choice(genders, p=gender_probs)\n",
    "        age_group = np.random.choice(age_groups, p=age_probs)\n",
    "        income_level = np.random.choice(income_levels, p=income_probs)\n",
    "        \n",
    "        # 随机生成两个字母的国家和省/州代码\n",
    "        country_code = ''.join(random.choices(string.ascii_uppercase, k=2))\n",
    "        state_code = ''.join(random.choices(string.ascii_uppercase, k=2))\n",
    "        \n",
    "        # 编码 Customer_ID\n",
    "        gender_code = 'M' if gender_raw == 'Male' else 'W'\n",
    "        \n",
    "        # 构建组合前缀\n",
    "        prefix = f'C{gender_code}{country_code}{state_code}'\n",
    "        \n",
    "        # 获取并递增序号\n",
    "        if prefix not in combination_tracker:\n",
    "            combination_tracker[prefix] = 0\n",
    "        else:\n",
    "            combination_tracker[prefix] += 1\n",
    "            \n",
    "        # 序号部分为四位数字，从0000开始\n",
    "        sequential_id = f\"{combination_tracker[prefix] % 10000:04d}\"\n",
    "        \n",
    "        customer_id = f'{prefix}{sequential_id}'\n",
    "\n",
    "        data.append([customer_id, full_name, 'Individual', gender_raw, age_group, income_level, 'NA', 'NA', 'NA'])\n",
    "\n",
    "    individual_df = pd.DataFrame(data, columns=['Customer_ID', 'Customer_Name', 'Customer_Segment', 'Gender', 'Age_Group', 'Income_Level', 'Country', 'State_Province', 'City'])\n",
    "\n",
    "    # 新增业务客户数据，用于购买监管积分\n",
    "    business_customers = [\n",
    "        ['B001', 'General Motors', 'Business', 'NA', 'NA', 'NA', 'United States', 'Michigan', 'Detroit'],\n",
    "        ['B002', 'Ford Motor Company', 'Business', 'NA', 'NA', 'NA', 'United States', 'Michigan', 'Dearborn'],\n",
    "        ['B003', 'Toyota', 'Business', 'NA', 'NA', 'NA', 'Japan', 'Aichi', 'Toyota'],\n",
    "        ['B004', 'Volkswagen', 'Business', 'NA', 'NA', 'NA', 'Germany', 'Lower Saxony', 'Wolfsburg'],\n",
    "        ['B005', 'Stellantis', 'Business', 'NA', 'NA', 'NA', 'Netherlands', 'North Holland', 'Amsterdam'],\n",
    "        ['B006', 'Honda', 'Business', 'NA', 'NA', 'NA', 'Japan', 'Tokyo', 'Tokyo'],\n",
    "        ['B007', 'Nissan', 'Business', 'NA', 'NA', 'NA', 'Japan', 'Kanagawa', 'Yokohama'],\n",
    "        ['B008', 'Delta Air Lines', 'Business', 'NA', 'NA', 'NA', 'United States', 'Georgia', 'Atlanta'],\n",
    "        ['B009', 'United Airlines', 'Business', 'NA', 'NA', 'NA', 'United States', 'Illinois', 'Chicago'],\n",
    "        ['B010', 'American Airlines', 'Business', 'NA', 'NA', 'NA', 'United States', 'Texas', 'Fort Worth'],\n",
    "        ['B011', 'Shell', 'Business', 'NA', 'NA', 'NA', 'Netherlands', 'South Holland', 'The Hague'],\n",
    "        ['B012', 'ExxonMobil', 'Business', 'NA', 'NA', 'NA', 'United States', 'Texas', 'Irving'],\n",
    "        ['B013', 'BP', 'Business', 'NA', 'NA', 'NA', 'United Kingdom', 'Greater London', 'London'],\n",
    "        ['B014', 'Chevron', 'Business', 'NA', 'NA', 'NA', 'United States', 'California', 'San Ramon'],\n",
    "        ['B015', 'TotalEnergies', 'Business', 'NA', 'NA', 'NA', 'France', 'Île-de-France', 'Courbevoie'],\n",
    "    ]\n",
    "    \n",
    "    business_df = pd.DataFrame(business_customers, columns=['Customer_ID', 'Customer_Name', 'Customer_Segment', 'Gender', 'Age_Group', 'Income_Level', 'Country', 'State_Province', 'City'])\n",
    "\n",
    "    # 合并个人和业务客户数据\n",
    "    final_df = pd.concat([individual_df, business_df], ignore_index=True)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Generating Dim_Customer table...\")\n",
    "    dim_customer_df = generate_dim_customer()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(\"Saving Dim_Customer.csv...\")\n",
    "    dim_customer_df.to_csv(os.path.join(output_dir, 'Dim_Customer.csv'), index=False, encoding='utf-8')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Dim_Customer.csv has been successfully generated with {len(dim_customer_df)} rows in {end_time - start_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b9de72-6e92-4530-b9db-9157d15e5e35",
   "metadata": {},
   "source": [
    "### **4/6: 生成 Dim_Geography 表 （按大洲、国家编号）(相对静态数据)维度表更可能需要更新Update或追加Append。例如，一个客户的地址可能会发生变化或更新到新的国家和城市，此时就需要更新Update或追加Append表中的相应记录。这种变化管理被称为“缓慢变化维度”（Slowly Changing Dimension, SCD）** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20731257-2d69-448d-a07a-84c6e7fc2ee0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Dim_Geography table...\n",
      "Saving Dim_Geography.csv...\n",
      "Dim_Geography.csv has been successfully generated with 432 rows in 0.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"4/6: Generate Dim_Geography Table\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Use a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def generate_plausible_zip(country):\n",
    "    \"\"\"Generates a plausible zip code based on the country, padded to 8 characters.\"\"\"\n",
    "    letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    digits = '0123456789'\n",
    "    \n",
    "    # 辅助函数，用于填充到8位\n",
    "    def pad_to_eight(s):\n",
    "        return (s + '0' * 8)[:8]\n",
    "\n",
    "    if country == 'United States':\n",
    "        return pad_to_eight(f\"{random.randint(10000, 99999)}\")\n",
    "    elif country == 'Canada':\n",
    "        # A1A 1A1 format (6 characters + 1 space)\n",
    "        code = f\"{random.choice(letters)}{random.choice(digits)}{random.choice(letters)} {random.choice(digits)}{random.choice(letters)}{random.choice(digits)}\"\n",
    "        return pad_to_eight(code.replace(' ', '')) # Remove space for 8-char ID, or keep for Zip_Code column\n",
    "    elif country == 'Mexico':\n",
    "        return pad_to_eight(f\"{random.randint(10000, 99999)}\")\n",
    "    elif country == 'United Kingdom':\n",
    "        # AN NAA or ANN NAA format\n",
    "        part1_letters = ''.join(random.choices(letters, k=random.choice([1, 2])))\n",
    "        part1_digits = ''.join(random.choices(digits, k=random.choice([1, 2])))\n",
    "        part2 = f\"{random.choice(digits)}{random.choice(letters)}{random.choice(letters)}\"\n",
    "        code = f\"{part1_letters}{part1_digits} {part2}\"\n",
    "        return pad_to_eight(code.replace(' ', ''))\n",
    "    elif country == 'France':\n",
    "        # 5 digits, but first is not zero\n",
    "        return pad_to_eight(f\"{random.randint(10000, 99999)}\")\n",
    "    elif country in ['Germany', 'Italy', 'Spain', 'Switzerland', 'Netherlands', 'Denmark', 'Norway', 'Sweden', 'Finland', 'Greece', 'Iceland', 'Ireland', 'Luxembourg', 'Monaco']:\n",
    "        # Most of Europe uses 5-digit numbers\n",
    "        return pad_to_eight(f\"{random.randint(10000, 99999)}\")\n",
    "    elif country == 'China':\n",
    "        # 6-digit numeric\n",
    "        return pad_to_eight(f\"{random.randint(100000, 999999)}\")\n",
    "    elif country == 'Japan':\n",
    "        # 7-digit numeric, often with a hyphen, so we generate and pad\n",
    "        return pad_to_eight(f\"{random.randint(1000000, 9999999)}\")\n",
    "    elif country in ['South Korea', 'Taiwan', 'Hong Kong', 'Macau']:\n",
    "        # 5-7 digit numeric\n",
    "        return pad_to_eight(f\"{random.randint(10000, 9999999)}\")\n",
    "    elif country == 'Australia':\n",
    "        # 4-digit numeric\n",
    "        return pad_to_eight(f\"{random.randint(1000, 9999)}\")\n",
    "    elif country == 'New Zealand':\n",
    "        # 4-digit numeric\n",
    "        return pad_to_eight(f\"{random.randint(1000, 9999)}\")\n",
    "    else:\n",
    "        return \"00000000\"\n",
    "\n",
    "def generate_dim_geography():\n",
    "    \"\"\"\n",
    "    Generates a Dim_Geography table.\n",
    "    \"\"\"\n",
    "    geography_data = []\n",
    "    \n",
    "    # Continent codes for the new Geo_ID\n",
    "    continent_codes = {\n",
    "        'North America': 'NA',\n",
    "        'Europe': 'EU',\n",
    "        'Asia': 'AS',\n",
    "        'Oceania': 'OC'\n",
    "    }\n",
    "    \n",
    "    # North America\n",
    "    north_america_countries = {\n",
    "        'United States': {\n",
    "            'code': 'US',\n",
    "            'provinces': [\n",
    "                'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut',\n",
    "                'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa',\n",
    "                'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan',\n",
    "                'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire',\n",
    "                'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio',\n",
    "                'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota',\n",
    "                'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia',\n",
    "                'Wisconsin', 'Wyoming'\n",
    "            ]\n",
    "        },\n",
    "        'Canada': {\n",
    "            'code': 'CA',\n",
    "            'provinces': [\n",
    "                'Alberta', 'British Columbia', 'Manitoba', 'New Brunswick', 'Newfoundland and Labrador',\n",
    "                'Nova Scotia', 'Ontario', 'Prince Edward Island', 'Québec', 'Saskatchewan',\n",
    "                'Northwest Territories', 'Nunavut', 'Yukon'\n",
    "            ]\n",
    "        },\n",
    "        'Mexico': {\n",
    "            'code': 'MX',\n",
    "            'provinces': [\n",
    "                'Aguascalientes', 'Baja California', 'Baja California Sur', 'Campeche', 'Chiapas',\n",
    "                'Chihuahua', 'Coahuila', 'Colima', 'Durango', 'Guanajuato', 'Guerrero', 'Hidalgo',\n",
    "                'Jalisco', 'México', 'Distrito Federal', 'Michoacán', 'Morelos', 'Nayarit',\n",
    "                'Nuevo León', 'Oaxaca', 'Puebla', 'Querétaro', 'Quintana Roo', 'San Luis Potosí',\n",
    "                'Sinaloa', 'Sonora', 'Tabasco', 'Tamaulipas', 'Tlaxcala', 'Veracruz', 'Yucatán', 'Zacatecas'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Europe\n",
    "    europe_countries = {\n",
    "        'Germany': {\n",
    "            'code': 'DE',\n",
    "            'provinces': [\n",
    "                'Baden-Württemberg', 'Bavaria', 'Berlin', 'Brandenburg', 'Bremen', 'Hamburg',\n",
    "                'Hesse', 'Lower Saxony', 'Mecklenburg-Vorpommern', 'North Rhine-Westphalia',\n",
    "                'Rhineland-Palatinate', 'Saarland', 'Saxony', 'Saxony-Anhalt',\n",
    "                'Schleswig-Holstein', 'Thuringia'\n",
    "            ]\n",
    "        },\n",
    "        'United Kingdom': {\n",
    "            'code': 'GB',\n",
    "            'provinces': [\n",
    "                'England', 'Scotland', 'Wales', 'Northern Ireland'\n",
    "            ]\n",
    "        },\n",
    "        'Norway': {'code': 'NO', 'provinces': ['Oslo', 'Viken', 'Innlandet', 'Vestfold og Telemark', 'Agder', 'Rogaland', 'Vestland', 'Møre og Romsdal', 'Trøndelag', 'Nordland', 'Troms og Finnmark']},\n",
    "        'France': {'code': 'FR', 'provinces': ['Bretagne', 'Normandie', 'Île-de-France', 'Auvergne-Rhône-Alpes', 'Bourgogne-Franche-Comté', 'Centre-Val de Loire', 'Corsica', 'Grand Est', 'Hauts-de-France', 'Nouvelle-Aquitaine', 'Occitanie', 'Pays de la Loire', 'Provence-Alpes-Côte d\\'Azur']},\n",
    "        'Netherlands': {'code': 'NL', 'provinces': ['Drenthe', 'Flevoland', 'Friesland', 'Gelderland', 'Groningen', 'Limburg', 'North Brabant', 'North Holland', 'Overijssel', 'Utrecht', 'Zeeland', 'South Holland']},\n",
    "        'Sweden': {'code': 'SE', 'provinces': ['Blekinge', 'Dalarna', 'Gotland', 'Gävleborg', 'Halland', 'Jämtland', 'Jönköping', 'Kalmar', 'Kronoberg', 'Norrbotten', 'Skåne', 'Stockholm', 'Södermanland', 'Uppsala', 'Värmland', 'Västerbotten', 'Västernorrland', 'Västmanland', 'Västra Götaland', 'Örebro', 'Östergötland']},\n",
    "        'Switzerland': {'code': 'CH', 'provinces': ['Zurich', 'Bern', 'Lucerne', 'Uri', 'Schwyz', 'Obwalden', 'Nidwalden', 'Glarus', 'Zug', 'Fribourg', 'Solothurn', 'Basel-Stadt', 'Basel-Landschaft', 'Schaffhausen', 'Appenzell Ausserrhoden', 'Appenzell Innerrhoden', 'St. Gallen', 'Graubünden', 'Aargau', 'Thurgau', 'Ticino', 'Vaud', 'Valais', 'Neuchâtel', 'Geneva', 'Jura']},\n",
    "        'Italy': {'code': 'IT', 'provinces': ['Abruzzo', 'Aosta Valley', 'Apulia', 'Basilicata', 'Calabria', 'Campania', 'Emilia-Romagna', 'Friuli-Venezia Giulia', 'Lazio', 'Liguria', 'Lombardy', 'Marche', 'Molise', 'Piedmont', 'Sardinia', 'Sicily', 'Tuscany', 'Trentino-Alto Adige', 'Umbria', 'Veneto']},\n",
    "        'Spain': {'code': 'ES', 'provinces': ['Andalusia', 'Aragon', 'Principality of Asturias', 'Balearic Islands', 'Basque Country', 'Canary Islands', 'Cantabria', 'Castile and León', 'Castile-La Mancha', 'Catalonia', 'Community of Madrid', 'Valencian Community', 'Extremadura', 'Galicia', 'La Rioja', 'Region of Murcia', 'Foral Community of Navarre']},\n",
    "        'Denmark': {'code': 'DK', 'provinces': ['Capital Region of Denmark', 'Central Denmark Region', 'North Denmark Region', 'Region Zealand', 'Region of Southern Denmark']},\n",
    "        'Finland': {'code': 'FI', 'provinces': ['Åland Islands', 'Central Finland', 'Central Ostrobothnia', 'Kainuu', 'Kymenlaakso', 'Lapland', 'North Karelia', 'North Ostrobothnia', 'Northern Savonia', 'Päijät-Häme', 'Pirkanmaa', 'Satakunta', 'South Karelia', 'Southern Ostrobothnia', 'Southern Savonia', 'Tavastia Proper', 'Uusimaa', 'Southwest Finland']},\n",
    "        'Greece': {'code': 'GR', 'provinces': ['Attica', 'Central Greece', 'Central Macedonia', 'Crete', 'East Macedonia and Thrace', 'Epirus', 'Ionian Islands', 'North Aegean', 'Peloponnese', 'South Aegean', 'Thessaly', 'West Greece', 'West Macedonia']},\n",
    "        'Iceland': {'code': 'IS', 'provinces': ['Capital Region', 'Southern Peninsula', 'Western Region', 'Westfjords', 'Northwest Region', 'Northeast Region', 'Eastern Region', 'Southern Region']},\n",
    "        'Ireland': {'code': 'IE', 'provinces': ['Connacht', 'Leinster', 'Munster', 'Ulster']},\n",
    "        'Luxembourg': {'code': 'LU', 'provinces': ['Diekirch', 'Grevenmacher', 'Luxembourg']},\n",
    "        'Monaco': {'code': 'MC', 'provinces': ['Monaco']}\n",
    "    }\n",
    "    \n",
    "    # Asia\n",
    "    asia_countries = {\n",
    "        'China': {\n",
    "            'code': 'CN',\n",
    "            'provinces': [\n",
    "                'Anhui', 'Fujian', 'Gansu', 'Guangdong', 'Guizhou', 'Hainan', 'Hebei', 'Heilongjiang',\n",
    "                'Henan', 'Hubei', 'Hunan', 'Jiangsu', 'Jiangxi', 'Jilin', 'Liaoning', 'Qinghai',\n",
    "                'Shaanxi', 'Shandong', 'Shanxi', 'Sichuan', 'Yunnan', 'Zhejiang',\n",
    "                'Guangxi', 'Nei Mongol', 'Ningxia Hui', 'Xinjiang Uygur', 'Xizang',\n",
    "                'Beijing', 'Chongqing', 'Shanghai', 'Tianjin'\n",
    "            ]\n",
    "        },\n",
    "        'Hong Kong': {'code': 'HK', 'provinces': ['Hong Kong Island', 'Kowloon', 'New Territories']},\n",
    "        'Macau': {'code': 'MO', 'provinces': ['Macau']},\n",
    "        'Japan': {\n",
    "            'code': 'JP',\n",
    "            'provinces': [\n",
    "                'Hokkaido', 'Aomori', 'Iwate', 'Miyagi', 'Akita', 'Yamagata', 'Fukushima',\n",
    "                'Ibaraki', 'Tochigi', 'Gunma', 'Saitama', 'Chiba', 'Tokyo', 'Kanagawa',\n",
    "                'Niigata', 'Toyama', 'Ishikawa', 'Fukui', 'Yamanashi', 'Nagano',\n",
    "                'Gifu', 'Shizuoka', 'Aichi', 'Mie', 'Shiga', 'Kyoto', 'Osaka',\n",
    "                'Hyōgo', 'Nara', 'Wakayama', 'Tottori', 'Shimane', 'Okayama',\n",
    "                'Hiroshima', 'Yamaguchi', 'Tokushima', 'Kagawa', 'Ehime', 'Kochi',\n",
    "                'Fukuoka', 'Saga', 'Naoasaki', 'Kumamoto', 'Oita', 'Miyazaki', 'Kagoshima', 'Okinawa'\n",
    "            ]\n",
    "        },\n",
    "        'South Korea': {\n",
    "            'code': 'KR',\n",
    "            'provinces': [\n",
    "                'Busan', 'Chungcheongbuk-do', 'Chungcheongnam-do', 'Daegu', 'Daejeon', 'Gangwon-do',\n",
    "                'Gwangju', 'Gyeonggi-do', 'Gyeongsangbuk-do', 'Gyeongsangnam-do', 'Incheon', 'Jeollabuk-do',\n",
    "                'Jeollanam-do', 'Sejong', 'Seoul', 'Ulsan', 'Jeju'\n",
    "            ]\n",
    "        },\n",
    "        'Taiwan': {\n",
    "            'code': 'TW',\n",
    "            'provinces': [\n",
    "                'Taipei', 'New Taipei', 'Taichung', 'Tainan', 'Kaohsiung', 'Taoyuan',\n",
    "                'Keelung', 'Hsinchu City', 'Chiayi City', 'Hsinchu County', 'Chiayi County',\n",
    "                'Changhua', 'Nantou', 'Yulin', 'Miaoli', 'Pingtung', 'Yilan', 'Hualien',\n",
    "                'Taitung', 'Penghu', 'Kinmen', 'Lienkiang'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Oceania\n",
    "    oceania_countries = {\n",
    "        'Australia': {\n",
    "            'code': 'AU',\n",
    "            'provinces': [\n",
    "                'New South Wales', 'Victoria', 'Queensland', 'South Australia', 'Western Australia',\n",
    "                'Tasmania', 'Australian Capital Territory', 'Northern Territory'\n",
    "            ]\n",
    "        },\n",
    "        'New Zealand': {\n",
    "            'code': 'NZ',\n",
    "            'provinces': [\n",
    "                'Auckland', 'Bay of Plenty', 'Canterbury', 'Gisborne', 'Hawke\\'s Bay',\n",
    "                'Manawatu-Wanganui', 'Marlborough', 'Nelson', 'Northland', 'Otago',\n",
    "                'Southland', 'Taranaki', 'Tasman', 'Waikato', 'Wellington', 'West Coast'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    continents = {\n",
    "        'North America': north_america_countries,\n",
    "        'Europe': europe_countries,\n",
    "        'Asia': asia_countries,\n",
    "        'Oceania': oceania_countries\n",
    "    }\n",
    "\n",
    "    for continent, countries in continents.items():\n",
    "        for country, details in countries.items():\n",
    "            state_id = 1\n",
    "            for province in details['provinces']:\n",
    "                # The state abbreviation logic needs to be robust for all cases.\n",
    "                state_abbr_words = province.split(' ')\n",
    "                state_abbr_raw = ''.join([word[0].upper() for word in state_abbr_words if word[0].isalpha()]).ljust(2, 'X')\n",
    "                \n",
    "                # Create a reliable 2-letter abbreviation\n",
    "                state_abbr = state_abbr_raw[:2]\n",
    "\n",
    "                # Create the new 8-character Geo_ID\n",
    "                geo_id = f\"{continent_codes[continent]}{details['code']}{state_abbr}{state_id:02d}\"\n",
    "\n",
    "                geography_data.append([\n",
    "                    geo_id,\n",
    "                    continent,\n",
    "                    country,\n",
    "                    details['code'],\n",
    "                    province,\n",
    "                    state_abbr,\n",
    "                    generate_plausible_zip(country)\n",
    "                ])\n",
    "                state_id += 1\n",
    "\n",
    "    dim_geography_df = pd.DataFrame(geography_data, columns=[\n",
    "        'Geo_ID', 'Continent', 'Country', 'Country_Code', 'State_Province', 'State_Province_Abbr', 'Zip_Code'\n",
    "    ])\n",
    "    \n",
    "    return dim_geography_df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Generating Dim_Geography table...\")\n",
    "    dim_geography_df = generate_dim_geography()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(\"Saving Dim_Geography.csv...\")\n",
    "    dim_geography_df.to_csv(os.path.join(output_dir, 'Dim_Geography.csv'), index=False, encoding='utf-8')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Dim_Geography.csv has been successfully generated with {len(dim_geography_df)} rows in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5e4897-3e37-49ec-916d-e38386464c31",
   "metadata": {},
   "source": [
    "### **5/6: 生成 Dim_Prices 表 (相对静态数据)维度表更可能需要更新Update或追加Append。例如，新产品或不同时段价格可能会发生变化，此时就需要更新或追加Append表中的相应记录。这种变化管理被称为“缓慢变化维度”（Slowly Changing Dimension, SCD）** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e3387e8-e364-4367-a5f7-45052df60898",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在生成 Dim_Prices 表...\n",
      "保存 Dim_Prices.csv...\n",
      "Dim_Prices.csv 已成功生成！\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Generate Dim_Prices Table\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Use a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def generate_dim_prices():\n",
    "    \"\"\"\n",
    "    Generates the Dim_Prices table with prices for different vehicle models and time periods.\n",
    "    \"\"\"\n",
    "    start_date = datetime(2013, 1, 1)\n",
    "    end_date = datetime(2025, 6, 30)\n",
    "\n",
    "    price_data = []\n",
    "\n",
    "    # 定义不同车型的基础价格\n",
    "    # 价格基于公开数据和市场趋势估算\n",
    "    base_prices = {\n",
    "        1: 75000,  # Model S\n",
    "        2: 80000,  # Model X\n",
    "        3: 40000,  # Model 3\n",
    "        4: 50000,  # Model Y\n",
    "        5: 120000, # Cybertruck\n",
    "    }\n",
    "    \n",
    "    # 定义产品ID的映射，使其与产品维度表格式一致\n",
    "    product_id_mapping = {\n",
    "        1: 'PRO001',\n",
    "        2: 'PRO002',\n",
    "        3: 'PRO003',\n",
    "        4: 'PRO004',\n",
    "        5: 'PRO005',\n",
    "    }\n",
    "\n",
    "    # 手动添加 2013-2018 年的价格数据以确保销售数据生成准确\n",
    "    # Model S (Product_ID = 1)\n",
    "    price_data.append({'Quarter_Start_Date': datetime(2013, 1, 1), 'Product_ID': product_id_mapping[1], 'Standard_Price_USD': 75000, 'Discounted_Price_USD': 75000})\n",
    "    price_data.append({'Quarter_Start_Date': datetime(2013, 4, 1), 'Product_ID': product_id_mapping[1], 'Standard_Price_USD': 75000, 'Discounted_Price_USD': 75000})\n",
    "    price_data.append({'Quarter_Start_Date': datetime(2013, 7, 1), 'Product_ID': product_id_mapping[1], 'Standard_Price_USD': 75000, 'Discounted_Price_USD': 75000})\n",
    "    price_data.append({'Quarter_Start_Date': datetime(2013, 10, 1), 'Product_ID': product_id_mapping[1], 'Standard_Price_USD': 75000, 'Discounted_Price_USD': 75000})\n",
    "\n",
    "    # Model X (Product_ID = 2) 在2015年末发布\n",
    "    # Model 3 (Product_ID = 3) 在2017年中发布\n",
    "    # Model Y (Product_ID = 4) 在2020年初发布\n",
    "    # Cybertruck (Product_ID = 5) 在2023年末发布\n",
    "    \n",
    "    # 填充 2014-2018 年的价格\n",
    "    for year in range(2014, 2019):\n",
    "        for month in [1, 4, 7, 10]:\n",
    "            quarter_start = datetime(year, month, 1)\n",
    "            # Model S 价格小幅波动\n",
    "            price_s = base_prices[1] + np.random.randint(-2000, 2000)\n",
    "            price_data.append({'Quarter_Start_Date': quarter_start, 'Product_ID': product_id_mapping[1], 'Standard_Price_USD': price_s, 'Discounted_Price_USD': price_s})\n",
    "\n",
    "            # Model X\n",
    "            if year >= 2015 and quarter_start >= datetime(2015, 9, 1):\n",
    "                price_x = base_prices[2] + np.random.randint(-2000, 2000)\n",
    "                price_data.append({'Quarter_Start_Date': quarter_start, 'Product_ID': product_id_mapping[2], 'Standard_Price_USD': price_x, 'Discounted_Price_USD': price_x})\n",
    "\n",
    "            # Model 3\n",
    "            if year >= 2017 and quarter_start >= datetime(2017, 7, 1):\n",
    "                price_3 = base_prices[3] + np.random.randint(-1000, 1000)\n",
    "                price_data.append({'Quarter_Start_Date': quarter_start, 'Product_ID': product_id_mapping[3], 'Standard_Price_USD': price_3, 'Discounted_Price_USD': price_3})\n",
    "\n",
    "    # 填充 2019 年至今的价格，并引入价格波动和折扣\n",
    "    current_date = datetime(2019, 1, 1)\n",
    "    while current_date <= end_date:\n",
    "        for product_id, base_price in base_prices.items():\n",
    "            if (product_id == 4 and current_date < datetime(2020, 1, 1)) or \\\n",
    "               (product_id == 5 and current_date < datetime(2023, 11, 1)):\n",
    "                continue\n",
    "\n",
    "            # 模拟价格波动（5%以内的随机波动）\n",
    "            price_std = base_price * (1 + random.uniform(-0.05, 0.05))\n",
    "            price_dis = price_std\n",
    "\n",
    "            # 模拟折扣（约20%的记录有折扣）\n",
    "            if random.random() < 0.20:\n",
    "                discount_rate = random.uniform(0.01, 0.15)\n",
    "                price_dis = price_std * (1 - discount_rate)\n",
    "            \n",
    "            price_data.append({\n",
    "                'Quarter_Start_Date': current_date,\n",
    "                'Product_ID': product_id_mapping[product_id],\n",
    "                'Standard_Price_USD': round(price_std, 2),\n",
    "                'Discounted_Price_USD': round(price_dis, 2)\n",
    "            })\n",
    "\n",
    "        # 移动到下一个季度\n",
    "        if current_date.month == 10:\n",
    "            current_date = current_date.replace(year=current_date.year + 1, month=1)\n",
    "        else:\n",
    "            current_date = current_date.replace(month=current_date.month + 3)\n",
    "\n",
    "    dim_prices_df = pd.DataFrame(price_data)\n",
    "\n",
    "    # 格式化日期列\n",
    "    dim_prices_df['Quarter_Start_Date'] = pd.to_datetime(dim_prices_df['Quarter_Start_Date']).dt.date\n",
    "\n",
    "    # 生成 Price_ID，格式为 PRI###\n",
    "    price_ids = [f'PRI{i:03d}' for i in range(1, len(dim_prices_df) + 1)]\n",
    "    dim_prices_df['Price_ID'] = price_ids\n",
    "    \n",
    "    # 重新排序列以匹配您的要求\n",
    "    dim_prices_df = dim_prices_df[['Price_ID', 'Product_ID', 'Quarter_Start_Date', 'Standard_Price_USD', 'Discounted_Price_USD']]\n",
    "    \n",
    "    return dim_prices_df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"正在生成 Dim_Prices 表...\")\n",
    "    dim_prices_df = generate_dim_prices()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    print(\"保存 Dim_Prices.csv...\")\n",
    "    dim_prices_df.to_csv(os.path.join(output_dir, 'Dim_Prices.csv'), index=False, encoding='utf-8')\n",
    "    print(\"Dim_Prices.csv 已成功生成！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b18d6ee-49f0-4cf2-8fef-d2b9bb9f345f",
   "metadata": {},
   "source": [
    "### **6/6: 生成 Fact_Sales 表 （没有空白营收行 追加到2013）(高度动态数据，最常被追加（append）的表) 只进不出”的设计哲学。每当一笔新的销售发生，就在 Fact_Sales 表中追加一行新的数据，而不会去修改之前已经存在的历史销售记录** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "465a0f68-6f1f-4435-93e7-17243ecf80e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载所有维度表...\n",
      "已移除旧的 Fact_Sales.csv 文件。\n",
      "正在生成 Fact_Sales 表...\n",
      "正在为年份 2013 第 1 季度生成 4,750 条销售记录...\n",
      "正在为年份 2013 第 2 季度生成 5,150 条销售记录...\n",
      "正在为年份 2013 第 3 季度生成 5,800 条销售记录...\n",
      "正在为年份 2013 第 4 季度生成 6,742 条销售记录...\n",
      "正在为年份 2014 第 1 季度生成 6,450 条销售记录...\n",
      "正在为年份 2014 第 2 季度生成 7,570 条销售记录...\n",
      "正在为年份 2014 第 3 季度生成 8,800 条销售记录...\n",
      "正在为年份 2014 第 4 季度生成 8,835 条销售记录...\n",
      "正在为年份 2015 第 1 季度生成 10,045 条销售记录...\n",
      "正在为年份 2015 第 2 季度生成 11,532 条销售记录...\n",
      "正在为年份 2015 第 3 季度生成 11,584 条销售记录...\n",
      "正在为年份 2015 第 4 季度生成 17,356 条销售记录...\n",
      "正在为年份 2016 第 1 季度生成 14,810 条销售记录...\n",
      "正在为年份 2016 第 2 季度生成 18,345 条销售记录...\n",
      "正在为年份 2016 第 3 季度生成 24,500 条销售记录...\n",
      "正在为年份 2016 第 4 季度生成 18,588 条销售记录...\n",
      "正在为年份 2017 第 1 季度生成 25,418 条销售记录...\n",
      "正在为年份 2017 第 2 季度生成 22,000 条销售记录...\n",
      "正在为年份 2017 第 3 季度生成 26,135 条销售记录...\n",
      "正在为年份 2017 第 4 季度生成 29,538 条销售记录...\n",
      "正在为年份 2018 第 1 季度生成 29,980 条销售记录...\n",
      "正在为年份 2018 第 2 季度生成 40,740 条销售记录...\n",
      "正在为年份 2018 第 3 季度生成 83,780 条销售记录...\n",
      "正在为年份 2018 第 4 季度生成 90,991 条销售记录...\n",
      "正在为年份 2019 第 1 季度生成 67,927 条销售记录...\n",
      "正在为年份 2019 第 2 季度生成 94,988 条销售记录...\n",
      "正在为年份 2019 第 3 季度生成 94,284 条销售记录...\n",
      "正在为年份 2019 第 4 季度生成 110,455 条销售记录...\n",
      "正在为年份 2020 第 1 季度生成 94,803 条销售记录...\n",
      "正在为年份 2020 第 2 季度生成 95,611 条销售记录...\n",
      "正在为年份 2020 第 3 季度生成 138,933 条销售记录...\n",
      "正在为年份 2020 第 4 季度生成 170,186 条销售记录...\n",
      "正在为年份 2021 第 1 季度生成 180,711 条销售记录...\n",
      "正在为年份 2021 第 2 季度生成 208,002 条销售记录...\n",
      "正在为年份 2021 第 3 季度生成 239,295 条销售记录...\n",
      "正在为年份 2021 第 4 季度生成 308,212 条销售记录...\n",
      "正在为年份 2022 第 1 季度生成 302,504 条销售记录...\n",
      "正在为年份 2022 第 2 季度生成 273,118 条销售记录...\n",
      "正在为年份 2022 第 3 季度生成 346,018 条销售记录...\n",
      "正在为年份 2022 第 4 季度生成 392,210 条销售记录...\n",
      "正在为年份 2023 第 1 季度生成 435,993 条销售记录...\n",
      "正在为年份 2023 第 2 季度生成 465,858 条销售记录...\n",
      "正在为年份 2023 第 3 季度生成 436,385 条销售记录...\n",
      "正在为年份 2023 第 4 季度生成 470,343 条销售记录...\n",
      "正在为年份 2024 第 1 季度生成 390,135 条销售记录...\n",
      "正在为年份 2024 第 2 季度生成 467,041 条销售记录...\n",
      "正在为年份 2024 第 3 季度生成 461,217 条销售记录...\n",
      "正在为年份 2024 第 4 季度生成 470,832 条销售记录...\n",
      "正在为年份 2025 第 1 季度生成 333,167 条销售记录...\n",
      "正在为年份 2025 第 2 季度生成 387,635 条销售记录...\n",
      "Fact_Sales.csv 已成功生成 7,965,302 行数据，耗时 164.99 秒。\n",
      "数据生成完成！\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Generate Fact_Sales Table (CPU Version)\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "\n",
    "def generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath):\n",
    "    \"\"\"\n",
    "    Generates the Fact_Sales table by combining all dimension tables.\n",
    "    Uses real-world Tesla sales distribution and volume data for realistic output.\n",
    "    \"\"\"\n",
    "    end_date = datetime(2025, 6, 30)\n",
    "\n",
    "    # 季度营收数据 (单位: 10亿 USD)，已更新为更精确的数值\n",
    "    quarterly_revenue = {\n",
    "        # 2013年 ($2.01B) - 仅Model S销售，按季度比例分配\n",
    "        (2013, 1): 0.4e9, (2013, 2): 0.45e9, (2013, 3): 0.53e9, (2013, 4): 0.63e9,\n",
    "        # 2014年 ($3.2B) - 按季度比例分配\n",
    "        (2014, 1): 0.65e9, (2014, 2): 0.75e9, (2014, 3): 0.85e9, (2014, 4): 0.95e9,\n",
    "        # 2015年 ($4.05B) - 按季度比例分配\n",
    "        (2015, 1): 0.8e9, (2015, 2): 0.9e9, (2015, 3): 1.0e9, (2015, 4): 1.35e9,\n",
    "        # 2016年 ($7B) - 按季度比例分配\n",
    "        (2016, 1): 1.4e9, (2016, 2): 1.6e9, (2016, 3): 1.9e9, (2016, 4): 2.1e9,\n",
    "        # 2017年 ($11.76B) - 按季度比例分配\n",
    "        (2017, 1): 2.3e9, (2017, 2): 2.6e9, (2017, 3): 3.0e9, (2017, 4): 3.86e9,\n",
    "        # 2018年 ($21.46B) - 按季度比例分配\n",
    "        (2018, 1): 4.1e9, (2018, 2): 4.9e9, (2018, 3): 5.8e9, (2018, 4): 6.66e9,\n",
    "        # 2019-2025年季度营收，已更新为更精确的数值\n",
    "        (2019, 1): 4.541e9, (2019, 2): 6.350e9, (2019, 3): 6.303e9, (2019, 4): 7.384e9,\n",
    "        (2020, 1): 5.985e9, (2020, 2): 6.036e9, (2020, 3): 8.771e9, (2020, 4): 10.744e9,\n",
    "        (2021, 1): 10.389e9, (2021, 2): 11.958e9, (2021, 3): 13.757e9, (2021, 4): 17.719e9,\n",
    "        (2022, 1): 18.756e9, (2022, 2): 16.934e9, (2022, 3): 21.454e9, (2022, 4): 24.318e9,\n",
    "        (2023, 1): 23.329e9, (2023, 2): 24.927e9, (2023, 3): 23.350e9, (2023, 4): 25.167e9,\n",
    "        (2024, 1): 21.301e9, (2024, 2): 25.500e9, (2024, 3): 25.182e9, (2024, 4): 25.707e9,\n",
    "        (2025, 1): 19.335e9, (2025, 2): 22.496e9\n",
    "    }\n",
    "\n",
    "    # 年度交付量数据，已根据你提供的实际历史数据更新\n",
    "    unit_targets_by_year = {\n",
    "        2013: 22442,\n",
    "        2014: 31655,\n",
    "        2015: 50517,\n",
    "        2016: 76243,\n",
    "        2017: 103091,\n",
    "        2018: 245491,\n",
    "        2019: 367656,\n",
    "        2020: 499535,\n",
    "        2021: 936222,\n",
    "        2022: 1313851,\n",
    "        2023: 1808581,\n",
    "        2024: 1789226\n",
    "    }\n",
    "    unit_targets_by_year[2025] = 336681 + 384122\n",
    "    \n",
    "    # 2013-2018年季度交付量手动分配\n",
    "    quarterly_unit_splits = {\n",
    "        2013: {1: 4750, 2: 5150, 3: 5800, 4: 6742},\n",
    "        2014: {1: 6450, 2: 7570, 3: 8800, 4: 8835},\n",
    "        2015: {1: 10045, 2: 11532, 3: 11584, 4: 17356},\n",
    "        2016: {1: 14810, 2: 18345, 3: 24500, 4: 18588},\n",
    "        2017: {1: 25418, 2: 22000, 3: 26135, 4: 29538},\n",
    "        2018: {1: 29980, 2: 40740, 3: 83780, 4: 90991}\n",
    "    }\n",
    "\n",
    "    # --------------------------\n",
    "    # 步骤 1: 数据清洗和预处理\n",
    "    # --------------------------\n",
    "    if 'Product_Name' not in dim_product_df.columns:\n",
    "        print(\"警告：Dim_Product.csv中缺少'Product_Name'列，正在根据Product_ID创建。\")\n",
    "        product_id_to_name = {\n",
    "            'PRO001': 'Model S', 'PRO002': 'Model X', 'PRO003': 'Model 3', 'PRO004': 'Model Y', 'PRO005': 'Cybertruck'\n",
    "        }\n",
    "        dim_product_df['Product_Name'] = dim_product_df['Product_ID'].map(product_id_to_name).fillna('Other')\n",
    "    \n",
    "    # 补全国家列表，确保数据更真实\n",
    "    asia_countries = ['China', 'Japan', 'South Korea', 'Singapore', 'India', 'Indonesia', 'Thailand', 'Malaysia', 'Taiwan']\n",
    "    oceania_countries = ['Australia', 'New Zealand']\n",
    "    europe_countries = ['Germany', 'United Kingdom', 'France', 'Norway', 'Netherlands', 'Sweden', 'Italy', 'Switzerland', 'Spain', 'Belgium', 'Austria', 'Denmark', 'Finland', 'Portugal', 'Ireland', 'Luxembourg', 'Iceland']\n",
    "    \n",
    "    def get_continent(country):\n",
    "        if country in asia_countries: return 'Asia'\n",
    "        if country in oceania_countries: return 'Oceania'\n",
    "        if country in europe_countries: return 'Europe'\n",
    "        return 'North America'\n",
    "            \n",
    "    dim_geography_df['Continent'] = dim_geography_df['Country'].apply(get_continent).astype(str)\n",
    "\n",
    "    # --------------------------\n",
    "    # 步骤 2: 定义权重\n",
    "    # --------------------------\n",
    "    product_weights_by_name = {\n",
    "        'Model S': 0.45, 'Model X': 0.45, 'Model 3': 0.05, 'Model Y': 0.04, 'Cybertruck': 0.01\n",
    "    }\n",
    "    \n",
    "    # 定义大陆、国家、省份的权重，并提供默认值\n",
    "    continent_weights = {'North America': 0.45, 'Europe': 0.30, 'Asia': 0.23, 'Oceania': 0.02}\n",
    "    country_weights = {'United States': 0.80, 'Canada': 0.20, 'China': 0.70, 'Japan': 0.18, 'South Korea': 0.13, 'Germany': 0.30, 'United Kingdom': 0.20, 'France': 0.15, 'Norway': 0.10, 'Australia': 0.75, 'New Zealand': 0.25, 'Taiwan': 0.1}\n",
    "    state_province_weights = {\n",
    "        'California': 0.40, 'Texas': 0.25, 'Florida': 0.15, 'Washington': 0.10, 'New York': 0.10,\n",
    "        'Ontario': 0.4, 'Quebec': 0.25, 'British Columbia': 0.2, 'Alberta': 0.15,\n",
    "        'Shanghai': 0.50, 'Beijing': 0.20, 'Guangdong': 0.20, 'Zhejiang': 0.10,\n",
    "        'Taipei': 0.5, 'New Taipei City': 0.2, 'Taichung': 0.1, 'Kaohsiung': 0.1, 'Tainan': 0.05, 'Taoyuan': 0.05,\n",
    "        'Bavaria': 0.40, 'North Rhine-Westphalia': 0.25, 'Baden-Württemberg': 0.15, 'Berlin': 0.10,\n",
    "        'Greater London': 0.50, 'South East England': 0.25, 'North West England': 0.15, 'West Midlands': 0.10,\n",
    "        'Île-de-France': 0.60, 'Auvergne-Rhône-Alpes': 0.20, 'Nouvelle-Aquitaine': 0.10, 'Provence-Alpes-Côte d\\'Azur': 0.10,\n",
    "        'Oslo': 0.70, 'Vestland': 0.15, 'Viken': 0.10, 'Trøndelag': 0.05,\n",
    "        'New South Wales': 0.5, 'Victoria': 0.3, 'Queensland': 0.1, 'Western Australia': 0.05, 'South Australia': 0.05,\n",
    "        'Auckland': 0.6, 'Wellington': 0.2, 'Canterbury': 0.1, 'Otago': 0.05, 'Waikato': 0.05,\n",
    "    }\n",
    "\n",
    "    # 预计算所有 Geo_ID 的权重，并确保任何 Geo_ID 都有一个非零的权重\n",
    "    dim_geography_df['Geo_Weight'] = 0.0\n",
    "    for continent, c_weight in continent_weights.items():\n",
    "        countries_in_continent = dim_geography_df[dim_geography_df['Continent'] == continent]['Country'].unique()\n",
    "        for country in countries_in_continent:\n",
    "            country_w = country_weights.get(country, 0.01)\n",
    "            states = dim_geography_df[dim_geography_df['Country'] == country]['State_Province'].unique()\n",
    "            for state in states:\n",
    "                state_w = state_province_weights.get(state, 0.01)\n",
    "                mask = (dim_geography_df['Country'] == country) & (dim_geography_df['State_Province'] == state)\n",
    "                dim_geography_df.loc[mask, 'Geo_Weight'] = c_weight * country_w * state_w\n",
    "    dim_geography_df['Geo_Weight'] = dim_geography_df['Geo_Weight'].replace(0.0, 0.0001)\n",
    "\n",
    "    customer_ids = dim_customer_df['Customer_ID'].values\n",
    "    \n",
    "    # --------------------------\n",
    "    # 步骤 3: 确保时间数据类型一致\n",
    "    # --------------------------\n",
    "    dim_time_df['Full_Date'] = pd.to_datetime(dim_time_df['Full_Date'])\n",
    "    dim_time_df['Year_Int'] = dim_time_df['Full_Date'].dt.year\n",
    "    dim_time_df['Quarter_Int'] = dim_time_df['Full_Date'].dt.quarter\n",
    "    dim_time_df['Quarter_Start_Date'] = dim_time_df['Full_Date'].dt.to_period('Q').dt.start_time\n",
    "\n",
    "    # --------------------------\n",
    "    # 步骤 4: 创建价格查找字典\n",
    "    # --------------------------\n",
    "    price_lookup = {}\n",
    "    if 'Standard_Price_USD' not in dim_prices_df.columns or 'Discounted_Price_USD' not in dim_prices_df.columns:\n",
    "        raise KeyError(\"Dim_Prices.csv 文件中缺少必要的列。请检查文件是否包含 'Standard_Price_USD' 和 'Discounted_Price_USD'。\")\n",
    "\n",
    "    dim_prices_df['Quarter_Start_Date'] = pd.to_datetime(dim_prices_df['Quarter_Start_Date'])\n",
    "    for _, row in dim_prices_df.iterrows():\n",
    "        quarter_start_date = row['Quarter_Start_Date']\n",
    "        product_id = row['Product_ID']\n",
    "        price_lookup[(quarter_start_date, product_id)] = {\n",
    "            'Standard_Price_USD': row['Standard_Price_USD'],\n",
    "            'Discounted_Price_USD': row['Discounted_Price_USD']\n",
    "        }\n",
    "\n",
    "    model_avg_prices = dim_prices_df.groupby('Product_ID')['Standard_Price_USD'].mean().to_dict()\n",
    "\n",
    "    # 将产品和地理信息转换为字典，以便在循环中快速查找\n",
    "    product_weights_dict = {\n",
    "        pid: product_weights_by_name.get(pname, 0.0001) for pid, pname in dim_product_df.set_index('Product_ID')['Product_Name'].to_dict().items()\n",
    "    }\n",
    "    geo_weights_dict = dim_geography_df.set_index('Geo_ID')['Geo_Weight'].to_dict()\n",
    "\n",
    "    start_year = min(unit_targets_by_year.keys())\n",
    "    \n",
    "    total_generated_rows = 0\n",
    "    header_written = False\n",
    "\n",
    "    # 预先生成所有可能的组合及其权重，但**不**存储在巨大的 DataFrame 中\n",
    "    all_product_ids = list(product_weights_dict.keys())\n",
    "    all_geo_ids = list(geo_weights_dict.keys())\n",
    "    \n",
    "    # 建立组合到索引的映射\n",
    "    combo_to_index = {}\n",
    "    combo_list = []\n",
    "    combo_weights_list = []\n",
    "    \n",
    "    idx = 0\n",
    "    for prod_id, geo_id in product(all_product_ids, all_geo_ids):\n",
    "        prod_weight = product_weights_dict.get(prod_id, 0.0001)\n",
    "        geo_weight = geo_weights_dict.get(geo_id, 0.0001)\n",
    "        combo_to_index[(prod_id, geo_id)] = idx\n",
    "        combo_list.append((prod_id, geo_id))\n",
    "        combo_weights_list.append(prod_weight * geo_weight)\n",
    "        idx += 1\n",
    "\n",
    "    total_combo_weight = sum(combo_weights_list)\n",
    "    if total_combo_weight == 0:\n",
    "        print(\"警告：总组合权重为零，无法进行数据生成。\")\n",
    "        return 0\n",
    "\n",
    "    combo_probabilities = np.array(combo_weights_list) / total_combo_weight\n",
    "    \n",
    "    # 按年份和季度循环生成\n",
    "    for year in range(start_year, end_date.year + 1):\n",
    "        for quarter in range(1, 5):\n",
    "            target_units = 0\n",
    "            target_revenue = 0\n",
    "\n",
    "            # 检查是否有该季度的数据\n",
    "            if (year, quarter) not in quarterly_revenue:\n",
    "                continue\n",
    "\n",
    "            if year < 2019:\n",
    "                if year not in quarterly_unit_splits or quarter not in quarterly_unit_splits[year]: continue\n",
    "                target_units = quarterly_unit_splits[year][quarter]\n",
    "                target_revenue = quarterly_revenue.get((year, quarter), 0)\n",
    "            else:\n",
    "                target_revenue = quarterly_revenue.get((year, quarter), 0)\n",
    "                total_year_units = unit_targets_by_year.get(year, 0)\n",
    "                if total_year_units == 0: continue\n",
    "                total_year_revenue = sum(v for k, v in quarterly_revenue.items() if k[0] == year)\n",
    "                if total_year_revenue == 0: continue\n",
    "                quarter_revenue_ratio = target_revenue / total_year_revenue\n",
    "                target_units = int(total_year_units * quarter_revenue_ratio)\n",
    "            \n",
    "            if target_units <= 0: continue\n",
    "            \n",
    "            print(f\"正在为年份 {year} 第 {quarter} 季度生成 {target_units:,} 条销售记录...\")\n",
    "            \n",
    "            # 使用 NumPy 直接进行高效抽样\n",
    "            sampled_combo_indices = np.random.choice(len(combo_list), size=target_units, p=combo_probabilities)\n",
    "            \n",
    "            # 根据抽样结果，构建数据\n",
    "            records = []\n",
    "            quarter_time_ids = dim_time_df[\n",
    "                (dim_time_df['Year_Int'] == year) & (dim_time_df['Quarter_Int'] == quarter)\n",
    "            ]['Time_ID'].tolist()\n",
    "            if not quarter_time_ids:\n",
    "                print(f\"警告：年份 {year} 第 {quarter} 季度没有可用的时间组合，跳过生成。\")\n",
    "                continue\n",
    "            \n",
    "            # 预先获取季度开始日期\n",
    "            quarter_start_date = dim_time_df[\n",
    "                (dim_time_df['Year_Int'] == year) & (dim_time_df['Quarter_Int'] == quarter)\n",
    "            ]['Quarter_Start_Date'].iloc[0]\n",
    "\n",
    "            # 新增逻辑：引入收入差异化\n",
    "            generated_revenues = []\n",
    "            transaction_details = []\n",
    "\n",
    "            for i in range(target_units):\n",
    "                combo_index = sampled_combo_indices[i]\n",
    "                product_id, geo_id = combo_list[combo_index]\n",
    "                \n",
    "                prices = price_lookup.get((quarter_start_date, product_id))\n",
    "                if prices:\n",
    "                    standard_price = prices['Standard_Price_USD']\n",
    "                    discounted_price = prices['Discounted_Price_USD']\n",
    "                else:\n",
    "                    standard_price = model_avg_prices.get(product_id, 0)\n",
    "                    discounted_price = standard_price\n",
    "                \n",
    "                # 随机选择一个价格，模拟真实销售，80%概率为标准价，20%为折扣价\n",
    "                is_discounted = np.random.choice([True, False], p=[0.2, 0.8])\n",
    "                price_used = discounted_price if is_discounted else standard_price\n",
    "                generated_revenues.append(price_used)\n",
    "\n",
    "                time_id = np.random.choice(quarter_time_ids)\n",
    "                customer_id = np.random.choice(customer_ids)\n",
    "                \n",
    "                transaction_details.append({\n",
    "                    'Time_ID': time_id,\n",
    "                    'Geo_ID': geo_id,\n",
    "                    'Product_ID': product_id,\n",
    "                    'Customer_ID': customer_id,\n",
    "                    'Sales_Units': 1,\n",
    "                    'Is_Discounted_Sale': is_discounted,\n",
    "                    'Revenue_USD': 0 # 临时占位，稍后校准\n",
    "                })\n",
    "\n",
    "            if not generated_revenues:\n",
    "                continue\n",
    "\n",
    "            # 校准收入以匹配季度总营收\n",
    "            total_generated_revenue = sum(generated_revenues)\n",
    "            if total_generated_revenue > 0:\n",
    "                scaling_factor = target_revenue / total_generated_revenue\n",
    "            else:\n",
    "                scaling_factor = 0\n",
    "            \n",
    "            for detail, revenue in zip(transaction_details, generated_revenues):\n",
    "                detail['Revenue_USD'] = revenue * scaling_factor\n",
    "\n",
    "            fact_sales_df_temp = pd.DataFrame(transaction_details)\n",
    "\n",
    "            # 首次写入时带上表头，后续写入则不带\n",
    "            fact_sales_df_temp.to_csv(output_filepath, mode='a', header=not header_written, index=False, encoding='utf-8')\n",
    "            header_written = True\n",
    "            total_generated_rows += len(fact_sales_df_temp)\n",
    "    \n",
    "    return total_generated_rows\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"正在加载所有维度表...\")\n",
    "    try:\n",
    "        dim_product_df = pd.read_csv(os.path.join('./output_data', 'Dim_Product.csv'))\n",
    "        dim_time_df = pd.read_csv(os.path.join('./output_data', 'Dim_Time.csv'))\n",
    "        dim_customer_df = pd.read_csv(os.path.join('./output_data', 'Dim_Customer.csv'))\n",
    "        dim_geography_df = pd.read_csv(os.path.join('./output_data', 'Dim_Geography.csv'))\n",
    "        dim_prices_df = pd.read_csv(os.path.join('./output_data', 'Dim_Prices.csv'))\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"错误：缺少一个或多个必需的 CSV 文件。请先运行所有维度生成脚本（1-5）。\\n{e}\")\n",
    "        exit()\n",
    "\n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    output_filepath = os.path.join(output_dir, 'Fact_Sales.csv')\n",
    "\n",
    "    # 移除旧文件以确保从一个干净的状态开始\n",
    "    if os.path.exists(output_filepath):\n",
    "        os.remove(output_filepath)\n",
    "        print(\"已移除旧的 Fact_Sales.csv 文件。\")\n",
    "\n",
    "    print(\"正在生成 Fact_Sales 表...\")\n",
    "    total_rows = generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath)\n",
    "\n",
    "    if total_rows > 0:\n",
    "        end_time = time.time()\n",
    "        print(f\"Fact_Sales.csv 已成功生成 {total_rows:,} 行数据，耗时 {end_time - start_time:.2f} 秒。\")\n",
    "        print(\"数据生成完成！\")\n",
    "    else:\n",
    "        print(\"数据生成失败。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cca4312-d2df-43e5-8a99-e1aa6627e97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a67ea-6cd9-4b11-90b5-e2b020b25769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ef63912-8cb9-4de3-9d4e-69412b8fbb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载所有维度表...\n",
      "正在生成 Fact_Sales 表...\n",
      "正在生成 2013年Q1季度的数据...\n",
      "正在生成 2013年Q2季度的数据...\n",
      "正在生成 2013年Q3季度的数据...\n",
      "正在生成 2013年Q4季度的数据...\n",
      "正在生成 2014年Q1季度的数据...\n",
      "正在生成 2014年Q2季度的数据...\n",
      "正在生成 2014年Q3季度的数据...\n",
      "正在生成 2014年Q4季度的数据...\n",
      "正在生成 2015年Q1季度的数据...\n",
      "正在生成 2015年Q2季度的数据...\n",
      "正在生成 2015年Q3季度的数据...\n",
      "正在生成 2015年Q4季度的数据...\n",
      "正在生成 2016年Q1季度的数据...\n",
      "正在生成 2016年Q2季度的数据...\n",
      "正在生成 2016年Q3季度的数据...\n",
      "正在生成 2016年Q4季度的数据...\n",
      "正在生成 2017年Q1季度的数据...\n",
      "正在生成 2017年Q2季度的数据...\n",
      "正在生成 2017年Q3季度的数据...\n",
      "正在生成 2017年Q4季度的数据...\n",
      "正在生成 2018年Q1季度的数据...\n",
      "正在生成 2018年Q2季度的数据...\n",
      "正在生成 2018年Q3季度的数据...\n",
      "正在生成 2018年Q4季度的数据...\n",
      "正在生成 2019年Q1季度的数据...\n",
      "正在生成 2019年Q2季度的数据...\n",
      "正在生成 2019年Q3季度的数据...\n",
      "正在生成 2019年Q4季度的数据...\n",
      "正在生成 2020年Q1季度的数据...\n",
      "正在生成 2020年Q2季度的数据...\n",
      "正在生成 2020年Q3季度的数据...\n",
      "正在生成 2020年Q4季度的数据...\n",
      "正在生成 2021年Q1季度的数据...\n",
      "正在生成 2021年Q2季度的数据...\n",
      "正在生成 2021年Q3季度的数据...\n",
      "正在生成 2021年Q4季度的数据...\n",
      "正在生成 2022年Q1季度的数据...\n",
      "正在生成 2022年Q2季度的数据...\n",
      "正在生成 2022年Q3季度的数据...\n",
      "正在生成 2022年Q4季度的数据...\n",
      "正在生成 2023年Q1季度的数据...\n",
      "正在生成 2023年Q2季度的数据...\n",
      "正在生成 2023年Q3季度的数据...\n",
      "正在生成 2023年Q4季度的数据...\n",
      "正在生成 2024年Q1季度的数据...\n",
      "正在生成 2024年Q2季度的数据...\n",
      "正在生成 2024年Q3季度的数据...\n",
      "正在生成 2024年Q4季度的数据...\n",
      "正在生成 2025年Q1季度的数据...\n",
      "正在生成 2025年Q2季度的数据...\n",
      "Fact_Sales.csv 已成功生成 42,518,504 行数据，耗时 1730.99 秒。\n",
      "数据生成完成！\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Generate Fact_Sales Table (CPU Version)\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "\n",
    "def generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath):\n",
    "    \"\"\"\n",
    "    Generates the Fact_Sales table by combining all dimension tables.\n",
    "    Uses real-world Tesla sales distribution and volume data for realistic output.\n",
    "    \"\"\"\n",
    "    end_date = datetime(2025, 6, 30)\n",
    "\n",
    "    # 季度营收数据 (单位: 10亿 USD)，已根据财报数据更新\n",
    "    quarterly_revenues_by_category = {\n",
    "        # 2021Q1 - 2025Q2 财报数据\n",
    "        (2021, 1): {'Automotive sales': 8.187e9, 'Automotive regulatory credits': 518e6, 'Automotive leasing': 297e6, 'Energy Generation & Storage': 494e6, 'Services & Other': 893e6},\n",
    "        (2021, 2): {'Automotive sales': 9.520e9, 'Automotive regulatory credits': 354e6, 'Automotive leasing': 332e6, 'Energy Generation & Storage': 801e6, 'Services & Other': 951e6},\n",
    "        (2021, 3): {'Automotive sales': 11.393e9, 'Automotive regulatory credits': 279e6, 'Automotive leasing': 385e6, 'Energy Generation & Storage': 806e6, 'Services & Other': 894e6},\n",
    "        (2021, 4): {'Automotive sales': 15.025e9, 'Automotive regulatory credits': 314e6, 'Automotive leasing': 628e6, 'Energy Generation & Storage': 688e6, 'Services & Other': 1.064e9},\n",
    "        (2022, 1): {'Automotive sales': 15.514e9, 'Automotive regulatory credits': 679e6, 'Automotive leasing': 668e6, 'Energy Generation & Storage': 616e6, 'Services & Other': 1.279e9},\n",
    "        (2022, 2): {'Automotive sales': 13.670e9, 'Automotive regulatory credits': 344e6, 'Automotive leasing': 588e6, 'Energy Generation & Storage': 866e6, 'Services & Other': 1.466e9},\n",
    "        (2022, 3): {'Automotive sales': 17.785e9, 'Automotive regulatory credits': 286e6, 'Automotive leasing': 621e6, 'Energy Generation & Storage': 1.117e9, 'Services & Other': 1.645e9},\n",
    "        (2022, 4): {'Automotive sales': 20.241e9, 'Automotive regulatory credits': 467e6, 'Automotive leasing': 599e6, 'Energy Generation & Storage': 1.310e9, 'Services & Other': 1.701e9},\n",
    "        (2023, 1): {'Automotive sales': 18.878e9, 'Automotive regulatory credits': 521e6, 'Automotive leasing': 564e6, 'Energy Generation & Storage': 1.529e9, 'Services & Other': 1.837e9},\n",
    "        (2023, 2): {'Automotive sales': 20.419e9, 'Automotive regulatory credits': 282e6, 'Automotive leasing': 567e6, 'Energy Generation & Storage': 1.509e9, 'Services & Other': 2.150e9},\n",
    "        (2023, 3): {'Automotive sales': 18.582e9, 'Automotive regulatory credits': 554e6, 'Automotive leasing': 489e6, 'Energy Generation & Storage': 1.559e9, 'Services & Other': 2.166e9},\n",
    "        (2023, 4): {'Automotive sales': 20.630e9, 'Automotive regulatory credits': 433e6, 'Automotive leasing': 500e6, 'Energy Generation & Storage': 1.438e9, 'Services & Other': 2.166e9},\n",
    "        (2024, 1): {'Automotive sales': 16.460e9, 'Automotive regulatory credits': 442e6, 'Automotive leasing': 476e6, 'Energy Generation & Storage': 1.635e9, 'Services & Other': 2.288e9},\n",
    "        (2024, 2): {'Automotive sales': 18.530e9, 'Automotive regulatory credits': 890e6, 'Automotive leasing': 458e6, 'Energy Generation & Storage': 3.014e9, 'Services & Other': 2.608e9},\n",
    "        (2024, 3): {'Automotive sales': 18.831e9, 'Automotive regulatory credits': 739e6, 'Automotive leasing': 446e6, 'Energy Generation & Storage': 2.376e9, 'Services & Other': 2.790e9},\n",
    "        (2024, 4): {'Automotive sales': 18.659e9, 'Automotive regulatory credits': 692e6, 'Automotive leasing': 447e6, 'Energy Generation & Storage': 3.061e9, 'Services & Other': 2.848e9},\n",
    "        (2025, 1): {'Automotive sales': 12.925e9, 'Automotive regulatory credits': 595e6, 'Automotive leasing': 447e6, 'Energy Generation & Storage': 2.730e9, 'Services & Other': 2.638e9},\n",
    "        (2025, 2): {'Automotive sales': 15.787e9, 'Automotive regulatory credits': 439e6, 'Automotive leasing': 435e6, 'Energy Generation & Storage': 2.789e9, 'Services & Other': 3.046e9},\n",
    "    }\n",
    "    \n",
    "    # 年度交付量数据\n",
    "    unit_targets_by_year = {\n",
    "        2013: 22442, 2014: 31655, 2015: 50517, 2016: 76243, 2017: 103091,\n",
    "        2018: 245491, 2019: 367656, 2020: 499535, 2021: 936222, 2022: 1313851,\n",
    "        2023: 1808581, 2024: 1789226, 2025: 336681 + 384122\n",
    "    }\n",
    "    \n",
    "    # --------------------------\n",
    "    # 步骤 1: 数据清洗和预处理\n",
    "    # --------------------------\n",
    "    dim_product_df.columns = dim_product_df.columns.str.strip()\n",
    "    if 'Product_Name' not in dim_product_df.columns:\n",
    "        raise KeyError(\"Dim_Product.csv中缺少'Product_Name'列，请检查文件。\")\n",
    "    if 'Product_Category' not in dim_product_df.columns:\n",
    "        raise KeyError(\"Dim_Product.csv中缺少'Product_Category'列，请检查文件。\")\n",
    "\n",
    "    asia_countries = ['China', 'Japan', 'South Korea', 'Singapore', 'India', 'Indonesia', 'Thailand', 'Malaysia', 'Taiwan']\n",
    "    oceania_countries = ['Australia', 'New Zealand']\n",
    "    europe_countries = ['Germany', 'United Kingdom', 'France', 'Norway', 'Netherlands', 'Sweden', 'Italy', 'Switzerland', 'Spain', 'Belgium', 'Austria', 'Denmark', 'Finland', 'Portugal', 'Ireland', 'Luxembourg', 'Iceland']\n",
    "    \n",
    "    def get_continent(country):\n",
    "        if country in asia_countries: return 'Asia'\n",
    "        if country in oceania_countries: return 'Oceania'\n",
    "        if country in europe_countries: return 'Europe'\n",
    "        return 'North America'\n",
    "        \n",
    "    dim_geography_df['Continent'] = dim_geography_df['Country'].apply(get_continent).astype(str)\n",
    "\n",
    "    # --------------------------\n",
    "    # 步骤 2: 定义权重\n",
    "    # --------------------------\n",
    "    # 定义大陆、国家、省份的权重\n",
    "    continent_weights = {'North America': 0.45, 'Europe': 0.30, 'Asia': 0.23, 'Oceania': 0.02}\n",
    "    country_weights = {'United States': 0.80, 'Canada': 0.20, 'China': 0.70, 'Japan': 0.18, 'South Korea': 0.13, 'Germany': 0.30, 'United Kingdom': 0.20, 'France': 0.15, 'Norway': 0.10, 'Australia': 0.75, 'New Zealand': 0.25, 'Taiwan': 0.1}\n",
    "    state_province_weights = {\n",
    "        'California': 0.40, 'Texas': 0.25, 'Florida': 0.15, 'Washington': 0.10, 'New York': 0.10,\n",
    "        'Ontario': 0.4, 'Quebec': 0.25, 'British Columbia': 0.2, 'Alberta': 0.15,\n",
    "        'Shanghai': 0.50, 'Beijing': 0.20, 'Guangdong': 0.20, 'Zhejiang': 0.10,\n",
    "        'Taipei': 0.5, 'New Taipei City': 0.2, 'Taichung': 0.1, 'Kaohsiung': 0.1, 'Tainan': 0.05, 'Taoyuan': 0.05,\n",
    "        'Bavaria': 0.40, 'North Rhine-Westphalia': 0.25, 'Baden-Württemberg': 0.15, 'Berlin': 0.10,\n",
    "        'Greater London': 0.50, 'South East England': 0.25, 'North West England': 0.15, 'West Midlands': 0.10,\n",
    "        'Île-de-France': 0.60, 'Auvergne-Rhône-Alpes': 0.20, 'Nouvelle-Aquitaine': 0.10, 'Provence-Alpes-Côte d\\'Azur': 0.10,\n",
    "        'Oslo': 0.70, 'Vestland': 0.15, 'Viken': 0.10, 'Trøndelag': 0.05,\n",
    "        'New South Wales': 0.5, 'Victoria': 0.3, 'Queensland': 0.1, 'Western Australia': 0.05, 'South Australia': 0.05,\n",
    "        'Auckland': 0.6, 'Wellington': 0.2, 'Canterbury': 0.1, 'Otago': 0.05, 'Waikato': 0.05,\n",
    "    }\n",
    "\n",
    "    # 预计算所有 Geo_ID 的权重并归一化\n",
    "    dim_geography_df['Geo_Weight'] = 0.0\n",
    "    for continent, c_weight in continent_weights.items():\n",
    "        countries_in_continent = dim_geography_df[dim_geography_df['Continent'] == continent]['Country'].unique()\n",
    "        for country in countries_in_continent:\n",
    "            country_w = country_weights.get(country, 0.01)\n",
    "            states = dim_geography_df[dim_geography_df['Country'] == country]['State_Province'].unique()\n",
    "            for state in states:\n",
    "                state_w = state_province_weights.get(state, 0.01)\n",
    "                mask = (dim_geography_df['Country'] == country) & (dim_geography_df['State_Province'] == state)\n",
    "                dim_geography_df.loc[mask, 'Geo_Weight'] = c_weight * country_w * state_w\n",
    "    dim_geography_df['Geo_Weight'] = dim_geography_df['Geo_Weight'].replace(0.0, 0.0001)\n",
    "    # 归一化步骤，修复 ValueError\n",
    "    dim_geography_df['Geo_Weight'] = dim_geography_df['Geo_Weight'] / dim_geography_df['Geo_Weight'].sum()\n",
    "\n",
    "    customer_ids = dim_customer_df['Customer_ID'].values\n",
    "    regulatory_customer_names = ['Stellantis', 'Honda', 'Ford']\n",
    "    regulatory_customer_ids = dim_customer_df[dim_customer_df['Customer_Name'].isin(regulatory_customer_names)]['Customer_ID'].values\n",
    "    \n",
    "    # --------------------------\n",
    "    # 步骤 3: 确保时间数据类型一致\n",
    "    # --------------------------\n",
    "    dim_time_df['Full_Date'] = pd.to_datetime(dim_time_df['Full_Date'])\n",
    "    dim_time_df['Year_Int'] = dim_time_df['Full_Date'].dt.year\n",
    "    dim_time_df['Quarter_Int'] = dim_time_df['Full_Date'].dt.quarter\n",
    "    dim_time_df['Quarter_Start_Date'] = dim_time_df['Full_Date'].dt.to_period('Q').dt.start_time\n",
    "\n",
    "    # --------------------------\n",
    "    # 步骤 4: 创建价格查找字典\n",
    "    # --------------------------\n",
    "    price_lookup = {}\n",
    "    if 'Standard_Price_USD' not in dim_prices_df.columns or 'Discounted_Price_USD' not in dim_prices_df.columns:\n",
    "        raise KeyError(\"Dim_Prices.csv 文件中缺少必要的列。请检查文件是否包含 'Standard_Price_USD' 和 'Discounted_Price_USD'。\")\n",
    "\n",
    "    dim_prices_df['Quarter_Start_Date'] = pd.to_datetime(dim_prices_df['Quarter_Start_Date'])\n",
    "    for _, row in dim_prices_df.iterrows():\n",
    "        quarter_start_date = row['Quarter_Start_Date']\n",
    "        product_id = row['Product_ID']\n",
    "        price_lookup[(quarter_start_date, product_id)] = {\n",
    "            'Standard_Price_USD': row['Standard_Price_USD'],\n",
    "            'Discounted_Price_USD': row['Discounted_Price_USD']\n",
    "        }\n",
    "\n",
    "    model_avg_prices = dim_prices_df.groupby('Product_ID')['Standard_Price_USD'].mean().to_dict()\n",
    "    rough_avg_price_per_car = np.mean(list(model_avg_prices.values()))\n",
    "\n",
    "    # 建立产品类别到 Product_ID 的映射，并清洗类别名称\n",
    "    product_category_map = defaultdict(list)\n",
    "    for _, row in dim_product_df.iterrows():\n",
    "        cleaned_category = row['Product_Category'].strip()\n",
    "        product_category_map[cleaned_category].append(row['Product_ID'].strip())\n",
    "\n",
    "    start_year = min(unit_targets_by_year.keys())\n",
    "    \n",
    "    total_generated_rows = 0\n",
    "    header_written = False\n",
    "    \n",
    "    # 循环生成数据，从最早有交付量数据的年份开始\n",
    "    for year in range(start_year, end_date.year + 1):\n",
    "        for quarter in range(1, 5):\n",
    "            if (year, quarter) > (end_date.year, end_date.month // 3 + (1 if end_date.month % 3 > 0 else 0)):\n",
    "                continue\n",
    "\n",
    "            print(f\"正在生成 {year}年Q{quarter}季度的数据...\")\n",
    "            records = []\n",
    "            quarter_time_ids = dim_time_df[\n",
    "                (dim_time_df['Year_Int'] == year) & (dim_time_df['Quarter_Int'] == quarter)\n",
    "            ]['Time_ID'].tolist()\n",
    "            \n",
    "            if not quarter_time_ids:\n",
    "                continue\n",
    "\n",
    "            quarter_start_date = dim_time_df[\n",
    "                (dim_time_df['Year_Int'] == year) & (dim_time_df['Quarter_Int'] == quarter)\n",
    "            ]['Quarter_Start_Date'].iloc[0]\n",
    "\n",
    "            # ----------------------------------------------------\n",
    "            # 步骤 5: 生成销售记录\n",
    "            # ----------------------------------------------------\n",
    "            \n",
    "            if (year, quarter) in quarterly_revenues_by_category:\n",
    "                # 使用详细财报数据生成销售记录 (2021Q1 onwards)\n",
    "                quarter_revenue_data = quarterly_revenues_by_category[(year, quarter)]\n",
    "                total_year_units = unit_targets_by_year.get(year, 0)\n",
    "                total_year_revenue = sum(sum(d.values()) for y, d in quarterly_revenues_by_category.items() if y[0] == year)\n",
    "                total_quarter_revenue = sum(quarter_revenue_data.values())\n",
    "                quarter_revenue_ratio = total_quarter_revenue / total_year_revenue if total_year_revenue > 0 else 0\n",
    "                car_units = int(total_year_units * quarter_revenue_ratio)\n",
    "\n",
    "                car_product_ids = product_category_map.get('Automotive', [])\n",
    "                if car_units > 0 and car_product_ids:\n",
    "                    car_revenue_target = quarter_revenue_data.get('Automotive sales', 0)\n",
    "                    \n",
    "                    sampled_product_ids = np.random.choice(car_product_ids, size=car_units)\n",
    "                    sampled_geo_ids = np.random.choice(dim_geography_df['Geo_ID'], size=car_units, p=dim_geography_df['Geo_Weight'].values)\n",
    "                    \n",
    "                    car_revenues = []\n",
    "                    for i in range(car_units):\n",
    "                        product_id = sampled_product_ids[i]\n",
    "                        geo_id = sampled_geo_ids[i]\n",
    "                        \n",
    "                        prices = price_lookup.get((quarter_start_date, product_id))\n",
    "                        price_used = prices['Discounted_Price_USD'] if prices and np.random.rand() < 0.2 else (prices['Standard_Price_USD'] if prices else model_avg_prices.get(product_id, 0))\n",
    "                        \n",
    "                        car_revenues.append(price_used)\n",
    "                        \n",
    "                        records.append({\n",
    "                            'Time_ID': np.random.choice(quarter_time_ids),\n",
    "                            'Geo_ID': geo_id,\n",
    "                            'Product_ID': product_id,\n",
    "                            'Customer_ID': np.random.choice(customer_ids),\n",
    "                            'Sales_Units': 1,\n",
    "                            'Is_Discounted_Sale': True if prices and np.random.rand() < 0.2 else False,\n",
    "                            'Revenue_USD': 0 \n",
    "                        })\n",
    "                    \n",
    "                    total_generated_car_revenue = sum(car_revenues)\n",
    "                    if total_generated_car_revenue > 0:\n",
    "                        scaling_factor = car_revenue_target / total_generated_car_revenue\n",
    "                        for i, record in enumerate(records):\n",
    "                            record['Revenue_USD'] = car_revenues[i] * scaling_factor\n",
    "            \n",
    "                # --- Automotive Regulatory Credits (监管积分) ---\n",
    "                regulatory_revenue = quarter_revenue_data.get('Automotive regulatory credits', 0)\n",
    "                if regulatory_revenue > 0:\n",
    "                    credit_product_id = product_category_map.get('Financial & Regulatory', ['PRO011'])[0]\n",
    "                    avg_deal_value = 10e6\n",
    "                    num_deals = int(regulatory_revenue / avg_deal_value)\n",
    "                    \n",
    "                    for _ in range(num_deals):\n",
    "                        records.append({\n",
    "                            'Time_ID': np.random.choice(quarter_time_ids),\n",
    "                            'Geo_ID': np.random.choice(dim_geography_df['Geo_ID'], p=dim_geography_df['Geo_Weight'].values),\n",
    "                            'Product_ID': credit_product_id,\n",
    "                            'Customer_ID': np.random.choice(regulatory_customer_ids),\n",
    "                            'Sales_Units': 1,\n",
    "                            'Is_Discounted_Sale': False,\n",
    "                            'Revenue_USD': avg_deal_value\n",
    "                        })\n",
    "\n",
    "                # --- Automotive Leasing (车辆租赁) ---\n",
    "                leasing_revenue = quarter_revenue_data.get('Automotive leasing', 0)\n",
    "                if leasing_revenue > 0:\n",
    "                    leasing_product_ids = product_category_map.get('Automotive Leasing', [])\n",
    "                    if leasing_product_ids:\n",
    "                        avg_lease_value = (10000 + 20000) / 2\n",
    "                        num_leases = int(leasing_revenue / avg_lease_value)\n",
    "                        \n",
    "                        for _ in range(num_leases):\n",
    "                                records.append({\n",
    "                                    'Time_ID': np.random.choice(quarter_time_ids),\n",
    "                                    'Geo_ID': np.random.choice(dim_geography_df['Geo_ID'], p=dim_geography_df['Geo_Weight'].values),\n",
    "                                    'Product_ID': np.random.choice(leasing_product_ids),\n",
    "                                    'Customer_ID': np.random.choice(customer_ids),\n",
    "                                    'Sales_Units': 1,\n",
    "                                    'Is_Discounted_Sale': False,\n",
    "                                    'Revenue_USD': avg_lease_value\n",
    "                                })\n",
    "\n",
    "                # --- Energy Generation & Storage (能源) ---\n",
    "                energy_revenue = quarter_revenue_data.get('Energy Generation & Storage', 0)\n",
    "                if energy_revenue > 0:\n",
    "                    energy_product_ids = product_category_map.get('Energy Generation & Storage', [])\n",
    "                    if energy_product_ids:\n",
    "                        avg_energy_value = (5000 + 150000) / 2\n",
    "                        num_energy_sales = int(energy_revenue / avg_energy_value)\n",
    "                        \n",
    "                        for _ in range(num_energy_sales):\n",
    "                            records.append({\n",
    "                                'Time_ID': np.random.choice(quarter_time_ids),\n",
    "                                'Geo_ID': np.random.choice(dim_geography_df['Geo_ID'], p=dim_geography_df['Geo_Weight'].values),\n",
    "                                'Product_ID': np.random.choice(energy_product_ids),\n",
    "                                'Customer_ID': np.random.choice(customer_ids),\n",
    "                                'Sales_Units': 1,\n",
    "                                'Is_Discounted_Sale': False,\n",
    "                                'Revenue_USD': avg_energy_value\n",
    "                            })\n",
    "\n",
    "                # --- Services & Other (服务及其他) ---\n",
    "                services_revenue = quarter_revenue_data.get('Services & Other', 0)\n",
    "                if services_revenue > 0:\n",
    "                    service_product_ids = product_category_map.get('Services & Other', [])\n",
    "                    if service_product_ids:\n",
    "                        avg_service_value = (50 + 2000) / 2\n",
    "                        num_service_sales = int(services_revenue / avg_service_value)\n",
    "                        \n",
    "                        for _ in range(num_service_sales):\n",
    "                            records.append({\n",
    "                                'Time_ID': np.random.choice(quarter_time_ids),\n",
    "                                'Geo_ID': np.random.choice(dim_geography_df['Geo_ID'], p=dim_geography_df['Geo_Weight'].values),\n",
    "                                'Product_ID': np.random.choice(service_product_ids),\n",
    "                                'Customer_ID': np.random.choice(customer_ids),\n",
    "                                'Sales_Units': 1,\n",
    "                                'Is_Discounted_Sale': False,\n",
    "                                'Revenue_USD': avg_service_value\n",
    "                            })\n",
    "\n",
    "            else:\n",
    "                # 新增: 为没有详细财报数据的年份生成粗略数据 (2013-2020)\n",
    "                total_year_units = unit_targets_by_year.get(year, 0)\n",
    "                if total_year_units > 0:\n",
    "                    # 假设总营收 = 总交付量 * 粗略平均价格\n",
    "                    total_year_revenue = total_year_units * rough_avg_price_per_car\n",
    "                    # 将年度数据粗略平均分配到四个季度\n",
    "                    quarter_units = int(total_year_units / 4)\n",
    "                    quarter_revenue = total_year_revenue / 4\n",
    "                    revenue_per_unit = quarter_revenue / quarter_units if quarter_units > 0 else 0\n",
    "                    \n",
    "                    car_product_ids = product_category_map.get('Automotive', [])\n",
    "                    if car_product_ids:\n",
    "                        for _ in range(quarter_units):\n",
    "                            records.append({\n",
    "                                'Time_ID': np.random.choice(quarter_time_ids),\n",
    "                                'Geo_ID': np.random.choice(dim_geography_df['Geo_ID'], p=dim_geography_df['Geo_Weight'].values),\n",
    "                                'Product_ID': np.random.choice(car_product_ids),\n",
    "                                'Customer_ID': np.random.choice(customer_ids),\n",
    "                                'Sales_Units': 1,\n",
    "                                'Is_Discounted_Sale': False,\n",
    "                                'Revenue_USD': revenue_per_unit\n",
    "                            })\n",
    "                \n",
    "            if not records:\n",
    "                continue\n",
    "\n",
    "            fact_sales_df_temp = pd.DataFrame(records)\n",
    "\n",
    "            # 首次写入时带上表头，后续写入则不带\n",
    "            fact_sales_df_temp.to_csv(output_filepath, mode='a', header=not header_written, index=False, encoding='utf-8')\n",
    "            header_written = True\n",
    "            total_generated_rows += len(fact_sales_df_temp)\n",
    "    \n",
    "    return total_generated_rows\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"正在加载所有维度表...\")\n",
    "    try:\n",
    "        dim_product_df = pd.read_csv(os.path.join('./output_data', 'Dim_Product.csv'))\n",
    "        dim_time_df = pd.read_csv(os.path.join('./output_data', 'Dim_Time.csv'))\n",
    "        dim_customer_df = pd.read_csv(os.path.join('./output_data', 'Dim_Customer.csv'))\n",
    "        dim_geography_df = pd.read_csv(os.path.join('./output_data', 'Dim_Geography.csv'))\n",
    "        dim_prices_df = pd.read_csv(os.path.join('./output_data', 'Dim_Prices.csv'))\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"错误：缺少一个或多个必需的 CSV 文件。请先运行所有维度生成脚本（1-5）。\\n{e}\")\n",
    "        exit()\n",
    "\n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    output_filepath = os.path.join(output_dir, 'Fact_Sales.csv')\n",
    "\n",
    "    if os.path.exists(output_filepath):\n",
    "        os.remove(output_filepath)\n",
    "        print(\"已移除旧的 Fact_Sales.csv 文件。\")\n",
    "\n",
    "    print(\"正在生成 Fact_Sales 表...\")\n",
    "    total_rows = generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df, output_filepath)\n",
    "\n",
    "    if total_rows > 0:\n",
    "        end_time = time.time()\n",
    "        print(f\"Fact_Sales.csv 已成功生成 {total_rows:,} 行数据，耗时 {end_time - start_time:.2f} 秒。\")\n",
    "        print(\"数据生成完成！\")\n",
    "    else:\n",
    "        print(\"数据生成失败。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c851d3c-f2ab-4428-b951-3bf7224a1273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

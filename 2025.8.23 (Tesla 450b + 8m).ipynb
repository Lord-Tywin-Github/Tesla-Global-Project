{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf449bef-e93a-4d03-917c-639f8a222244",
   "metadata": {},
   "source": [
    "**1/6: 生成 Dim_Product 表 (简单静态数据)维度表更可能需要更新Update或追加Append。例如，新产品发布，此时就需要更新Update或追加Append表中的相应记录。这种变化管理被称为“缓慢变化维度”（Slowly Changing Dimension, SCD）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b99ed20-01ec-4cb6-aea8-81bbe173f7da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Dim_Product table...\n",
      "Saving Dim_Product.csv...\n",
      "Dim_Product.csv has been successfully generated with 5 rows in 0.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"1/6: Generate Dim_Product Table\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Use a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def generate_dim_product():\n",
    "    \"\"\"Generates the Dim_Product table.\"\"\"\n",
    "    data = [\n",
    "        [1, 'Model 3', 'Sedan', 46500.00, '2017-07-28'],\n",
    "        [2, 'Model Y', 'SUV', 55000.00, '2020-03-13'],\n",
    "        [3, 'Model S', 'Sedan', 82500.00, '2012-06-22'],\n",
    "        [4, 'Model X', 'SUV', 95000.00, '2015-09-29'],\n",
    "        [5, 'Cybertruck', 'Truck', 70000.00, '2023-11-30']\n",
    "    ]\n",
    "    df = pd.DataFrame(data, columns=['Model_ID', 'Model_Name', 'Model_Category', 'Model_Base_Price_USD', 'Model_Launch_Date'])\n",
    "    df['Model_Launch_Date'] = pd.to_datetime(df['Model_Launch_Date'])\n",
    "    return df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Generating Dim_Product table...\")\n",
    "    dim_product_df = generate_dim_product()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(\"Saving Dim_Product.csv...\")\n",
    "    dim_product_df.to_csv(os.path.join(output_dir, 'Dim_Product.csv'), index=False, encoding='utf-8')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Dim_Product.csv has been successfully generated with {len(dim_product_df)} rows in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f371243-4776-49eb-a503-cd4097725786",
   "metadata": {},
   "source": [
    "**2/6: 生成 Dim_Time 表 (单一向前数据)维度表只追加Append。每一个时间点、每一天、每一个月都是一个既定的、永恒不变的事实。你无法“更新”昨天或去年的日期，此时就需要追加Append表中的相应记录。没有复杂的版本控制机制（Slowly Changing Dimension, SCD）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09664203-5c7a-4b41-b672-1b8e9986894e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Dim_Time table...\n",
      "Saving Dim_Time.csv...\n",
      "Dim_Time.csv has been successfully generated with 3287 rows in 0.03 seconds.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"2/6: Generate Dim_Time Table\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "# Use a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def generate_dim_time():\n",
    "    \"\"\"Generates the Dim_Time table.\"\"\"\n",
    "    start_date = datetime.date(2017, 1, 1)\n",
    "    end_date = datetime.date(2025, 12, 31)\n",
    "    date_range = [start_date + datetime.timedelta(days=x) for x in range(0, (end_date - start_date).days + 1)]\n",
    "\n",
    "    data = []\n",
    "    for date in date_range:\n",
    "        data.append([\n",
    "            int(date.strftime('%Y%m%d')),\n",
    "            date,\n",
    "            date.year,\n",
    "            f\"Q{((date.month - 1) // 3) + 1}\",\n",
    "            date.month,\n",
    "            date.day,\n",
    "            date.isocalendar()[1],\n",
    "            date.isoweekday(),\n",
    "            date.strftime('%A')\n",
    "        ])\n",
    "    \n",
    "    return pd.DataFrame(data, columns=['Time_ID', 'Full_Date', 'Year', 'Quarter', 'Month', 'Day', 'Week_of_Year', 'Day_of_Week', 'Day_Name'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Generating Dim_Time table...\")\n",
    "    dim_time_df = generate_dim_time()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(\"Saving Dim_Time.csv...\")\n",
    "    dim_time_df.to_csv(os.path.join(output_dir, 'Dim_Time.csv'), index=False, encoding='utf-8')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Dim_Time.csv has been successfully generated with {len(dim_time_df)} rows in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f953d5d-7de6-4c86-b659-04a6b8375338",
   "metadata": {},
   "source": [
    "**3/6: 生成 Dim_Customer 表 (相对静态数据)维度表更可能需要更新Update或追加Append。例如，一个客户的收入水平或家庭住址可能会发生变化，此时就需要更新Update或追加Append表中的相应记录。这种变化管理被称为“缓慢变化维度”（Slowly Changing Dimension, SCD）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9146ff25-3cda-4671-a321-2b0f048ade8d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Dim_Customer table...\n",
      "Saving Dim_Customer.csv...\n",
      "Dim_Customer.csv has been successfully generated with 50000 rows in 0.09 seconds.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"3/6: Generate Dim_Customer Table\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Use a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def generate_dim_customer(num_customers=50000):\n",
    "    \"\"\"Generates the Dim_Customer table.\"\"\"\n",
    "    genders = ['Male', 'Female', 'Other']\n",
    "    age_groups = ['<25', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "    income_levels = ['Low', 'Medium', 'High']\n",
    "    first_names = ['James', 'Mary', 'John', 'Patricia', 'Robert', 'Jennifer', 'Michael', 'Linda', 'William', 'Elizabeth', 'David', 'Susan', 'Richard', 'Jessica', 'Joseph', 'Sarah', 'Thomas', 'Karen', 'Charles', 'Nancy', 'Christopher', 'Lisa', 'Daniel', 'Betty', 'Paul', 'Margaret', 'Mark', 'Sandra', 'Donald', 'Ashley', 'George', 'Kimberly', 'Kenneth', 'Donna', 'Steven', 'Emily', 'Edward', 'Carol', 'Brian', 'Michelle', 'Ronald', 'Amanda', 'Anthony', 'Melissa', 'Kevin', 'Deborah', 'Jason', 'Stephanie', 'Jeff', 'Maria', 'Gary', 'Heather', 'Timothy', 'Nicole', 'Jose', 'Denise', 'Larry', 'Megan', 'Jeffrey', 'Christina', 'Frank', 'Alexis', 'Scott', 'Tiffany', 'Eric', 'Lauren', 'Stephen', 'Rachel', 'Andrew', 'Crystal', 'Raymond', 'Kayla', 'Ryan', 'Danielle', 'Jacob', 'Brittany', 'Nicholas', 'Emma', 'Jonathan', 'Samantha', 'Laura', 'Alexis', 'Joshua', 'Brandon', 'Justin', 'Daniel', 'Daniel', 'Taylor']\n",
    "    last_names = ['Smith', 'Johnson', 'Williams', 'Jones', 'Brown', 'Davis', 'Miller', 'Wilson', 'Moore', 'Taylor', 'Anderson', 'Thomas', 'Jackson', 'White', 'Harris', 'Martin', 'Thompson', 'Garcia', 'Martinez', 'Robinson', 'Clark', 'Rodriguez', 'Lewis', 'Lee', 'Walker', 'Hall', 'Allen', 'Young', 'Hernandez', 'King', 'Wright', 'Lopez', 'Hill', 'Scott', 'Green', 'Adams', 'Baker', 'Gonzalez', 'Nelson', 'Carter', 'Mitchell', 'Perez', 'Roberts', 'Turner', 'Phillips', 'Campbell', 'Parker', 'Evans', 'Edwards', 'Collins', 'Stewart', 'Sanchez', 'Morris', 'Rogers', 'Reed', 'Cook', 'Morgan', 'Bell', 'Murphy', 'Bailey', 'Rivera', 'Cooper', 'Richardson', 'Cox', 'Howard', 'Ward', 'Torres', 'Peterson', 'Gray', 'Ramirez', 'James', 'Watson', 'Brooks', 'Kelly', 'Sanders', 'Price', 'Bennett', 'Wood', 'Barnes', 'Ross', 'Henderson', 'Coleman', 'Jenkins', 'Perry', 'Powell', 'Long', 'Patterson', 'Hughes', 'Flores', 'Washington', 'Butler', 'Simmons', 'Foster', 'Gonzales', 'Bryant', 'Alexander', 'Russell', 'Griffin', 'Diaz', 'Hayes', 'Myers', 'Ford', 'Hamilton', 'Graham', 'Sullivan', 'Wallace', 'Woods', 'Cole', 'West', 'Jordan', 'Owens', 'Reynolds', 'Fisher', 'Ellis', 'Harrison', 'Gibson', 'Mcdonald', 'Cruz', 'Marshall', 'Ortiz', 'Gomez', 'Murray', 'Freeman', 'Wells', 'Webb', 'Simpson', 'Stevens', 'Tucker', 'Porter', 'Hunter', 'Hicks', 'Crawford', 'Henry', 'Boyd', 'Mason', 'Kennedy', 'Warren', 'Dixon', 'Ramos', 'Reid', 'Carr', 'Chavez', 'Gibson']\n",
    "    \n",
    "    data = []\n",
    "    for i in range(1, num_customers + 1):\n",
    "        full_name = f\"{random.choice(first_names)} {random.choice(last_names)}\"\n",
    "        gender = random.choice(genders)\n",
    "        age_group = random.choice(age_groups)\n",
    "        income_level = random.choice(income_levels)\n",
    "        data.append([i, full_name, gender, age_group, income_level])\n",
    "        \n",
    "    return pd.DataFrame(data, columns=['Customer_ID', 'Customer_Name', 'Gender', 'Age_Group', 'Income_Level'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Generating Dim_Customer table...\")\n",
    "    dim_customer_df = generate_dim_customer()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(\"Saving Dim_Customer.csv...\")\n",
    "    dim_customer_df.to_csv(os.path.join(output_dir, 'Dim_Customer.csv'), index=False, encoding='utf-8')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Dim_Customer.csv has been successfully generated with {len(dim_customer_df)} rows in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46ad79b-74fc-416c-9e6b-6e7f06c55d9c",
   "metadata": {},
   "source": [
    "**4/6: 生成 Dim_Geography 表 (相对静态数据)维度表更可能需要更新Update或追加Append。例如，一个客户的地址可能会发生变化或更新到新的国家和城市，此时就需要更新Update或追加Append表中的相应记录。这种变化管理被称为“缓慢变化维度”（Slowly Changing Dimension, SCD）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f933bf39-e98c-47f9-9973-351260157c88",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Dim_Geography table...\n",
      "Saving Dim_Geography.csv...\n",
      "Dim_Geography.csv has been successfully generated with 432 rows in 0.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"4/6: Generate Dim_Geography Table\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Use a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def generate_plausible_zip(country, state_province_abbr):\n",
    "    \"\"\"Generates a plausible zip code based on the country and state/province.\"\"\"\n",
    "    letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    digits = '0123456789'\n",
    "\n",
    "    if country == 'United States':\n",
    "        return f\"{random.randint(10000, 99999)}\"\n",
    "    elif country == 'Canada':\n",
    "        return f\"{random.choice(letters)}{random.choice(digits)}{random.choice(letters)} {random.choice(digits)}{random.choice(letters)}{random.choice(digits)}\"\n",
    "    elif country == 'Mexico':\n",
    "        return f\"{random.randint(10000, 99999)}\"\n",
    "    elif country in ['Germany', 'Italy', 'Spain', 'Switzerland', 'Netherlands', 'Denmark', 'Norway', 'Sweden', 'Finland', 'Greece', 'Iceland', 'Ireland', 'Luxembourg', 'Monaco']:\n",
    "        return f\"{random.randint(10000, 99999)}\"\n",
    "    elif country == 'United Kingdom':\n",
    "        part1 = ''.join(random.choices(letters, k=random.choice([1, 2]))) + ''.join(random.choices(digits, k=random.choice([1, 2])))\n",
    "        part2 = f\"{random.choice(digits)}{random.choice(letters)}{random.choice(letters)}\"\n",
    "        return f\"{part1} {part2}\"\n",
    "    elif country == 'France':\n",
    "        return f\"{random.randint(1, 9)}{random.randint(0, 9)}{random.randint(0, 9)}{random.randint(0, 9)}{random.randint(0, 9)}\"\n",
    "    elif country == 'China':\n",
    "        return f\"{random.randint(100000, 999999)}\"\n",
    "    elif country in ['Japan', 'South Korea', 'Taiwan', 'Hong Kong', 'Macau']:\n",
    "        return f\"{random.randint(10000, 9999999)}\"\n",
    "    elif country == 'Australia':\n",
    "        return f\"{random.randint(1000, 9999)}\"\n",
    "    elif country == 'New Zealand':\n",
    "        return f\"{random.randint(1000, 9999)}\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def generate_dim_geography():\n",
    "    \"\"\"\n",
    "    Generates a Dim_Geography table.\n",
    "    \"\"\"\n",
    "    geography_data = []\n",
    "    geo_id = 1\n",
    "    \n",
    "    # North America\n",
    "    north_america_countries = {\n",
    "        'United States': {\n",
    "            'code': 'US',\n",
    "            'provinces': [\n",
    "                'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut',\n",
    "                'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa',\n",
    "                'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan',\n",
    "                'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire',\n",
    "                'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio',\n",
    "                'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota',\n",
    "                'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia',\n",
    "                'Wisconsin', 'Wyoming'\n",
    "            ]\n",
    "        },\n",
    "        'Canada': {\n",
    "            'code': 'CA',\n",
    "            'provinces': [\n",
    "                'Alberta', 'British Columbia', 'Manitoba', 'New Brunswick', 'Newfoundland and Labrador',\n",
    "                'Nova Scotia', 'Ontario', 'Prince Edward Island', 'Québec', 'Saskatchewan',\n",
    "                'Northwest Territories', 'Nunavut', 'Yukon'\n",
    "            ]\n",
    "        },\n",
    "        'Mexico': {\n",
    "            'code': 'MX',\n",
    "            'provinces': [\n",
    "                'Aguascalientes', 'Baja California', 'Baja California Sur', 'Campeche', 'Chiapas',\n",
    "                'Chihuahua', 'Coahuila', 'Colima', 'Durango', 'Guanajuato', 'Guerrero', 'Hidalgo',\n",
    "                'Jalisco', 'México', 'Distrito Federal', 'Michoacán', 'Morelos', 'Nayarit',\n",
    "                'Nuevo León', 'Oaxaca', 'Puebla', 'Querétaro', 'Quintana Roo', 'San Luis Potosí',\n",
    "                'Sinaloa', 'Sonora', 'Tabasco', 'Tamaulipas', 'Tlaxcala', 'Veracruz', 'Yucatán', 'Zacatecas'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Europe\n",
    "    europe_countries = {\n",
    "        'Germany': {\n",
    "            'code': 'DE',\n",
    "            'provinces': [\n",
    "                'Baden-Württemberg', 'Bavaria', 'Berlin', 'Brandenburg', 'Bremen', 'Hamburg',\n",
    "                'Hesse', 'Lower Saxony', 'Mecklenburg-Vorpommern', 'North Rhine-Westphalia',\n",
    "                'Rhineland-Palatinate', 'Saarland', 'Saxony', 'Saxony-Anhalt',\n",
    "                'Schleswig-Holstein', 'Thuringia'\n",
    "            ]\n",
    "        },\n",
    "        'United Kingdom': {\n",
    "            'code': 'GB',\n",
    "            'provinces': [\n",
    "                'England', 'Scotland', 'Wales', 'Northern Ireland'\n",
    "            ]\n",
    "        },\n",
    "        'Norway': {'code': 'NO', 'provinces': ['Oslo', 'Viken', 'Innlandet', 'Vestfold og Telemark', 'Agder', 'Rogaland', 'Vestland', 'Møre og Romsdal', 'Trøndelag', 'Nordland', 'Troms og Finnmark']},\n",
    "        'France': {'code': 'FR', 'provinces': ['Bretagne', 'Normandie', 'Île-de-France', 'Auvergne-Rhône-Alpes', 'Bourgogne-Franche-Comté', 'Centre-Val de Loire', 'Corsica', 'Grand Est', 'Hauts-de-France', 'Nouvelle-Aquitaine', 'Occitanie', 'Pays de la Loire', 'Provence-Alpes-Côte d\\'Azur']},\n",
    "        'Netherlands': {'code': 'NL', 'provinces': ['Drenthe', 'Flevoland', 'Friesland', 'Gelderland', 'Groningen', 'Limburg', 'North Brabant', 'North Holland', 'Overijssel', 'Utrecht', 'Zeeland', 'South Holland']},\n",
    "        'Sweden': {'code': 'SE', 'provinces': ['Blekinge', 'Dalarna', 'Gotland', 'Gävleborg', 'Halland', 'Jämtland', 'Jönköping', 'Kalmar', 'Kronoberg', 'Norrbotten', 'Skåne', 'Stockholm', 'Södermanland', 'Uppsala', 'Värmland', 'Västerbotten', 'Västernorrland', 'Västmanland', 'Västra Götaland', 'Örebro', 'Östergötland']},\n",
    "        'Switzerland': {'code': 'CH', 'provinces': ['Zurich', 'Bern', 'Lucerne', 'Uri', 'Schwyz', 'Obwalden', 'Nidwalden', 'Glarus', 'Zug', 'Fribourg', 'Solothurn', 'Basel-Stadt', 'Basel-Landschaft', 'Schaffhausen', 'Appenzell Ausserrhoden', 'Appenzell Innerrhoden', 'St. Gallen', 'Graubünden', 'Aargau', 'Thurgau', 'Ticino', 'Vaud', 'Valais', 'Neuchâtel', 'Geneva', 'Jura']},\n",
    "        'Italy': {'code': 'IT', 'provinces': ['Abruzzo', 'Aosta Valley', 'Apulia', 'Basilicata', 'Calabria', 'Campania', 'Emilia-Romagna', 'Friuli-Venezia Giulia', 'Lazio', 'Liguria', 'Lombardy', 'Marche', 'Molise', 'Piedmont', 'Sardinia', 'Sicily', 'Tuscany', 'Trentino-Alto Adige', 'Umbria', 'Veneto']},\n",
    "        'Spain': {'code': 'ES', 'provinces': ['Andalusia', 'Aragon', 'Principality of Asturias', 'Balearic Islands', 'Basque Country', 'Canary Islands', 'Cantabria', 'Castile and León', 'Castile-La Mancha', 'Catalonia', 'Community of Madrid', 'Valencian Community', 'Extremadura', 'Galicia', 'La Rioja', 'Region of Murcia', 'Foral Community of Navarre']},\n",
    "        'Denmark': {'code': 'DK', 'provinces': ['Capital Region of Denmark', 'Central Denmark Region', 'North Denmark Region', 'Region Zealand', 'Region of Southern Denmark']},\n",
    "        'Finland': {'code': 'FI', 'provinces': ['Åland Islands', 'Central Finland', 'Central Ostrobothnia', 'Kainuu', 'Kymenlaakso', 'Lapland', 'North Karelia', 'North Ostrobothnia', 'Northern Savonia', 'Päijät-Häme', 'Pirkanmaa', 'Satakunta', 'South Karelia', 'Southern Ostrobothnia', 'Southern Savonia', 'Tavastia Proper', 'Uusimaa', 'Southwest Finland']},\n",
    "        'Greece': {'code': 'GR', 'provinces': ['Attica', 'Central Greece', 'Central Macedonia', 'Crete', 'East Macedonia and Thrace', 'Epirus', 'Ionian Islands', 'North Aegean', 'Peloponnese', 'South Aegean', 'Thessaly', 'West Greece', 'West Macedonia']},\n",
    "        'Iceland': {'code': 'IS', 'provinces': ['Capital Region', 'Southern Peninsula', 'Western Region', 'Westfjords', 'Northwest Region', 'Northeast Region', 'Eastern Region', 'Southern Region']},\n",
    "        'Ireland': {'code': 'IE', 'provinces': ['Connacht', 'Leinster', 'Munster', 'Ulster']},\n",
    "        'Luxembourg': {'code': 'LU', 'provinces': ['Diekirch', 'Grevenmacher', 'Luxembourg']},\n",
    "        'Monaco': {'code': 'MC', 'provinces': ['Monaco']}\n",
    "    }\n",
    "    \n",
    "    # Asia\n",
    "    asia_countries = {\n",
    "        'China': {\n",
    "            'code': 'CN',\n",
    "            'provinces': [\n",
    "                'Anhui', 'Fujian', 'Gansu', 'Guangdong', 'Guizhou', 'Hainan', 'Hebei', 'Heilongjiang',\n",
    "                'Henan', 'Hubei', 'Hunan', 'Jiangsu', 'Jiangxi', 'Jilin', 'Liaoning', 'Qinghai',\n",
    "                'Shaanxi', 'Shandong', 'Shanxi', 'Sichuan', 'Yunnan', 'Zhejiang',\n",
    "                'Guangxi', 'Nei Mongol', 'Ningxia Hui', 'Xinjiang Uygur', 'Xizang', \n",
    "                'Beijing', 'Chongqing', 'Shanghai', 'Tianjin'\n",
    "            ]\n",
    "        },\n",
    "        'Hong Kong': {'code': 'HK', 'provinces': ['Hong Kong Island', 'Kowloon', 'New Territories']},\n",
    "        'Macau': {'code': 'MO', 'provinces': ['Macau']},\n",
    "        'Japan': {\n",
    "            'code': 'JP',\n",
    "            'provinces': [\n",
    "                'Hokkaido', 'Aomori', 'Iwate', 'Miyagi', 'Akita', 'Yamagata', 'Fukushima',\n",
    "                'Ibaraki', 'Tochigi', 'Gunma', 'Saitama', 'Chiba', 'Tokyo', 'Kanagawa',\n",
    "                'Niigata', 'Toyama', 'Ishikawa', 'Fukui', 'Yamanashi', 'Nagano',\n",
    "                'Gifu', 'Shizuoka', 'Aichi', 'Mie', 'Shiga', 'Kyoto', 'Osaka',\n",
    "                'Hyōgo', 'Nara', 'Wakayama', 'Tottori', 'Shimane', 'Okayama',\n",
    "                'Hiroshima', 'Yamaguchi', 'Tokushima', 'Kagawa', 'Ehime', 'Kochi',\n",
    "                'Fukuoka', 'Saga', 'Naoasaki', 'Kumamoto', 'Oita', 'Miyazaki', 'Kagoshima', 'Okinawa'\n",
    "            ]\n",
    "        },\n",
    "        'South Korea': {\n",
    "            'code': 'KR',\n",
    "            'provinces': [\n",
    "                'Busan', 'Chungcheongbuk-do', 'Chungcheongnam-do', 'Daegu', 'Daejeon', 'Gangwon-do',\n",
    "                'Gwangju', 'Gyeonggi-do', 'Gyeongsangbuk-do', 'Gyeongsangnam-do', 'Incheon', 'Jeollabuk-do',\n",
    "                'Jeollanam-do', 'Sejong', 'Seoul', 'Ulsan', 'Jeju'\n",
    "            ]\n",
    "        },\n",
    "        'Taiwan': {\n",
    "            'code': 'TW',\n",
    "            'provinces': [\n",
    "                'Taipei', 'New Taipei', 'Taichung', 'Tainan', 'Kaohsiung', 'Taoyuan', \n",
    "                'Keelung', 'Hsinchu City', 'Chiayi City', 'Hsinchu County', 'Chiayi County',\n",
    "                'Changhua', 'Nantou', 'Yulin', 'Miaoli', 'Pingtung', 'Yilan', 'Hualien',\n",
    "                'Taitung', 'Penghu', 'Kinmen', 'Lienkiang'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Oceania\n",
    "    oceania_countries = {\n",
    "        'Australia': {\n",
    "            'code': 'AU',\n",
    "            'provinces': [\n",
    "                'New South Wales', 'Victoria', 'Queensland', 'South Australia', 'Western Australia',\n",
    "                'Tasmania', 'Australian Capital Territory', 'Northern Territory'\n",
    "            ]\n",
    "        },\n",
    "        'New Zealand': {\n",
    "            'code': 'NZ',\n",
    "            'provinces': [\n",
    "                'Auckland', 'Bay of Plenty', 'Canterbury', 'Gisborne', 'Hawke\\'s Bay',\n",
    "                'Manawatu-Wanganui', 'Marlborough', 'Nelson', 'Northland', 'Otago',\n",
    "                'Southland', 'Taranaki', 'Tasman', 'Waikato', 'Wellington', 'West Coast'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    continents = {\n",
    "        'North America': north_america_countries,\n",
    "        'Europe': europe_countries,\n",
    "        'Asia': asia_countries,\n",
    "        'Oceania': oceania_countries\n",
    "    }\n",
    "\n",
    "    for continent, countries in continents.items():\n",
    "        for country, details in countries.items():\n",
    "            for province in details['provinces']:\n",
    "                state_abbr = province[:2].upper()\n",
    "                \n",
    "                geography_data.append([\n",
    "                    geo_id,\n",
    "                    continent,\n",
    "                    country,\n",
    "                    details['code'],\n",
    "                    province,\n",
    "                    state_abbr,\n",
    "                    generate_plausible_zip(country, state_abbr)\n",
    "                ])\n",
    "                geo_id += 1\n",
    "\n",
    "    dim_geography_df = pd.DataFrame(geography_data, columns=[\n",
    "        'Geo_ID', 'Continent', 'Country', 'Country_Code', 'State_Province', 'State_Province_Abbr', 'Zip_Code'\n",
    "    ])\n",
    "    \n",
    "    return dim_geography_df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Generating Dim_Geography table...\")\n",
    "    dim_geography_df = generate_dim_geography()\n",
    "    \n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(\"Saving Dim_Geography.csv...\")\n",
    "    dim_geography_df.to_csv(os.path.join(output_dir, 'Dim_Geography.csv'), index=False, encoding='utf-8')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Dim_Geography.csv has been successfully generated with {len(dim_geography_df)} rows in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7926e48-96b2-4648-ba01-8c1bde0daaa7",
   "metadata": {},
   "source": [
    "**5/6: 生成 Dim_Prices 表 (相对静态数据)维度表更可能需要更新Update或追加Append。例如，新产品或不同时段价格可能会发生变化，此时就需要更新或追加Append表中的相应记录。这种变化管理被称为“缓慢变化维度”（Slowly Changing Dimension, SCD）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "360e5f7c-0f05-4569-826d-eb07286bdaec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dim_Product and Dim_Time for price generation...\n",
      "Generating Dim_Prices table...\n",
      "Saving Dim_Prices.csv...\n",
      "Dim_Prices.csv has been successfully generated with 4186 rows in 1.21 seconds.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"5/6: Generate Dim_Prices Table\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Use a fixed random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def generate_dim_prices(dim_product_df, dim_time_df):\n",
    "    \"\"\"Generates the Dim_Prices table.\"\"\"\n",
    "    quarter_start_dates = sorted(dim_time_df['Full_Date'].loc[dim_time_df['Month'].isin([1, 4, 7, 10])].unique())\n",
    "    model_ids = dim_product_df['Model_ID'].unique()\n",
    "    \n",
    "    prices_data = []\n",
    "    \n",
    "    # Dynamic price generation with seasonal/random fluctuations\n",
    "    for quarter_start_date in quarter_start_dates:\n",
    "        for model_id in model_ids:\n",
    "            # Base price from product table\n",
    "            base_price = dim_product_df.loc[dim_product_df['Model_ID'] == model_id, 'Model_Base_Price_USD'].iloc[0]\n",
    "            \n",
    "            # Fluctuate prices randomly with a trend\n",
    "            price_factor = 1 + random.uniform(-0.05, 0.05)\n",
    "            \n",
    "            # Apply launch date logic\n",
    "            launch_date = dim_product_df.loc[dim_product_df['Model_ID'] == model_id, 'Model_Launch_Date'].iloc[0]\n",
    "            if pd.to_datetime(quarter_start_date) < launch_date:\n",
    "                # Car not launched yet\n",
    "                continue\n",
    "            \n",
    "            standard_price = base_price * price_factor\n",
    "            \n",
    "            # Randomly apply a discount\n",
    "            is_discounted = random.random() < 0.2  # 20% chance of a discount\n",
    "            discount_price = standard_price\n",
    "            if is_discounted:\n",
    "                discount_percentage = random.uniform(0.02, 0.10) # 2-10% discount\n",
    "                discount_price = standard_price * (1 - discount_percentage)\n",
    "            \n",
    "            prices_data.append([\n",
    "                model_id,\n",
    "                quarter_start_date,\n",
    "                standard_price,\n",
    "                discount_price\n",
    "            ])\n",
    "            \n",
    "    return pd.DataFrame(prices_data, columns=['Model_ID', 'Quarter_Start_Date', 'Standard_Price_USD', 'Discounted_Price_USD'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Loading Dim_Product and Dim_Time for price generation...\")\n",
    "    # This script depends on the output of the two previous scripts\n",
    "    try:\n",
    "        dim_product_df = pd.read_csv('./output_data/Dim_Product.csv')\n",
    "        dim_time_df = pd.read_csv('./output_data/Dim_Time.csv')\n",
    "        dim_time_df['Full_Date'] = pd.to_datetime(dim_time_df['Full_Date'])\n",
    "        dim_product_df['Model_Launch_Date'] = pd.to_datetime(dim_product_df['Model_Launch_Date'])\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Could not find 'Dim_Product.csv' or 'Dim_Time.csv'. Please run the previous scripts first.\")\n",
    "        exit()\n",
    "        \n",
    "    print(\"Generating Dim_Prices table...\")\n",
    "    dim_prices_df = generate_dim_prices(dim_product_df, dim_time_df)\n",
    "\n",
    "    output_dir = './output_data'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(\"Saving Dim_Prices.csv...\")\n",
    "    dim_prices_df.to_csv(os.path.join(output_dir, 'Dim_Prices.csv'), index=False, encoding='utf-8')\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Dim_Prices.csv has been successfully generated with {len(dim_prices_df)} rows in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c5fbf-fba3-4e2c-a34f-1a55941f2260",
   "metadata": {},
   "source": [
    "**6/6: 生成 Fact_Sales 表 (高度动态数据，最常被追加（append）的表) 只进不出”的设计哲学。每当一笔新的销售发生，就在 Fact_Sales 表中追加一行新的数据，而不会去修改之前已经存在的历史销售记录**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8acfd024-0ed6-4fa4-a9e5-fd1c74ebf2d6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载所有维度表...\n",
      "正在生成 Fact_Sales 表...\n",
      "正在为年份 2017 生成 103,091 条销售记录...\n",
      "正在为年份 2018 生成 245,491 条销售记录...\n",
      "正在为年份 2019 生成 367,656 条销售记录...\n",
      "正在为年份 2020 生成 499,535 条销售记录...\n",
      "正在为年份 2021 生成 936,222 条销售记录...\n",
      "正在为年份 2022 生成 1,313,851 条销售记录...\n",
      "正在为年份 2023 生成 1,808,581 条销售记录...\n",
      "正在为年份 2024 生成 1,789,226 条销售记录...\n",
      "正在为年份 2025 生成 720,803 条销售记录...\n",
      "保存 Fact_Sales.csv...\n",
      "Fact_Sales.csv 已成功生成 7,784,456 行数据，耗时 33.91 秒。\n",
      "数据生成完成！\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Generate Fact_Sales Table (CPU Version)\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# 全局变量，用于保存一次性生成的权重\n",
    "global_weights = {}\n",
    "\n",
    "def generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df):\n",
    "    \"\"\"\n",
    "    Generates the Fact_Sales table by combining all dimension tables.\n",
    "    Uses real-world Tesla sales distribution and volume data for realistic output.\n",
    "    \"\"\"\n",
    "    start_year = dim_time_df['Year'].min()\n",
    "    end_year = datetime.now().year\n",
    "\n",
    "    # 实际历史数据（已转换单位为百万）\n",
    "    revenue_targets = {\n",
    "        2008: 15e6, 2009: 112e6, 2010: 117e6, 2011: 204e6, 2012: 413e6,\n",
    "        2013: 2.01e9, 2014: 3.2e9, 2015: 4.05e9, 2016: 7e9, 2017: 11.76e9,\n",
    "        2018: 21.46e9, 2019: 24.58e9, 2020: 31.54e9, 2021: 53.82e9,\n",
    "        2022: 81.46e9, 2023: 96.77e9, 2024: 97.69e9\n",
    "    }\n",
    "\n",
    "    unit_targets = {\n",
    "        2013: 22442, 2014: 31655, 2015: 50517, 2016: 76243, 2017: 103091,\n",
    "        2018: 245491, 2019: 367656, 2020: 499535, 2021: 936222,\n",
    "        2022: 1313851, 2023: 1808581, 2024: 1789226\n",
    "    }\n",
    "    \n",
    "    # 根据您提供的最新数据，更新2025年Q1和Q2的交付量和营收\n",
    "    unit_targets[2025] = 336681 + 384122\n",
    "    revenue_targets[2025] = 19.335e9 + 22.496e9\n",
    "    \n",
    "    # 动态计算YTD日期，确保只生成到2025年Q2的数据\n",
    "    ytd_end_date = datetime(2025, 6, 30)\n",
    "\n",
    "    # --- 关键修复：移除之前的价格校准逻辑，将最终校准放在数据生成后 ---\n",
    "\n",
    "    sales_data = []\n",
    "\n",
    "    # --------------------------\n",
    "    # 步骤 1: 数据清洗和预处理\n",
    "    # --------------------------\n",
    "    asia_countries = ['China', 'Japan', 'South Korea', 'Singapore', 'India', 'Indonesia', 'Thailand', 'Malaysia', 'Taiwan']\n",
    "    oceania_countries = ['Australia', 'New Zealand']\n",
    "    europe_countries = ['Germany', 'United Kingdom', 'France', 'Norway', 'Netherlands', 'Sweden', 'Italy', 'Switzerland', 'Spain', 'Belgium', 'Austria', 'Denmark', 'Finland', 'Portugal', 'Ireland', 'Luxembourg', 'Iceland']\n",
    "    \n",
    "    def get_continent(country):\n",
    "        if country in asia_countries:\n",
    "            return 'Asia'\n",
    "        elif country in oceania_countries:\n",
    "            return 'Oceania'\n",
    "        elif country in europe_countries:\n",
    "            return 'Europe'\n",
    "        else:\n",
    "            return 'North America'\n",
    "            \n",
    "    dim_geography_df['Continent'] = dim_geography_df['Country'].apply(get_continent).astype(str)\n",
    "\n",
    "    # --------------------------\n",
    "    # 步骤 2: 定义权重\n",
    "    # --------------------------\n",
    "    product_weights = {1: 0.45, 2: 0.45, 3: 0.05, 4: 0.04, 5: 0.01}\n",
    "    continent_weights = {'North America': 0.45, 'Europe': 0.30, 'Asia': 0.23, 'Oceania': 0.02}\n",
    "    country_weights = {'United States': 0.80, 'Canada': 0.20, 'China': 0.90, 'Japan': 0.05, 'South Korea': 0.05, 'Germany': 0.30, 'United Kingdom': 0.20, 'France': 0.15, 'Norway': 0.10, 'Australia': 0.90, 'New Zealand': 0.10, 'Taiwan': 0.01}\n",
    "    \n",
    "    state_province_weights = {\n",
    "        # 北美\n",
    "        'California': 0.40, 'Texas': 0.25, 'Florida': 0.15, 'Washington': 0.10, 'New York': 0.10, # 美国\n",
    "        'Ontario': 0.4, 'Quebec': 0.25, 'British Columbia': 0.2, 'Alberta': 0.15, # 加拿大\n",
    "        # 亚洲\n",
    "        'Shanghai': 0.50, 'Beijing': 0.20, 'Guangdong': 0.20, 'Zhejiang': 0.10, # 中国\n",
    "        'Taipei': 0.5, 'New Taipei City': 0.2, 'Taichung': 0.1, 'Kaohsiung': 0.1, 'Tainan': 0.05, 'Taoyuan': 0.05, # 台湾\n",
    "        # 欧洲\n",
    "        'Bavaria': 0.40, 'North Rhine-Westphalia': 0.25, 'Baden-Württemberg': 0.15, 'Berlin': 0.10, # 德国\n",
    "        'Greater London': 0.50, 'South East England': 0.25, 'North West England': 0.15, 'West Midlands': 0.10, # 英国\n",
    "        'Île-de-France': 0.60, 'Auvergne-Rhône-Alpes': 0.20, 'Nouvelle-Aquitaine': 0.10, 'Provence-Alpes-Côte d\\'Azur': 0.10, # 法国\n",
    "        'Oslo': 0.70, 'Vestland': 0.15, 'Viken': 0.10, 'Trøndelag': 0.05, # 挪威\n",
    "        # 大洋洲\n",
    "        'New South Wales': 0.5, 'Victoria': 0.3, 'Queensland': 0.1, 'Western Australia': 0.05, 'South Australia': 0.05, # 澳大利亚\n",
    "        'Auckland': 0.6, 'Wellington': 0.2, 'Canterbury': 0.1, 'Otago': 0.05, 'Waikato': 0.05, # 新西兰\n",
    "    }\n",
    "\n",
    "    def get_state_weights_for_country(country):\n",
    "        if country in global_weights:\n",
    "            return global_weights[country]\n",
    "\n",
    "        states = dim_geography_df[dim_geography_df['Country'] == country]['State_Province'].unique()\n",
    "        if not states.any():\n",
    "            return {}\n",
    "        \n",
    "        weights = {}\n",
    "        states.sort()\n",
    "        num_states = len(states)\n",
    "        for i, s in enumerate(states):\n",
    "            weights[s] = (num_states - i) / (num_states * (num_states + 1) / 2)\n",
    "        \n",
    "        global_weights[country] = weights\n",
    "        return weights\n",
    "\n",
    "    # 预计算所有 Geo_ID 的权重\n",
    "    dim_geography_df['Geo_Weight'] = 0.0\n",
    "    for continent, c_weight in continent_weights.items():\n",
    "        countries_in_continent = dim_geography_df[dim_geography_df['Continent'] == continent]['Country'].unique()\n",
    "        for country in countries_in_continent:\n",
    "            country_w = country_weights.get(country, 0.01)\n",
    "            states = dim_geography_df[dim_geography_df['Country'] == country]['State_Province'].unique()\n",
    "            state_weights = state_province_weights.get(country, get_state_weights_for_country(country))\n",
    "            \n",
    "            for state in states:\n",
    "                state_w = state_province_weights.get(state, state_weights.get(state, 0.01))\n",
    "                mask = (dim_geography_df['Country'] == country) & (dim_geography_df['State_Province'] == state)\n",
    "                dim_geography_df.loc[mask, 'Geo_Weight'] = c_weight * country_w * state_w\n",
    "    \n",
    "    dim_geography_df['Geo_Weight'] = dim_geography_df['Geo_Weight'].fillna(0.0001)\n",
    "\n",
    "    customer_ids = dim_customer_df['Customer_ID'].values\n",
    "    \n",
    "    dim_time_df['Quarter_Start_Date'] = pd.to_datetime(dim_time_df['Full_Date']).dt.to_period('Q').dt.start_time\n",
    "    if 'Quarter_Start_Date' in dim_prices_df.columns and dim_prices_df['Quarter_Start_Date'].dt.tz is not None:\n",
    "        dim_prices_df['Quarter_Start_Date'] = dim_prices_df['Quarter_Start_Date'].dt.tz_localize(None)\n",
    "\n",
    "    price_time_lookup = dim_prices_df.merge(\n",
    "        dim_time_df, \n",
    "        on='Quarter_Start_Date', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    df_time = pd.DataFrame(price_time_lookup['Time_ID'].unique(), columns=['Time_ID'])\n",
    "    df_product = pd.DataFrame(list(product_weights.keys()), columns=['Model_ID'])\n",
    "    df_product['Product_Weight'] = df_product['Model_ID'].map(product_weights)\n",
    "    df_geography = dim_geography_df[['Geo_ID', 'Geo_Weight']].copy()\n",
    "\n",
    "    all_combinations = pd.merge(df_time.merge(df_product, how='cross'), df_geography, how='cross')\n",
    "    \n",
    "    all_combinations['Combined_Weight'] = all_combinations['Product_Weight'] * all_combinations['Geo_Weight']\n",
    "    \n",
    "    all_combinations.dropna(subset=['Combined_Weight', 'Time_ID'], inplace=True)\n",
    "    all_combinations['Probability'] = all_combinations['Combined_Weight'] / all_combinations['Combined_Weight'].sum()\n",
    "\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        target_units = unit_targets.get(year, 0)\n",
    "        if target_units == 0:\n",
    "            print(f\"警告：年份 {year} 没有交付量数据，跳过生成。\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"正在为年份 {year} 生成 {target_units:,} 条销售记录...\")\n",
    "        \n",
    "        # 筛选出当年的所有组合，并限制在YTD范围内\n",
    "        time_ids_str = all_combinations['Time_ID'].astype(int).astype(str)\n",
    "        current_year_combinations = all_combinations[\n",
    "            (pd.to_datetime(time_ids_str, format='%Y%m%d').dt.year == year) &\n",
    "            (pd.to_datetime(time_ids_str, format='%Y%m%d') <= ytd_end_date)\n",
    "        ].copy()\n",
    "\n",
    "        if current_year_combinations.empty:\n",
    "            print(f\"警告：年份 {year} 在 YTD 范围内没有可用的时间组合，跳过该年份。\")\n",
    "            continue\n",
    "            \n",
    "        current_year_combinations['Probability'] = current_year_combinations['Combined_Weight'] / current_year_combinations['Combined_Weight'].sum()\n",
    "\n",
    "        sampled_rows = current_year_combinations.sample(n=target_units, replace=True, weights='Probability', random_state=42).reset_index(drop=True)\n",
    "        sampled_rows['Customer_ID'] = np.random.choice(customer_ids, size=target_units, replace=True)\n",
    "\n",
    "        fact_sales_df_temp = sampled_rows.merge(price_time_lookup, on=['Time_ID', 'Model_ID'], how='left')\n",
    "\n",
    "        fact_sales_df_temp['Sales_Units'] = 1\n",
    "        fact_sales_df_temp['Is_Discounted_Sale'] = fact_sales_df_temp['Discounted_Price_USD'] < fact_sales_df_temp['Standard_Price_USD']\n",
    "        fact_sales_df_temp['Revenue_USD'] = fact_sales_df_temp['Sales_Units'] * fact_sales_df_temp['Discounted_Price_USD']\n",
    "\n",
    "        sales_data.append(fact_sales_df_temp)\n",
    "        \n",
    "    if not sales_data:\n",
    "        print(\"所有年份均没有可用数据，无法生成 Fact_Sales 表。\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    fact_sales_df = pd.concat(sales_data, ignore_index=True)\n",
    "    \n",
    "    # --- 最终修复：在生成完整的 Fact 表后，进行最终的营收校准 ---\n",
    "    current_total_revenue = fact_sales_df['Revenue_USD'].sum()\n",
    "    target_total_revenue = 450e9\n",
    "    \n",
    "    if current_total_revenue > 0:\n",
    "        revenue_factor = target_total_revenue / current_total_revenue\n",
    "        fact_sales_df['Revenue_USD'] = fact_sales_df['Revenue_USD'] * revenue_factor\n",
    "    # --- 最终修复结束 ---\n",
    "    \n",
    "    fact_sales_df['Is_Discounted_Sale'] = fact_sales_df['Is_Discounted_Sale'].astype(bool)\n",
    "    \n",
    "    fact_sales_df = fact_sales_df[['Time_ID', 'Geo_ID', 'Model_ID', 'Customer_ID', 'Sales_Units', 'Is_Discounted_Sale', 'Revenue_USD']]\n",
    "    \n",
    "    return fact_sales_df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"正在加载所有维度表...\")\n",
    "    try:\n",
    "        dim_product_df = pd.read_csv(os.path.join('./output_data', 'Dim_Product.csv'))\n",
    "        dim_time_df = pd.read_csv(os.path.join('./output_data', 'Dim_Time.csv'))\n",
    "        dim_customer_df = pd.read_csv(os.path.join('./output_data', 'Dim_Customer.csv'))\n",
    "        dim_geography_df = pd.read_csv(os.path.join('./output_data', 'Dim_Geography.csv'))\n",
    "        dim_prices_df = pd.read_csv(os.path.join('./output_data', 'Dim_Prices.csv'))\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"错误：缺少一个或多个必需的 CSV 文件。请先运行所有维度生成脚本（1-5）。\\n{e}\")\n",
    "        exit()\n",
    "\n",
    "    dim_time_df['Full_Date'] = pd.to_datetime(dim_time_df['Full_Date'])\n",
    "    dim_prices_df['Quarter_Start_Date'] = pd.to_datetime(dim_prices_df['Quarter_Start_Date'])\n",
    "    \n",
    "    print(\"正在生成 Fact_Sales 表...\")\n",
    "    fact_sales_df = generate_fact_sales(dim_product_df, dim_time_df, dim_customer_df, dim_geography_df, dim_prices_df)\n",
    "\n",
    "    if not fact_sales_df.empty:\n",
    "        output_dir = './output_data'\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        print(\"保存 Fact_Sales.csv...\")\n",
    "        fact_sales_df.to_csv(os.path.join(output_dir, 'Fact_Sales.csv'), index=False, encoding='utf-8')\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Fact_Sales.csv 已成功生成 {len(fact_sales_df):,} 行数据，耗时 {end_time - start_time:.2f} 秒。\")\n",
    "        print(\"数据生成完成！\")\n",
    "    else:\n",
    "        print(\"数据生成失败。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad926a72-11e2-4522-8add-4e77282c2af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
